---
title: "Market Basket"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Python

* pandas: isin | crosstab

* pd.group_by aggregate functions: size, count, sum, mean, median, sd, var, min, max, prod, first, last

* The only float that isn't equal to itself is nan.

* %matplotlib notebook: interactive plots

* Memory storage: use pd.copy to create a deep copy instead of a shallow copy

* IPy: %who or %whos shows defined variables & %reset resets them

* Append dict to df: use ignore_index = True. eg. films_df = films_df.append(film_dict, ignore_index=1)

* Debugging: import pdb | pdb.set_trace(), 

* dir() gives a list of in scope variables

* globals() gives a dictionary of global variables

* locals() gives a dictionary of local variables

**Vanderplas Jupyter**

* create helper functions and units tests as R/py for Rmd/ipynb

* pytest/hypothesis for testing

* use makefile to run cmd commands

* Write file with date: df.to_csv('{}_model.csv'.format(str(datetime.datetime.now()).split(' ')[0]))

* Make package for workflow with data (__init__.py) and use this formation for function docs:

def fun(a): 
```{python}
def fun(a):

  Role
  -----
  Does something
  
  Parameters
  ---------
  Accepts something
  
  Returns
  -------
  Returns something
  
  return(a)
```

## R

* rm(list = ls()): Remove all objects in the current workspace

* cut(): Transform a numeric variable into a categorical variable.

* car: recode (good for dummying)

* Examine the objects in the workspace: ls.str()

* This is how you dynamically update a value in Rmarkdown: x = *backtick* r x *backtick*. 

**R for Everything Talk**

* dir.exists | dir.create | download.file

* untar | unlink | file.info

* dir | file.rename | file.copy

* count.fields | system

* dplyr five main actions: select, filter, arrange, mutate, summarize.

## Git

* "Just learned something cool- when you screw up a git merge, you can use git reset --hard master@{"300 minutes ago"} with any time quantity you want in there to get back to where things were a period of time ago." [[source]](https://twitter.com/data_stephanie/status/968226587547258886)

* Add upstream to update a forked repo with the original: remote add upstream repo_url 

* To undo git add . use git reset (no dot)

* git config --global credential.helper 'cache --timeout=10000000'

* Update chnages from original repo, put in new branch: git fetch upstream

* Merge the upstream chnages to master on your local machine: git merge upstream/master

* Update local repo with master changes: git pull origin master

* git diff (--cache) | git rm --cached 't.py' //remove from staging area

* git show version_name + git branch (--merged, --no-merged) + git merge fix20

* never rebase commits to public repo + rebase: branch working with behind in commit

* use revert (change commit and log the change) + dont use reset: erases commit and doesnt log.

* get fork url use: git clone url + git remote add upstream url: ref original repo

* git fetch upstream: pull changes fro original repo + git push origin master: push stuff to clone

* git merge upstream/master: merge github and local + make pull request, send pull request

* Reset: Move master and working directory.

* Revert: Less harsh version of reset, maintains commit history but moves forward by one from most recent commit.

## Other

* Cheatsheets: [1](https://startupsventurecapital.com/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5) | [2](https://github.com/kailashahirwar/cheatsheets-ai) | [3](https://github.com/juliangaal/python-cheat-sheet):[4](http://www.datasciencefree.com/cheatsheets.html)

## YAML

A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with:

`conda env export > environment.yaml`

The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml. This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use:

`conda env create -f environment.yaml`

This will create a new environment with the same name listed in environment.yaml.

