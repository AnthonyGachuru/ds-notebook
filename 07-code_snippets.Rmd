# Code Snippets

## Python

### General

* https://chrisalbon.com/

* pandas: isin | crosstab

* pd.group_by aggregate functions: size, count, sum, mean, median, sd, var, min, max, prod, first, last

* The only float that isn't equal to itself is nan.

* %matplotlib notebook: interactive plots

* Memory storage: use pd.copy to create a deep copy instead of a shallow copy

* IPy: %who or %whos shows defined variables & %reset resets them

* Append dict to df: use ignore_index = True. eg. films_df = films_df.append(film_dict, ignore_index=1)

* Debugging: import pdb | pdb.set_trace(), 

* dir() gives a list of in scope variables

* globals() gives a dictionary of global variables

* locals() gives a dictionary of local variables

* https://bugra.github.io/work/notes/2015-01-03/i-wish-i-knew-these-things-when-i-first-learned-python/

* np.dot = np.multiply %>% np.sum

* flatten dict

    * pd.io.json.json_normalize(stuff)
    *https://stackoverflow.com/questions/6027558/flatten-nested-python-dictionaries-compressing-keys/41689055#41689055
    * https://towardsdatascience.com/flattening-json-objects-in-python-f5343c794b10
    

### Vanderplas Jupyter

* create helper functions and units tests as R/py for Rmd/ipynb

* pytest/hypothesis for testing

* use makefile to run cmd commands

* Write file with date: df.to_csv('{}_model.csv'.format(str(datetime.datetime.now()).split(' ')[0]))

* Make package for workflow with data (__init__.py) and use this formation for function docs:

```{python, eval = FALSE}
def fun(a):

  #Role
  #-----
  #Does something
  
  #Parameters
  #---------
  #Accepts something
  
  #Returns
  #-------
  #Returns something
  
  return(a)
```

### Auto Feature Engineering

```{python, eval = F}
#https://stackoverflow.com/questions/50145953/how-to-apply-deep-feature-synthesis-to-a-single-table

import numpy as np
import pandas as pd
import featuretools as ft

df = pd.read_csv('iris.csv')
df = df.reset_index()

es = ft.EntitySet(id = "test") #.drop(columns = ['species'], axis = 1)
es = es.entity_from_dataframe(entity_id = 'd', dataframe = df, make_index=True, index='ind')

fm, features = ft.dfs(
    entityset = es, 
    target_entity = 'd',
    agg_primitives = ['mean', 'max', 'percent_true', 'last'],
    trans_primitives = ['subtract', 'divide']
)

# produces 626 features

_, features2 = ft.dfs(
    entityset = es, 
    target_entity = 'd',
    max_depth = 2
)

# produces no new features
```

### SHAP Explainer

```{python, eval = F}
clf.fit(X_train, y_train)

explainer = shap.TreeExplainer(clf)
shap_values = explainer.shap_values(X_train)

shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:]) # one record explained
shap.summary_plot(shap_values, X_train, plot_type = "bar") # all records explained
shap.summary_plot(shap_values, X_train, plot_type = "bar") # shap mae for features across all records
```

### DF To HTML Table

```{python, eval = F}
from flask import Flask
import pandas as pd
app = Flask(__name__)
pd.set_option('display.max_colwidth', -1)

@app.route("/")
def show_tables():
    data = pd.read_csv('squads.csv')
    return data.to_html(escape = False, index_names = False)

if __name__ == "__main__":
    app.run(debug=True)
```

### Masking Array
    
You can mask your array using the numpy.ma.array function and subsequently apply any numpy operation:

```{python, eval = FALSE}
import numpy as np

a = np.random.rand(10)            # Generate random data.
a = np.where(a > 0.8, np.nan, a)  # Set all data larger than 0.8 to NaN

a = np.ma.array(a, mask=np.isnan(a)) # Use a mask to mark the NaNs

a_norm  = a / np.sum(a) # The sum function ignores the masked values.
a_norm2 = a / np.std(a) # The std function ignores the masked values.

a.data
```

### Showing Data With Plotly

```{python, eval = FALSE}
# plotly display data

from plotly.tools import FigureFactory as ff
import plotly
import pandas as pd
plotly.offline.init_notebook_mode()
df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_usa_states.csv')
table = ff.create_table(df.iloc[1:10, 1:5])
plotly.offline.plot(table, output_type = 'div', show_link = False, include_plotlyjs = False)
```

### Hyperband Cross Validation

```{python, eval = FALSE}
from civismlext.hyperband import HyperbandSearchCV
#https://github.com/civisanalytics/civisml-extensions/blob/master/civismlext/hyperband.py
```

### Pandas Display Options

```{python, eval = FALSE}
# Display floats with 2 decimal places
pd.options.display.float_format = '{:,.2f}'.format
 
# Expand display limits
pd.options.display.max_rows = 200
pd.options.display.max_columns = 100
```

### Infix Operators

```{python, eval = FALSE}
# Define new operator

class Infix:
    def __init__(self, function):
        self.function = function
    def __ror__(self, other):
        return Infix(lambda x, self = self, other = other: self.function(other, x))
    def __or__(self, other):
        return self.function(other)
    def __rlshift__(self, other):
        return Infix(lambda x, self=self, other=other: self.function(other, x))
    def __rshift__(self, other):
        return self.function(other)
    def __call__(self, value1, value2):
        return self.function(value1, value2)

pipe = Infix(lambda x,y: y(x))
4 |pipe| (lambda z: z**2)
```

### Generators

```{python, eval = FALSE}
# Generators Error

iterator = iter(iterable)
try:
    while True:
        item = next(iterator)
        do_stuff(item)
except StopIteration:
    pass
finally:
    del iterator
```

### Rowwise Operations In Pandas

```{python, eval = FALSE}
# Apply a function to every row in a pandas dataframe

rectangles = [
    { 'height': 40, 'width': 10 },
    { 'height': 20, 'width': 9 },
    { 'height': 3.4, 'width': 4 }
]

rectangles_df = pd.DataFrame(rectangles)

def calculate_area(row):
    return row['height'] * row['width']

rectangles_df.apply(calculate_area, axis=1)

# Apply to single column

df['SAL-RATE'].apply(money_to_float)
```

### Additional Functions Args In Map

```{python, eval = FALSE}
# Extra arguments to function

import functools

def add(x, y):
    return x + y
    
a = [1, 2, 3]
map(functools.partial(add, y=2), a)
```

### Check CSV Encoding

```{python, eval = F}
with open("../input/kickstarter-projects/ks-projects-201801.csv", 'rb') as rawdata:
    result = chardet.detect(rawdata.read(10000))
```

### MNIST Example

```{python, eval = FALSE}
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn import svm

digits = datasets.load_digits()

#print(digits.data)
#print(digits.target)
print(digits.images[0])

clf = svm.SVC(gamma=.001,C=100)
x, y = digits.data[:-10], digits.target[:-10]

clf.fit(x,y)
print("Prediction: ", clf.predict(digits.data[-2].reshape(1, -1)))

plt.imshow(digits.images[-2], cmap=plt.cm.gray_r, interpolation="nearest")
plt.show()
```

## R

### General

* ctrl + shift + a: reformat code in rstudio

* library(rethinking) | data(UCBadmit) | d <- UCBadmit

* purrr::p/map_dfr/c

* date = date %>% as.POSIXct() %>% strptime('%Y-%m-%d') %>% strftime(format="%Y-%m-%d")

* e <- matrix(NA_real_, nrow = 1000, ncol = 8)

* rowwise in R: purrr::pmap

* str_split + unnest()

* https://stat.ethz.ch/R-manual/R-devel/library/base/html/Last.value.html

* na_if: Replace certain values by na

* purrr::map_df - map over columns

* studio multiple cursors, snippets,  addins

* ctrl + shift + o: toggle table of contents

* ctrl shift enter: run chunk

* ctrl pageup/down: navigate chunks

* atl shift k: shortcuts

* ctrl + shift + R: label sections

* ctrl + alt + R: run all chunks

* df_print: kable in yaml rmrkdown header

* rm(list = ls()): Remove all objects in the current workspace

* cut(): Transform a numeric variable into a categorical variable.

* car: recode (good for dummying)

* Examine the objects in the workspace: ls.str()

* This is how you dynamically update a value in Rmarkdown: x = *backtick* r x *backtick*. 

* df[setdiff(names(df), "z")]: remove column z

* purrr::walk

* purr::keep/discard for is.factor

* choroplethr | choroplethrMaps || d3r | d3treeR | data.tree

### Knitting A GHub Doc

output:
  github_document: default
  html_notebook: default
  
## Various

```{r, eval = F}
tapply(Summary_Variable, Group_Variable, Function)

boxplot(frequency ~ attitude*gender,
col=c("white","lightgray"), politeness)

#corrplot package in r
cor(Carseats[sapply(Carseats, function(x) !is.factor(x))])

install.packages(c("caret", "pROC"), dependencies = c("Depends", "Imports", "Suggests"))

library(knitr)
kable(pause_sum, caption = "Summary Statistics Table for Exit Slip Dataset",
      col.names = c("Mean", "Median", "SD", "Min", "Max", "N", "NAs"))

typeof(1) #"double"
typeof(1L) #"integer"

#Prints out the first 4 multiples of 3.
for(i in 1:4*3) {cat(i)}
```

### Create Package

```{r, eval = F}
#https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/

library(devtools)
library(roxygen2)

# Navigate to parent folder
setwd('../Desktop/me')

# Name and create package
create("sansor")

# Add file with function
setwd('sansor/R')
file.create('test.R') # test <- function(){print('This is a test')}

# Back to package dir
setwd("..")

# Generate auto docs
document()

# Install package for use
setwd('..')
install()
```

### Create Operator

```{r, eval = F}
library(stringr)
`%[]%` <- function(string, subset){
  return(str_sub(string, subset[1], subset[2]))
}
'test'%[]%c(1,3)
```

### Useful Date Manipulation

```{r, eval = F}
year = as.integer(format(as.Date(TestEndTime, format="%Y-%m-%d"),"%Y"))
date <- seq(as.Date("2017/09/01"), as.Date("2017/09/25"), by="day")
```

### R for Everything Talk

* dir.exists | dir.create | download.file

* untar | unlink | file.info

* dir | file.rename | file.copy

* count.fields | system

* dplyr five main actions: select, filter, arrange, mutate, summarize.

### Multi Character To Numeric Casting

```{r, eval = F}
char_to_num_cols <- df %>% select(starts_with('MMR')) %>% names
df[, char_to_num_cols] <- sapply(df[, char_to_num_cols], as.numeric)
```


### Grid Plot

```{r, eval=FALSE}
gridExtra::grid.arrange(
  plots[[1]],plots[[2]],plots[[3]],
  plots[[4]],plots[[5]],plots[[6]], nrow=3)
```

### Classification Target Comparison

```{r, eval = FALSE}
chisq.test(table(cut(iris$Sepal.Length, 3), iris$Species))
```

### Pairwise Scatterplot

```{r, eval = FALSE}
GGally::ggpairs(data, mapping = aes(colour = category))
```

### Deploy Shiny App

```{r, eval = F}
library(shinyapps)
library(shiny)

working_dir <- ''
setwd(working_dir)

shinyapps::setAccountInfo(name="<ACCOUNT>", 
                          token="<TOKEN>", 
                          secret="<SECRET>")

runApp()
deployApp()
```

### Tidy Evaluation Example

```{r, eval = F}
# tidy evaluation
df %>%
    filter(
      !is.na((!!as.symbol("col1"))),
      (!!as.symbol("col2")) == 1
      ) %>%
    select(c(1, 2, 4))
```

### Shut Up, R

```{r, eval = F}
#chunk options: echo = F, warning=F, error=F, message=F, results='hide'
```

### EBB

```{r, eval = F}
df_ebb <- df %>%
  summarise(successes = sum(success), sample_size = n()) %>%
  add_ebb_estimate(num_passed, sample_size)
```


### Plotting

Stuff I did while testing Bundesliga xG data.

```{r, eval = F}
library(openxlsx)
library(tidyr)
library(ggplot2)
library(dplyr)
library(ggvis)
library(rCharts)

bund_xg <- read.xlsx("data/bundesliga_xg_2015_2016.xlsx")

bund_xg.long <- gather(bund_xg, Status, Team, Home:Away)
bund_xg.long$xG <- ifelse(bund_xg.long$Status == 'Home', 
                          bund_xg.long$xG_H, 
                          bund_xg.long$xG_A)
bund_xg.long.team <- group_by(bund_xg.long, Team)

xg.plot <-  ggplot(data = bund_xg.long, 
       aes(x = GW, y = xG, group = Status, color = Status)) + 
  geom_point() + 
  geom_line() + 
  labs(title = 'Bundesliga 15/16', x = 'Game Week', y ='Expected Goals For') +
  facet_wrap(~Team)

ggsave(plot = xg.plot, filename = 'bund_xg_plot.png')

bund_xg.long[bund_xg.long$Team == 'Bayern',] %>% 
  ggvis(~GW, ~xG) %>% 
  layer_points() %>% layer_lines()
  #add_tooltip(function(df) df$GW)

p = rPlot(xG ~ GW, 
      data = bund_xg.long[bund_xg.long$Team == 'Bayern',], 
      color = 'Status', 
      type = 'line')

p$set(title = 'Bayern Munich (Bundesliga 15/16)')
p$guides(x = list(title = "Game Week"))
p$guides(y = list(title = "Expected Goals"))
```

### Nested Tree

Stuff I did while testing tree viz for ODSC DS tools.

```{r, eval = FALSE}
library(googleVis)
test.data <- read.csv('C:/Users/Gordon/Downloads/test.csv', header = T)

Org <- gvisOrgChart(test.data, 
                    options=list(width=600, height=250,
                                 size='large', allowCollapse=TRUE))
Org$html$footer  <- NULL
Org$html$caption  <- NULL
plot(Org)

test.data$Val  <- seq(1, nrow(test.data), 1)
test.data$Fac  <- seq(1, nrow(test.data), 1)

Tree <- gvisTreeMap(test.data,  
                    "Node", "Parent", 
                    #"Val", "Fac", 
                    options=list(fontSize=16))
plot(Tree)
```

### Setup Project

```{r, eval = F}
library(knitr)

#Create top level folder
dir.create('my-data-project')
setwd('./my-data-project/')

#Create child folders
dir.create('code')
dir.create('visualizations')
dir.create('reports')
dir.create('data')
dir.create('deploy_maintain')

#Create trackers
file.create('README.md')
file.create('CHANGELOG.md')

#Create grandchildren folders for data
setwd('./data')
dir.create('raw')
dir.create('refined')

#Create grandchildren folders for visualizations
setwd('../visualizations')
dir.create('exploratory')
dir.create('communication')

#Initialize git repo
git2r::init('.')

# CHANGELOG.md Example

## Logs

## Excluded processes should be assumed to be the same as version 0.1.

## Current Best Model:
## Current Best Score / Metric:

## 0.1

## 1_import_tidy.Rmd

## 2_transform_visualize.Rmd

## 3_modeling.ipynb

# Layout

## libs, functions, imports, preprocessing, feature engineering, feature selection, model building

```

### MAP Model

```{r, eval = FALSE}
library(tidyverse)

model <- function(df) {
  lm(mpg ~ ., data = df)
}

df <- mtcars
df %>% group_by(cyl) %>% split(.$cyl) %>% purrr::map(~ lm(mpg ~ ., data = .))
df %>% group_by(cyl) %>% nest() %>% mutate(model = map(data, model))

chickweight %>% group_by(Diet) %>% nest() %>% 
mutate(mod = data %>% map(~ lm(weight ~ Time, data=.)))
```

### DT Options

```{r, eval = FALSE}
datatable(
  df_version_check,
  options = list(filter = 'top',
                 searching = T,
                 pageLength = 10, lengthChange = FALSE, ordering = FALSE,
                 scrollCollapse = T,
                 scrollY = '1500',
                 paging = T
                 )
  )
```

### Plotly MAP

```{r, eval=F}
ggplotly(
    ggplot(df_master2 %>% filter(skl_group==x),
       aes(SkillId, correct_rate, label = Master, color = SkillId)) +
  geom_jitter(width = .2),
    tooltip = c('y', 'label')
    )
```

### Pipe Anonymous Function

```{r,eval = F}
data %>%
  (function(input.object) {
    complex
    logic
    goes
    here
    output.object
  })
```

### Binarize  Predictions

```{r, eval = F}
clf_lr_final <- clf_lr$finalModel
model_tidy <- broom::tidy(clf_lr_final)
df2$pass_predicted <- as.factor(
  ifelse(clf_lr_final$fitted.values >= .5, 'pass', 'fail')
  )
metrics(df2, pass, pass_predicted)

var_imp <- varImp(clf_lr_final) %>% mutate(cols = row.names(.)) %>% arrange(-Overall) %>% select(cols, Overall)
var_imp
```

### Make Formula

```{r}
make_formula <- function(target, additions, subtractions = NULL, powers = NULL){
  
  add_sub_sep = ifelse(is.null(subtractions), '', '-')
  add <- paste0(additions, collapse = ' + ')
  subtract <- paste0(subtractions, collapse = ' - ')
  add_subtract <- paste(add, subtract, sep = add_sub_sep)
  
  return(as.formula(paste(target, add_subtract, sep = '~')))
  
}
```

### Shiny Reactive

```{r, eval = FALSE}
df_labeled = eventReactive({c(input$good, input$bad)}, {    
    df %>% filter(value == input$value)
  })
```

### Custom Theme

```{r, eval=F}
theme(
     axis.text.y = element_text(angle = 65, vjust = 0.6),
     axis.title.x = element_blank(),
     panel.background = element_blank()
     )
```

### Create Factor

```{r, eval=F}
mons = factor(
   c("August","September", "October","November",
           "December", "January","February","March",
               "April","May","June","July"),
  levels = c("August","September", "October","November",
           "December", "January","February","March",
               "April","May","June","July"),
  ordered = TRUE)
```

### Extract Date

```{r, eval = F}
StartTime %>% as.POSIXct() %>% strftime(format="%Y-%m-%d")
YearMonth = Day %>% strftime(format="%Y-%m")
```

### Geom_Path

```{r, eval=F}
ggplot(ilo_data) +
  geom_path(
            aes(x = working_hours, y = country),
            arrow = arrow(length = unit(1.5, "mm"), type = "closed")
)
```

### Theme Template

```{r, eval = F}
theme_ilo <- function() {
  theme_minimal() +
  theme(
    text = element_text(family = "Bookman", color = "gray25"),
    plot.subtitle = element_text(size = 12),
    plot.caption = element_text(color = "gray30"),
    plot.background = element_rect(fill = "gray95"),
    plot.margin = unit(c(5, 10, 5, 10), units = "mm")
  )
}
```

### Heatmap

```{r, eval = F}
library(corrplot)
df_fltrd %>% select_if(is.numeric) %>%  
cor() %>% corrplot(method = "circle", is.corr = FALSE)
```

### Calculate Accuracy

```{r, eval = FALSE}
calc_accuracy <- function(labels, preds){
  
  results <- table(labels, preds) %>% 
    data.frame %>%
    mutate(correct = ifelse(labels==preds, 1, 0)) %>%
    group_by(correct) %>% 
    summarise(freq = sum(Freq)) %>% 
    ungroup() %>%
    mutate(prop = freq/sum(freq)) %>%
    filter(correct == 1)
  
  return(results)

}
```

### Replace NA

```{r, eval=F}
df %>% replace_na(list(x = 0, y = "unknown"))
df2 %>% replace(., is.na(.), "")
```

### Filter By Row

```{r, eval = FALSE}
df %>%
  filter(
    !grepl('Schedules', issues)
  )
```

### DB Functions

```{r, eval = FALSE}
# DB Functions

data <- dbGetQuery(con, 'select * from iris')
dbListTables(con) %>% sort
dbExistsTable(con, "iris")
dbRemoveTable(con, "iris")
```

### Knitr

```{r, eval = F}
knitr::include_graphics(rep("./assets/ml_trading/portfolio.png", 3))
```

## Bash

script to do joining of dummied csvs

```{bash, eval = F}
paste -d=',' file1.csv file2.csv file3.csv > file_final.csv
```

