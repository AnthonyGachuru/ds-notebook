<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A Minimal Book Example</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="A Minimal Book Example" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Minimal Book Example" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Yihui Xie">


<meta name="date" content="2018-04-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="model.html">
<link rel="next" href="cdm.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>2</b> Workflow</a></li>
<li class="chapter" data-level="3" data-path="preamble.html"><a href="preamble.html"><i class="fa fa-check"></i><b>3</b> Preamble</a></li>
<li class="chapter" data-level="4" data-path="annotated-checklist.html"><a href="annotated-checklist.html"><i class="fa fa-check"></i><b>4</b> Annotated Checklist</a><ul>
<li class="chapter" data-level="4.1" data-path="annotated-checklist.html"><a href="annotated-checklist.html#preparation"><i class="fa fa-check"></i><b>4.1</b> Preparation</a></li>
<li class="chapter" data-level="4.2" data-path="annotated-checklist.html"><a href="annotated-checklist.html#import"><i class="fa fa-check"></i><b>4.2</b> Import</a></li>
<li class="chapter" data-level="4.3" data-path="annotated-checklist.html"><a href="annotated-checklist.html#tidy"><i class="fa fa-check"></i><b>4.3</b> Tidy</a></li>
<li class="chapter" data-level="4.4" data-path="annotated-checklist.html"><a href="annotated-checklist.html#utransform"><i class="fa fa-check"></i><b>4.4</b> uTransform</a></li>
<li class="chapter" data-level="4.5" data-path="annotated-checklist.html"><a href="annotated-checklist.html#uvisualize"><i class="fa fa-check"></i><b>4.5</b> uVisualize</a></li>
<li class="chapter" data-level="4.6" data-path="annotated-checklist.html"><a href="annotated-checklist.html#umodel"><i class="fa fa-check"></i><b>4.6</b> uModel</a></li>
<li class="chapter" data-level="4.7" data-path="annotated-checklist.html"><a href="annotated-checklist.html#communicate"><i class="fa fa-check"></i><b>4.7</b> Communicate</a></li>
<li class="chapter" data-level="4.8" data-path="annotated-checklist.html"><a href="annotated-checklist.html#deployment-maintenance"><i class="fa fa-check"></i><b>4.8</b> Deployment / Maintenance</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="import-tidy.html"><a href="import-tidy.html"><i class="fa fa-check"></i><b>5</b> Import &amp; Tidy</a><ul>
<li class="chapter" data-level="5.1" data-path="import-tidy.html"><a href="import-tidy.html#general"><i class="fa fa-check"></i><b>5.1</b> General</a></li>
<li class="chapter" data-level="5.2" data-path="import-tidy.html"><a href="import-tidy.html#sql"><i class="fa fa-check"></i><b>5.2</b> SQL</a></li>
<li class="chapter" data-level="5.3" data-path="import-tidy.html"><a href="import-tidy.html#scraping"><i class="fa fa-check"></i><b>5.3</b> Scraping</a></li>
<li class="chapter" data-level="5.4" data-path="import-tidy.html"><a href="import-tidy.html#exploration"><i class="fa fa-check"></i><b>5.4</b> Exploration</a></li>
<li class="chapter" data-level="5.5" data-path="import-tidy.html"><a href="import-tidy.html#general-1"><i class="fa fa-check"></i><b>5.5</b> General</a></li>
<li class="chapter" data-level="5.6" data-path="import-tidy.html"><a href="import-tidy.html#missingness-imputation"><i class="fa fa-check"></i><b>5.6</b> Missingness &amp; Imputation</a></li>
<li class="chapter" data-level="5.7" data-path="import-tidy.html"><a href="import-tidy.html#data-table"><i class="fa fa-check"></i><b>5.7</b> Data Table</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="transform-visualize.html"><a href="transform-visualize.html"><i class="fa fa-check"></i><b>6</b> Transform &amp; Visualize</a><ul>
<li class="chapter" data-level="6.1" data-path="transform-visualize.html"><a href="transform-visualize.html#transform"><i class="fa fa-check"></i><b>6.1</b> Transform</a></li>
<li class="chapter" data-level="6.2" data-path="transform-visualize.html"><a href="transform-visualize.html#visualize"><i class="fa fa-check"></i><b>6.2</b> Visualize</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="model.html"><a href="model.html"><i class="fa fa-check"></i><b>7</b> Model</a><ul>
<li class="chapter" data-level="7.1" data-path="model.html"><a href="model.html#feature-selection"><i class="fa fa-check"></i><b>7.1</b> Feature Selection</a></li>
<li class="chapter" data-level="7.2" data-path="model.html"><a href="model.html#feature-engineering"><i class="fa fa-check"></i><b>7.2</b> Feature Engineering</a></li>
<li class="chapter" data-level="7.3" data-path="model.html"><a href="model.html#model-selection"><i class="fa fa-check"></i><b>7.3</b> Model Selection</a></li>
<li class="chapter" data-level="7.4" data-path="model.html"><a href="model.html#unbalanced-classes"><i class="fa fa-check"></i><b>7.4</b> Unbalanced Classes</a></li>
<li class="chapter" data-level="7.5" data-path="model.html"><a href="model.html#other"><i class="fa fa-check"></i><b>7.5</b> Other</a></li>
<li class="chapter" data-level="7.6" data-path="model.html"><a href="model.html#bayesian"><i class="fa fa-check"></i><b>7.6</b> Bayesian</a></li>
<li class="chapter" data-level="7.7" data-path="model.html"><a href="model.html#naive-bayes"><i class="fa fa-check"></i><b>7.7</b> Naïve Bayes</a><ul>
<li class="chapter" data-level="7.7.1" data-path="model.html"><a href="model.html#intro"><i class="fa fa-check"></i><b>7.7.1</b> Intro</a></li>
<li class="chapter" data-level="7.7.2" data-path="model.html"><a href="model.html#assumptions"><i class="fa fa-check"></i><b>7.7.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.7.3" data-path="model.html"><a href="model.html#characteristics"><i class="fa fa-check"></i><b>7.7.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.7.4" data-path="model.html"><a href="model.html#evaluation"><i class="fa fa-check"></i><b>7.7.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.7.5" data-path="model.html"><a href="model.html#proscons"><i class="fa fa-check"></i><b>7.7.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="model.html"><a href="model.html#lda"><i class="fa fa-check"></i><b>7.8</b> LDA</a><ul>
<li class="chapter" data-level="7.8.1" data-path="model.html"><a href="model.html#intro-1"><i class="fa fa-check"></i><b>7.8.1</b> Intro</a></li>
<li class="chapter" data-level="7.8.2" data-path="model.html"><a href="model.html#assumptions-1"><i class="fa fa-check"></i><b>7.8.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.8.3" data-path="model.html"><a href="model.html#characteristics-1"><i class="fa fa-check"></i><b>7.8.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.8.4" data-path="model.html"><a href="model.html#evaluation-1"><i class="fa fa-check"></i><b>7.8.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.8.5" data-path="model.html"><a href="model.html#proscons-1"><i class="fa fa-check"></i><b>7.8.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="model.html"><a href="model.html#qda"><i class="fa fa-check"></i><b>7.9</b> QDA</a><ul>
<li class="chapter" data-level="7.9.1" data-path="model.html"><a href="model.html#intro-2"><i class="fa fa-check"></i><b>7.9.1</b> Intro</a></li>
<li class="chapter" data-level="7.9.2" data-path="model.html"><a href="model.html#assumptions-2"><i class="fa fa-check"></i><b>7.9.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.9.3" data-path="model.html"><a href="model.html#characteristics-2"><i class="fa fa-check"></i><b>7.9.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.9.4" data-path="model.html"><a href="model.html#evaluation-2"><i class="fa fa-check"></i><b>7.9.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.9.5" data-path="model.html"><a href="model.html#proscons-2"><i class="fa fa-check"></i><b>7.9.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="model.html"><a href="model.html#advanced-bayesian"><i class="fa fa-check"></i><b>7.10</b> Advanced Bayesian</a></li>
<li class="chapter" data-level="7.11" data-path="model.html"><a href="model.html#clustering"><i class="fa fa-check"></i><b>7.11</b> Clustering</a></li>
<li class="chapter" data-level="7.12" data-path="model.html"><a href="model.html#k-means"><i class="fa fa-check"></i><b>7.12</b> K-Means</a><ul>
<li class="chapter" data-level="7.12.1" data-path="model.html"><a href="model.html#intro-3"><i class="fa fa-check"></i><b>7.12.1</b> Intro</a></li>
<li class="chapter" data-level="7.12.2" data-path="model.html"><a href="model.html#assumptions-3"><i class="fa fa-check"></i><b>7.12.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.12.3" data-path="model.html"><a href="model.html#characteristics-3"><i class="fa fa-check"></i><b>7.12.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.12.4" data-path="model.html"><a href="model.html#evaluation-3"><i class="fa fa-check"></i><b>7.12.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.12.5" data-path="model.html"><a href="model.html#proscons-3"><i class="fa fa-check"></i><b>7.12.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="model.html"><a href="model.html#hierarchical-clustering"><i class="fa fa-check"></i><b>7.13</b> Hierarchical Clustering</a><ul>
<li class="chapter" data-level="7.13.1" data-path="model.html"><a href="model.html#intro-4"><i class="fa fa-check"></i><b>7.13.1</b> Intro</a></li>
<li class="chapter" data-level="7.13.2" data-path="model.html"><a href="model.html#assumptions-4"><i class="fa fa-check"></i><b>7.13.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.13.3" data-path="model.html"><a href="model.html#characteristics-4"><i class="fa fa-check"></i><b>7.13.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.13.4" data-path="model.html"><a href="model.html#evaluation-4"><i class="fa fa-check"></i><b>7.13.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.13.5" data-path="model.html"><a href="model.html#proscons-4"><i class="fa fa-check"></i><b>7.13.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.14" data-path="model.html"><a href="model.html#pca"><i class="fa fa-check"></i><b>7.14</b> PCA</a><ul>
<li class="chapter" data-level="7.14.1" data-path="model.html"><a href="model.html#intro-5"><i class="fa fa-check"></i><b>7.14.1</b> Intro</a></li>
<li class="chapter" data-level="7.14.2" data-path="model.html"><a href="model.html#assumptions-5"><i class="fa fa-check"></i><b>7.14.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.14.3" data-path="model.html"><a href="model.html#characteristics-5"><i class="fa fa-check"></i><b>7.14.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.14.4" data-path="model.html"><a href="model.html#evaluation-5"><i class="fa fa-check"></i><b>7.14.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.14.5" data-path="model.html"><a href="model.html#proscons-5"><i class="fa fa-check"></i><b>7.14.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.15" data-path="model.html"><a href="model.html#linear-regression"><i class="fa fa-check"></i><b>7.15</b> Linear Regression</a><ul>
<li class="chapter" data-level="7.15.1" data-path="model.html"><a href="model.html#intro-6"><i class="fa fa-check"></i><b>7.15.1</b> Intro</a></li>
<li class="chapter" data-level="7.15.2" data-path="model.html"><a href="model.html#assumptions-6"><i class="fa fa-check"></i><b>7.15.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.15.3" data-path="model.html"><a href="model.html#evaluation-6"><i class="fa fa-check"></i><b>7.15.3</b> Evaluation</a></li>
<li class="chapter" data-level="7.15.4" data-path="model.html"><a href="model.html#proscons-6"><i class="fa fa-check"></i><b>7.15.4</b> Pros/Cons</a></li>
<li class="chapter" data-level="7.15.5" data-path="model.html"><a href="model.html#code-examples"><i class="fa fa-check"></i><b>7.15.5</b> Code Examples</a></li>
</ul></li>
<li class="chapter" data-level="7.16" data-path="model.html"><a href="model.html#ridgelasso"><i class="fa fa-check"></i><b>7.16</b> Ridge/Lasso</a><ul>
<li class="chapter" data-level="7.16.1" data-path="model.html"><a href="model.html#intro-7"><i class="fa fa-check"></i><b>7.16.1</b> Intro</a></li>
<li class="chapter" data-level="7.16.2" data-path="model.html"><a href="model.html#assumptions-7"><i class="fa fa-check"></i><b>7.16.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.16.3" data-path="model.html"><a href="model.html#evaluation-7"><i class="fa fa-check"></i><b>7.16.3</b> Evaluation</a></li>
<li class="chapter" data-level="7.16.4" data-path="model.html"><a href="model.html#proscons-7"><i class="fa fa-check"></i><b>7.16.4</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.17" data-path="model.html"><a href="model.html#logistic-regression"><i class="fa fa-check"></i><b>7.17</b> Logistic Regression</a><ul>
<li class="chapter" data-level="7.17.1" data-path="model.html"><a href="model.html#intro-8"><i class="fa fa-check"></i><b>7.17.1</b> Intro</a></li>
<li class="chapter" data-level="7.17.2" data-path="model.html"><a href="model.html#assumptions-8"><i class="fa fa-check"></i><b>7.17.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.17.3" data-path="model.html"><a href="model.html#evaluation-8"><i class="fa fa-check"></i><b>7.17.3</b> Evaluation</a></li>
<li class="chapter" data-level="7.17.4" data-path="model.html"><a href="model.html#proscons-8"><i class="fa fa-check"></i><b>7.17.4</b> Pros/Cons</a></li>
<li class="chapter" data-level="7.17.5" data-path="model.html"><a href="model.html#code-example"><i class="fa fa-check"></i><b>7.17.5</b> Code Example</a></li>
</ul></li>
<li class="chapter" data-level="7.18" data-path="model.html"><a href="model.html#poisson-regression"><i class="fa fa-check"></i><b>7.18</b> Poisson Regression</a><ul>
<li class="chapter" data-level="7.18.1" data-path="model.html"><a href="model.html#intro-9"><i class="fa fa-check"></i><b>7.18.1</b> Intro</a></li>
<li class="chapter" data-level="7.18.2" data-path="model.html"><a href="model.html#assumptions-9"><i class="fa fa-check"></i><b>7.18.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.18.3" data-path="model.html"><a href="model.html#evaluation-9"><i class="fa fa-check"></i><b>7.18.3</b> Evaluation</a></li>
<li class="chapter" data-level="7.18.4" data-path="model.html"><a href="model.html#proscons-9"><i class="fa fa-check"></i><b>7.18.4</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.19" data-path="model.html"><a href="model.html#generalized-additive-models"><i class="fa fa-check"></i><b>7.19</b> Generalized Additive Models</a><ul>
<li class="chapter" data-level="7.19.1" data-path="model.html"><a href="model.html#intro-10"><i class="fa fa-check"></i><b>7.19.1</b> Intro</a></li>
<li class="chapter" data-level="7.19.2" data-path="model.html"><a href="model.html#assumptions-10"><i class="fa fa-check"></i><b>7.19.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.19.3" data-path="model.html"><a href="model.html#evaluation-10"><i class="fa fa-check"></i><b>7.19.3</b> Evaluation</a></li>
<li class="chapter" data-level="7.19.4" data-path="model.html"><a href="model.html#proscons-10"><i class="fa fa-check"></i><b>7.19.4</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.20" data-path="model.html"><a href="model.html#knn"><i class="fa fa-check"></i><b>7.20</b> KNN</a><ul>
<li class="chapter" data-level="7.20.1" data-path="model.html"><a href="model.html#intro-11"><i class="fa fa-check"></i><b>7.20.1</b> Intro</a></li>
<li class="chapter" data-level="7.20.2" data-path="model.html"><a href="model.html#assumptions-11"><i class="fa fa-check"></i><b>7.20.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.20.3" data-path="model.html"><a href="model.html#characteristics-6"><i class="fa fa-check"></i><b>7.20.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.20.4" data-path="model.html"><a href="model.html#evaluation-11"><i class="fa fa-check"></i><b>7.20.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.20.5" data-path="model.html"><a href="model.html#proscons-11"><i class="fa fa-check"></i><b>7.20.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.21" data-path="model.html"><a href="model.html#svm"><i class="fa fa-check"></i><b>7.21</b> SVM</a><ul>
<li class="chapter" data-level="7.21.1" data-path="model.html"><a href="model.html#intro-12"><i class="fa fa-check"></i><b>7.21.1</b> Intro</a></li>
<li class="chapter" data-level="7.21.2" data-path="model.html"><a href="model.html#assumptions-12"><i class="fa fa-check"></i><b>7.21.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.21.3" data-path="model.html"><a href="model.html#characteristics-7"><i class="fa fa-check"></i><b>7.21.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.21.4" data-path="model.html"><a href="model.html#evaluation-12"><i class="fa fa-check"></i><b>7.21.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.21.5" data-path="model.html"><a href="model.html#proscons-12"><i class="fa fa-check"></i><b>7.21.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.22" data-path="model.html"><a href="model.html#decision-tree"><i class="fa fa-check"></i><b>7.22</b> Decision Tree</a><ul>
<li class="chapter" data-level="7.22.1" data-path="model.html"><a href="model.html#intro-13"><i class="fa fa-check"></i><b>7.22.1</b> Intro</a></li>
<li class="chapter" data-level="7.22.2" data-path="model.html"><a href="model.html#assumptions-13"><i class="fa fa-check"></i><b>7.22.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.22.3" data-path="model.html"><a href="model.html#characteristics-8"><i class="fa fa-check"></i><b>7.22.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.22.4" data-path="model.html"><a href="model.html#evaluation-13"><i class="fa fa-check"></i><b>7.22.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.22.5" data-path="model.html"><a href="model.html#proscons-13"><i class="fa fa-check"></i><b>7.22.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.23" data-path="model.html"><a href="model.html#bagging"><i class="fa fa-check"></i><b>7.23</b> Bagging</a><ul>
<li class="chapter" data-level="7.23.1" data-path="model.html"><a href="model.html#intro-14"><i class="fa fa-check"></i><b>7.23.1</b> Intro</a></li>
<li class="chapter" data-level="7.23.2" data-path="model.html"><a href="model.html#assumptions-14"><i class="fa fa-check"></i><b>7.23.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.23.3" data-path="model.html"><a href="model.html#characteristics-9"><i class="fa fa-check"></i><b>7.23.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.23.4" data-path="model.html"><a href="model.html#evaluation-14"><i class="fa fa-check"></i><b>7.23.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.23.5" data-path="model.html"><a href="model.html#proscons-14"><i class="fa fa-check"></i><b>7.23.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.24" data-path="model.html"><a href="model.html#random-forest"><i class="fa fa-check"></i><b>7.24</b> Random Forest</a><ul>
<li class="chapter" data-level="7.24.1" data-path="model.html"><a href="model.html#intro-15"><i class="fa fa-check"></i><b>7.24.1</b> Intro</a></li>
<li class="chapter" data-level="7.24.2" data-path="model.html"><a href="model.html#assumptions-15"><i class="fa fa-check"></i><b>7.24.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.24.3" data-path="model.html"><a href="model.html#characteristics-10"><i class="fa fa-check"></i><b>7.24.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.24.4" data-path="model.html"><a href="model.html#evaluation-15"><i class="fa fa-check"></i><b>7.24.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.24.5" data-path="model.html"><a href="model.html#proscons-15"><i class="fa fa-check"></i><b>7.24.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.25" data-path="model.html"><a href="model.html#boosting"><i class="fa fa-check"></i><b>7.25</b> Boosting</a><ul>
<li class="chapter" data-level="7.25.1" data-path="model.html"><a href="model.html#intro-16"><i class="fa fa-check"></i><b>7.25.1</b> Intro</a></li>
<li class="chapter" data-level="7.25.2" data-path="model.html"><a href="model.html#assumptions-16"><i class="fa fa-check"></i><b>7.25.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.25.3" data-path="model.html"><a href="model.html#characteristics-11"><i class="fa fa-check"></i><b>7.25.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.25.4" data-path="model.html"><a href="model.html#evaluation-16"><i class="fa fa-check"></i><b>7.25.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.25.5" data-path="model.html"><a href="model.html#proscons-16"><i class="fa fa-check"></i><b>7.25.5</b> Pros/Cons</a></li>
</ul></li>
<li class="chapter" data-level="7.26" data-path="model.html"><a href="model.html#nlp"><i class="fa fa-check"></i><b>7.26</b> NLP</a></li>
<li class="chapter" data-level="7.27" data-path="model.html"><a href="model.html#topic-modeling"><i class="fa fa-check"></i><b>7.27</b> Topic Modeling</a></li>
<li class="chapter" data-level="7.28" data-path="model.html"><a href="model.html#recommendation-systems"><i class="fa fa-check"></i><b>7.28</b> Recommendation Systems</a></li>
<li class="chapter" data-level="7.29" data-path="model.html"><a href="model.html#time-series"><i class="fa fa-check"></i><b>7.29</b> Time Series</a><ul>
<li class="chapter" data-level="7.29.1" data-path="model.html"><a href="model.html#intro-17"><i class="fa fa-check"></i><b>7.29.1</b> Intro</a></li>
<li class="chapter" data-level="7.29.2" data-path="model.html"><a href="model.html#assumptions-17"><i class="fa fa-check"></i><b>7.29.2</b> Assumptions</a></li>
<li class="chapter" data-level="7.29.3" data-path="model.html"><a href="model.html#characteristics-12"><i class="fa fa-check"></i><b>7.29.3</b> Characteristics</a></li>
<li class="chapter" data-level="7.29.4" data-path="model.html"><a href="model.html#evaluation-17"><i class="fa fa-check"></i><b>7.29.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.29.5" data-path="model.html"><a href="model.html#proscons-17"><i class="fa fa-check"></i><b>7.29.5</b> Pros/Cons</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html"><i class="fa fa-check"></i><b>8</b> Udacity: TS Fundamentals</a><ul>
<li class="chapter" data-level="8.1" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#dl"><i class="fa fa-check"></i><b>8.1</b> DL</a></li>
<li class="chapter" data-level="8.2" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#tensorflow"><i class="fa fa-check"></i><b>8.2</b> TensorFlow</a></li>
<li class="chapter" data-level="8.3" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#keras"><i class="fa fa-check"></i><b>8.3</b> Keras</a><ul>
<li class="chapter" data-level="8.3.1" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#regression"><i class="fa fa-check"></i><b>8.3.1</b> Regression</a></li>
<li class="chapter" data-level="8.3.2" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#classification"><i class="fa fa-check"></i><b>8.3.2</b> Classification</a></li>
<li class="chapter" data-level="8.3.3" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#another-example"><i class="fa fa-check"></i><b>8.3.3</b> Another Example</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#association-rule-mining"><i class="fa fa-check"></i><b>8.4</b> Association Rule Mining</a><ul>
<li class="chapter" data-level="8.4.1" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#intro-18"><i class="fa fa-check"></i><b>8.4.1</b> Intro</a></li>
<li class="chapter" data-level="8.4.2" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#assumptions-18"><i class="fa fa-check"></i><b>8.4.2</b> Assumptions</a></li>
<li class="chapter" data-level="8.4.3" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#characteristics-13"><i class="fa fa-check"></i><b>8.4.3</b> Characteristics</a></li>
<li class="chapter" data-level="8.4.4" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#evaluation-18"><i class="fa fa-check"></i><b>8.4.4</b> Evaluation</a></li>
<li class="chapter" data-level="8.4.5" data-path="udacity-ts-fundamentals.html"><a href="udacity-ts-fundamentals.html#proscons-18"><i class="fa fa-check"></i><b>8.4.5</b> Pros/Cons</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="cdm.html"><a href="cdm.html"><i class="fa fa-check"></i><b>9</b> CDM</a><ul>
<li class="chapter" data-level="9.1" data-path="cdm.html"><a href="cdm.html#shiny"><i class="fa fa-check"></i><b>9.1</b> Shiny</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="frameworks.html"><a href="frameworks.html"><i class="fa fa-check"></i>Frameworks</a><ul>
<li class="chapter" data-level="9.2" data-path="frameworks.html"><a href="frameworks.html#pyspark"><i class="fa fa-check"></i><b>9.2</b> PySpark</a></li>
<li class="chapter" data-level="9.3" data-path="frameworks.html"><a href="frameworks.html#sparklyr"><i class="fa fa-check"></i><b>9.3</b> Sparklyr</a></li>
<li class="chapter" data-level="9.4" data-path="frameworks.html"><a href="frameworks.html#caret"><i class="fa fa-check"></i><b>9.4</b> Caret</a></li>
<li class="chapter" data-level="9.5" data-path="frameworks.html"><a href="frameworks.html#preprocessing"><i class="fa fa-check"></i><b>9.5</b> Preprocessing</a></li>
<li class="chapter" data-level="9.6" data-path="frameworks.html"><a href="frameworks.html#lm"><i class="fa fa-check"></i><b>9.6</b> LM</a></li>
<li class="chapter" data-level="9.7" data-path="frameworks.html"><a href="frameworks.html#lassoridge"><i class="fa fa-check"></i><b>9.7</b> Lasso/Ridge</a></li>
<li class="chapter" data-level="9.8" data-path="frameworks.html"><a href="frameworks.html#logreg"><i class="fa fa-check"></i><b>9.8</b> LogReg</a></li>
<li class="chapter" data-level="9.9" data-path="frameworks.html"><a href="frameworks.html#train-test-split-folds-cv"><i class="fa fa-check"></i><b>9.9</b> Train-Test Split, Folds, &amp; CV</a></li>
<li class="chapter" data-level="9.10" data-path="frameworks.html"><a href="frameworks.html#random-forest-1"><i class="fa fa-check"></i><b>9.10</b> Random Forest</a></li>
<li class="chapter" data-level="9.11" data-path="frameworks.html"><a href="frameworks.html#svm-1"><i class="fa fa-check"></i><b>9.11</b> SVM</a></li>
<li class="chapter" data-level="9.12" data-path="frameworks.html"><a href="frameworks.html#model-selection-1"><i class="fa fa-check"></i><b>9.12</b> Model Selection</a></li>
<li class="chapter" data-level="9.13" data-path="frameworks.html"><a href="frameworks.html#stacking"><i class="fa fa-check"></i><b>9.13</b> Stacking</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="code-snippets.html"><a href="code-snippets.html"><i class="fa fa-check"></i>Code Snippets</a><ul>
<li class="chapter" data-level="9.14" data-path="code-snippets.html"><a href="code-snippets.html#python"><i class="fa fa-check"></i><b>9.14</b> Python</a><ul>
<li class="chapter" data-level="9.14.1" data-path="code-snippets.html"><a href="code-snippets.html#check-csv-encoding"><i class="fa fa-check"></i><b>9.14.1</b> Check CSV Encoding</a></li>
<li class="chapter" data-level="9.14.2" data-path="code-snippets.html"><a href="code-snippets.html#mnist-example"><i class="fa fa-check"></i><b>9.14.2</b> MNIST Example</a></li>
</ul></li>
<li class="chapter" data-level="9.15" data-path="code-snippets.html"><a href="code-snippets.html#r"><i class="fa fa-check"></i><b>9.15</b> R</a></li>
<li class="chapter" data-level="9.16" data-path="code-snippets.html"><a href="code-snippets.html#shiny-reactive"><i class="fa fa-check"></i><b>9.16</b> Shiny Reactive</a></li>
<li class="chapter" data-level="9.17" data-path="code-snippets.html"><a href="code-snippets.html#custom-theme"><i class="fa fa-check"></i><b>9.17</b> Custom Theme</a></li>
<li class="chapter" data-level="9.18" data-path="code-snippets.html"><a href="code-snippets.html#create-factor"><i class="fa fa-check"></i><b>9.18</b> Create Factor</a><ul>
<li class="chapter" data-level="9.18.1" data-path="code-snippets.html"><a href="code-snippets.html#extract-date"><i class="fa fa-check"></i><b>9.18.1</b> Extract Date</a></li>
<li class="chapter" data-level="9.18.2" data-path="code-snippets.html"><a href="code-snippets.html#geom_path"><i class="fa fa-check"></i><b>9.18.2</b> Geom_Path</a></li>
<li class="chapter" data-level="9.18.3" data-path="code-snippets.html"><a href="code-snippets.html#theme-template"><i class="fa fa-check"></i><b>9.18.3</b> Theme Template</a></li>
<li class="chapter" data-level="9.18.4" data-path="code-snippets.html"><a href="code-snippets.html#heatmap"><i class="fa fa-check"></i><b>9.18.4</b> Heatmap</a></li>
<li class="chapter" data-level="9.18.5" data-path="code-snippets.html"><a href="code-snippets.html#calculate-accuracy"><i class="fa fa-check"></i><b>9.18.5</b> Calculate Accuracy</a></li>
<li class="chapter" data-level="9.18.6" data-path="code-snippets.html"><a href="code-snippets.html#replace-na"><i class="fa fa-check"></i><b>9.18.6</b> Replace NA</a></li>
<li class="chapter" data-level="9.18.7" data-path="code-snippets.html"><a href="code-snippets.html#filter-by-row"><i class="fa fa-check"></i><b>9.18.7</b> Filter By Row</a></li>
<li class="chapter" data-level="9.18.8" data-path="code-snippets.html"><a href="code-snippets.html#db-functions"><i class="fa fa-check"></i><b>9.18.8</b> DB Functions</a></li>
</ul></li>
<li class="chapter" data-level="9.19" data-path="code-snippets.html"><a href="code-snippets.html#knitr"><i class="fa fa-check"></i><b>9.19</b> Knitr</a></li>
<li class="chapter" data-level="9.20" data-path="code-snippets.html"><a href="code-snippets.html#bash"><i class="fa fa-check"></i><b>9.20</b> Bash</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-2.html"><a href="general-2.html"><i class="fa fa-check"></i>General</a><ul>
<li class="chapter" data-level="9.21" data-path="general-2.html"><a href="general-2.html#python-1"><i class="fa fa-check"></i><b>9.21</b> Python</a></li>
<li class="chapter" data-level="9.22" data-path="general-2.html"><a href="general-2.html#r-1"><i class="fa fa-check"></i><b>9.22</b> R</a></li>
<li class="chapter" data-level="9.23" data-path="general-2.html"><a href="general-2.html#git"><i class="fa fa-check"></i><b>9.23</b> Git</a></li>
<li class="chapter" data-level="9.24" data-path="general-2.html"><a href="general-2.html#other-1"><i class="fa fa-check"></i><b>9.24</b> Other</a></li>
<li class="chapter" data-level="9.25" data-path="general-2.html"><a href="general-2.html#yaml"><i class="fa fa-check"></i><b>9.25</b> YAML</a></li>
<li class="chapter" data-level="9.26" data-path="general-2.html"><a href="general-2.html#ab-testing-overview"><i class="fa fa-check"></i><b>9.26</b> AB Testing Overview</a></li>
<li class="chapter" data-level="9.27" data-path="general-2.html"><a href="general-2.html#designing-an-experiment"><i class="fa fa-check"></i><b>9.27</b> Designing An Experiment</a></li>
<li class="chapter" data-level="9.28" data-path="general-2.html"><a href="general-2.html#networks"><i class="fa fa-check"></i><b>9.28</b> Networks</a></li>
<li class="chapter" data-level="9.29" data-path="general-2.html"><a href="general-2.html#networkx"><i class="fa fa-check"></i><b>9.29</b> Networkx</a></li>
<li class="chapter" data-level="9.30" data-path="general-2.html"><a href="general-2.html#stats"><i class="fa fa-check"></i><b>9.30</b> Stats</a><ul>
<li class="chapter" data-level="9.30.1" data-path="general-2.html"><a href="general-2.html#infer-package"><i class="fa fa-check"></i><b>9.30.1</b> Infer Package</a></li>
<li class="chapter" data-level="9.30.2" data-path="general-2.html"><a href="general-2.html#statistical-tests"><i class="fa fa-check"></i><b>9.30.2</b> Statistical Tests</a></li>
<li class="chapter" data-level="9.30.3" data-path="general-2.html"><a href="general-2.html#stats-for-hackers"><i class="fa fa-check"></i><b>9.30.3</b> Stats For Hackers</a></li>
<li class="chapter" data-level="9.30.4" data-path="general-2.html"><a href="general-2.html#think-stats"><i class="fa fa-check"></i><b>9.30.4</b> Think Stats</a></li>
</ul></li>
<li class="chapter" data-level="9.31" data-path="general-2.html"><a href="general-2.html#other-2"><i class="fa fa-check"></i><b>9.31</b> Other</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal Book Example</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="udacity-ts-fundamentals" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Udacity: TS Fundamentals</h1>
<p>Naive vs Seasonal Naive vs Exponential Smooothing</p>
<p>Seasonal Naive: Assumes magnitude of the seasonal pattern is constant.</p>
<p>cyclical vs seasonal patterns: longer, harder to predicit, don’t follow seasonl patterns</p>
<p>ETS: Error-Trend-Seasonality</p>
<p>The possible time series (TS) scenarios can be recognized by asking the following questions:</p>
<p>TS has a trend? If yes, is the trend increasing linearly or exponentially?</p>
<p>TS has seasonality? If yes, do the seasonal components increase in magnitude over time?</p>
<p>We are going to explore four ETS models that can help forecast these possible time-series scenarios.</p>
<p>Simple Exponential Smoothing Method</p>
<p>Holt’s Linear Trend Method</p>
<p>Exponential Trend Method</p>
<p>Holt-Winters Seasonal Method</p>
<p>Time series does not have a trend line and does not have seasonality component. We would use a Simple Exponential Smoothing model.</p>
<p>Time Seies: level, trend, seasonal compoent</p>
<p>Methods</p>
<p>There are several methods we need to pick in order to model any given time series appropriately:</p>
<p>Simple Exponential Smoothing: Finds the level of the time series</p>
<p>Holt’s Linear Trend: Finds the level of the time series</p>
<p>Additive model for linear trend</p>
<p>Exponential Trend: Finds the level of the time series</p>
<p>Multiplicative model for exponential trend</p>
<p>Holt-Winters Seasonal: Finds the level of the time series</p>
<p>Additive for trend</p>
<p>Multiplicative and Additive for seasonal components</p>
<p>These methods help deal with different scenarios in our time series involving:</p>
<p>Linear or exponential trend</p>
<p>Constant or increasing seasonality components</p>
<p>For trends that are exponential, we would need to use a multiplicative model.</p>
<p>For increasing seasonality components, we would need to use a multiplicative model model as well.</p>
<p>ETS</p>
<p>Therefore we can generalize all of these models using a naming system for ETS:</p>
<p>ETS (Error, Trend, Seasonality)</p>
<p>Error is the error line we saw in the time series decomposition part earlier in the course. If the error is increasing similar to an increasing seasonal components, we would need to consider a multiplicative design for the exponential model.</p>
<p>Therefore, for each component in the ETS system, we can assign None, Multiplicative, or Additive (or N, M, A) for each of the three components in our time series.</p>
<p>Examples</p>
<p>A time series model that has a constant error, linear trend, and increasing seasonal components means we would need to use an ETS model of:</p>
<p>ETS(N,A,M)</p>
<p>A time series model that has increasing error, exponential trend, and no seasonality means we would need to use an ETS model of:</p>
<p>ARIMA; Seasnoanl:ARIMA(p,d,q)(P,D,Q)M vs non-seasonal: ARIMA(p,d,q)</p>
<p>non-=statipjary: This plot shows an upward trend and seasonality.</p>
<p>stationaey: This plot revolves around a constant mean of 0 and shows contained variance.</p>
<p>Evluated withhold set and residual plots, should have mean of 0.</p>
<p>is less sensitive to the occasional very large error because it does not square the errors in the calculation.</p>
<p>Percentage Errors</p>
<p>Percentage errors, like MAPE, are useful because they are scale independent, so they can be used to compare forecasts between different data series, unlike scale dependent errors. The disadvantage is that it cannot be used if the series has zero values.</p>
<p>Mean Absolute Percentage Error (MAPE) is also often useful for purposes of reporting, because it is expressed in generic percentage terms it will make sense even to someone who has no idea what constitutes a “big” error in terms of dollars spent or widgets sold.</p>
<p>Scale-Free Errors</p>
<p>Scale-free errors were introduced more recently to offer a scale-independent measure that doesn’t have many of the problems of other errors like percentage errors.</p>
<p>Mean Absolute Scaled Error (MASE) is another relative measure of error that is applicable only to time series data. It is defined as the mean absolute error of the model divided by the the mean absolute value of the first difference of the series. Thus, it measures the relative reduction in error compared to a naive model. Ideally its value will be significantly less than 1 but is relative to comparison across other models for the same series. Since this error measurement is relative and can be applied across models, it is accepted as one of the best metrics for error measurement.</p>
<p>Can use AIC for model selection. Also use confidence intervals.</p>
<div id="dl" class="section level2">
<h2><span class="header-section-number">8.1</span> DL</h2>
<ul>
<li><p><a href="https://hackernoon.com/deep-learning-cheat-sheet-25421411e460">DL Cheatsheet</a></p></li>
<li><p>By reducing learning rate (for example, to 0.001), Test loss drops to a value much closer to Training loss. In most runs, increasing Batch size does not influence Training loss or Test loss significantly. However, in a small percentage of runs, increasing Batch size to 20 or greater causes Test loss to drop slightly below Training loss.</p></li>
<li><p>Reducing the ratio of training to test data from 50% to 10% dramatically lowers the number of data points in the training set. With so little data, high batch size and high learning rate cause the training model to jump around chaotically (jumping repeatedly over the minimum point).</p></li>
<li><p>There are several activation functions you may encounter in practice:</p>
<ul>
<li><p>Sigmoid: Takes a real-valued input and squashes it to range between 0 and 1 (<span class="math inline">\(σ(x) = 1 / (1 + exp(−x))\)</span>)</p></li>
<li><p>Softmax: Same end result as sigmoid, but different function.</p></li>
<li><p>tanh: Takes a real-valued input and squashes it to the range [-1, 1] (<span class="math inline">\(tanh(x) = 2σ(2x) − 1\)</span>)</p></li>
</ul></li>
<li><p>ReLU: The rectified linear activation function (called ReLU) has been shown to lead to very high-performance networks. This function takes a single number as an input, returning 0 if the input is negative, and the input if the input is positive. <span class="math inline">\(f(x) = max(0, x)\)</span></p></li>
<li><p>softmax doesn’t like multi-label classification</p></li>
<li><p>Embeddings vs One-Hot Encoding: Embeddings are better than One-Hot Encodings because it allows for relationships to be shown between days.</p></li>
<li><p>Advised to scale features</p></li>
<li><p><a href="https://www.youtube.com/watch?v=nqEYVzJLR_c&amp;feature=youtu.be&amp;t=31">Rule of 30</a>: A change that affects at least 30 data points in your validation set is usually significant and not just noise.</p></li>
<li><p>Gradient descent takes about 3 times longer than the loss function. Stochastic gradient descent works off an estimate of the loss function from a sample of the training set. Scales better than normal gradient descent.</p></li>
<li><p>Momentum and learning rate decay are good for knowing which way to go in gradient descent.</p></li>
<li><p>Always try to lower your learning rate for improvement.</p></li>
<li><p>ADAGRAD is another optimization option that takes care of some of the hyperparameters for you.</p></li>
<li><p>n inputs and k outputs gives you <span class="math inline">\((n+1)*k\)</span> parameters.</p></li>
<li><p>Back propogation takes about twice the memory as forward propogation.</p></li>
<li><p>Stop model from overoptimizing on training set: early termination (stop as soon as performance on validation set drops) and regularization which applies artifical constraints to reduce the number of free parameters while making it difficult to optimize. Uses l2 regularization or dropout. Dropout works by randomly setting activations from one layer to the next to 0 repeatly. Forces the network to learn redundant representations, and takes average consensus for final prediction. Makes things more robust and prevents overfitting. Scale the non-zero activates by 2 to get the right average. If it doesn’t work, go deeper.</p></li>
<li><p>Two ways are to average the yellow, blue, and green channels or to use YUV representation. If position on the screen doesn’t matter then use translation invariance. Use weight sharing if this occurs in text.</p></li>
<li><p>Things that don’t chnage across time, space, etc are called statistical invariants.</p></li>
<li><p>RNN’s use shared parameters over time to extract patterns. Uses a recurrent connection to provide a summary of the past and pass this info to the classifier.</p></li>
<li><p>Backpropagation occurs throw time to the beginning. All derivative applied to same parameters, so very correlated. Bad for stochastic gradient descent and makes math very unstable. Gradients are either zero (doesn’t remember the past well) or infinity. The latter is fixed by gradient clipping and the former by LSTM (long-short term memory). LSTM replaced the rectified linear units by continuous functions. You can use dropout or L2 regularization with an LSTM.</p></li>
<li><p>Generally dealing with images, Convolutional Neural Network is used mostly because of its better accuracy results.</p></li>
<li><p>Model capacity: Same as underfitting and overfitting in bias-variance. Less nodes and hidden layers corresponds to simpler model and vice versa.</p></li>
<li><p>The perceptron is the simplest neural network. The perceptron is an iterative classification method.The perceptron starts with a random hyperplane then adjust its weights to separate the data.</p></li>
<li><p>BackProp Algorithm: Initially all the edge weights are randomly assigned. For every input in the training dataset, the ANN is activated and its output is observed. This output is compared with the desired output that we already know, and the error is “propagated” back to the previous layer. This error is noted and the weights are “adjusted” accordingly. This process is repeated until the output error is below a predetermined threshold.</p></li>
<li><p>The last layer of a neural network captures the most complex interactions.</p></li>
<li><p>When plotting the mean-squared error loss function against predictions, the slope is <span class="math inline">\(2x(y-xb)\)</span>, or <span class="math inline">\(2input_data error\)</span>.</p></li>
<li><p>weights_updated = weights - slope*learning_rate</p></li>
<li><p>This is exactly what’s happening in the vanishing gradient problem – the gradients of the network’s output with respect to the parameters in the early layers become extremely small. That’s a fancy way of saying that even a large change in the value of parameters for the early layers doesn’t have a big effect on the output.</p></li>
<li><p>Batch: Subset of the data used to calculate slopes during back propagation. Different batches are used to calculate different updates.</p></li>
<li><p>Epoch: One full pass through all the batches in the training data.</p></li>
<li><p>Stochastic gradient descent calculates slopes one batch at a time.</p></li>
<li><p>This network again uses the ReLU activation function, so the slope of the activation function is 1 for any node receiving a positive value as input.</p></li>
<li><p>Few people use kfold cv in deep learning because of the large datasets in play.</p></li>
<li><p>Dying neuron + vanishing gradient: Change activation function</p></li>
</ul>
</div>
<div id="tensorflow" class="section level2">
<h2><span class="header-section-number">8.2</span> TensorFlow</h2>
<ul>
<li><p>In TensorFlow, we indicate a feature’s data type using a construct called a feature column. Feature columns store only a description of the feature data; they do not contain the feature data itself.</p></li>
<li><p>Amazingly enough, performing gradient descent on a small batch or even a batch of one example is usually more efficient than the full batch. After all, finding the gradient of one example is far cheaper than finding the gradient of millions of examples. To ensure a good representative sample, the algorithm scoops up another random small batch (or batch of one) on every iteration.</p></li>
<li><p>SGD &amp; Mini-Batch Gradient Descent</p></li>
</ul>
<p>Could compute gradient over entire data set on each step, but this turns out to be unnecessary. Computing gradient on small data samples works well. On every step, get a new random sample</p>
<p>Stochastic Gradient Descent: one example at a time</p>
<p>Mini-Batch Gradient Descent: batches of 10-1000. Loss &amp; gradients are averaged over the batch</p>
</div>
<div id="keras" class="section level2">
<h2><span class="header-section-number">8.3</span> Keras</h2>
<p>Here’s a <a href="https://github.com/fastforwardlabs/keras-hello-world/blob/master/kerashelloworld.ipynb">Hello World</a> and the general framework:</p>
<ul>
<li><p>declare: sequential</p></li>
<li><p>add layers input-hidden-output</p></li>
<li><p>compile</p></li>
<li><p>fit</p></li>
</ul>
<p>Keras only uses numpy arrays.</p>
<ul>
<li>keras.callbacks.EarlyStopping: Stop training when validation score stop improving after a certain number of epochs (baches?)</li>
</ul>
<div id="regression" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Regression</h3>
<ul>
<li><p>loss = mean_squared_error</p></li>
<li><p>metric: rmse</p></li>
<li><p>activation_function = relu</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> keras
<span class="im">from</span> keras.layers <span class="im">import</span> Dense
<span class="im">from</span> keras.models <span class="im">import</span> Sequential
<span class="co"># Specify the model: Two hidden layers</span>
model <span class="op">=</span> Sequential()
<span class="co">## Input</span>
n_cols <span class="op">=</span> predictors.shape[<span class="dv">1</span>]
model.add(Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape <span class="op">=</span> (n_cols,)))
<span class="co"># Hidden</span>
model.add(Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))
<span class="co"># Output</span>
model.add(Dense(<span class="dv">1</span>))
<span class="co"># Compile the model</span>
model.<span class="bu">compile</span>(optimizer <span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss <span class="op">=</span> <span class="st">&#39;mean_squared_error&#39;</span>) 
<span class="co"># Fit the model</span>
model.fit(predictors, target)
<span class="co">#Look at summary</span>
model.summary()
<span class="co"># Calculate predictions: predictions</span>
predictions <span class="op">=</span> model.predict(pred_data)</code></pre></div>
</div>
<div id="classification" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Classification</h3>
<ul>
<li><p>loss = categorical_crossentropy</p></li>
<li><p>metric = accuracy</p></li>
<li><p>activation_function = softmax</p></li>
<li><p>output layer with stuff equal to number of categorical groups</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> keras
<span class="im">from</span> keras.layers <span class="im">import</span> Dense
<span class="im">from</span> keras.models <span class="im">import</span> Sequential
<span class="co"># Specify the model: Two hidden layers</span>
n_cols <span class="op">=</span> predictors.shape[<span class="dv">1</span>]
model <span class="op">=</span> Sequential()
<span class="co">## Input</span>
model.add(Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape <span class="op">=</span> (n_cols,)))
<span class="co"># Hidden</span>
model.add(Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))
<span class="co"># Output</span>
model.add(Dense(<span class="dv">2</span>, activation <span class="op">=</span> <span class="st">&#39;softmax&#39;</span>))
<span class="co"># Compile the model</span>
model.<span class="bu">compile</span>(optimizer <span class="op">=</span> <span class="st">&#39;sgd&#39;</span>, loss <span class="op">=</span> <span class="st">&#39;categorical_crossentropy&#39;</span>, metrics <span class="op">=</span> [<span class="st">&#39;accuracy&#39;</span>])
<span class="co"># Fit the model</span>
model.fit(predictors, target)
<span class="co">#Look at summary</span>
model.summary()
<span class="co">#Calculate predictions: predictions</span>
predictions <span class="op">=</span> model.predict(pred_data)
<span class="co">#Calculate predicted probability of survival</span>
predicted_prob_true <span class="op">=</span> predictions[:, <span class="dv">1</span>]</code></pre></div>
</div>
<div id="another-example" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Another Example</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Import the SGD optimizer</span>
<span class="im">from</span> keras.optimizers <span class="im">import</span> SGD
<span class="co"># Create list of learning rates: lr_to_test</span>
lr_to_test <span class="op">=</span> [.<span class="dv">000001</span>, <span class="fl">0.01</span>, <span class="dv">1</span>]
<span class="co"># Loop over learning rates</span>
<span class="cf">for</span> lr <span class="kw">in</span> lr_to_test:
    <span class="bu">print</span>(<span class="st">&#39;Testing model with learning rate: &#39;</span>)
    
    <span class="co"># Build new model to test, unaffected by previous models</span>
    model <span class="op">=</span> get_new_model()
    
    <span class="co"># Create SGD optimizer with specified learning rate: my_optimizer</span>
    my_optimizer <span class="op">=</span> SGD(lr <span class="op">=</span> lr)
    
    <span class="co"># Compile the model</span>
    model.<span class="bu">compile</span>(optimizer <span class="op">=</span> my_optimizer, loss <span class="op">=</span> <span class="st">&#39;categorical_crossentropy&#39;</span>)
    
    <span class="co"># Fit the model</span>
    model.fit(predictors, 
              target, 
              validation_split <span class="op">=</span> <span class="fl">0.3</span>, 
              epochs <span class="op">=</span> <span class="dv">20</span>, 
              callbacks <span class="op">=</span> [early_stopping_monitor], 
              verbose <span class="op">=</span> <span class="va">False</span>)</code></pre></div>
</div>
</div>
<div id="association-rule-mining" class="section level2">
<h2><span class="header-section-number">8.4</span> Association Rule Mining</h2>
<div id="intro-18" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Intro</h3>
<ul>
<li><p>Used in Genetics, Fraud, and Market Basket Analysis, etc. A typical rule might be: if someone buys peanut butter and jelly, then that person is likely to buy bread as well.</p></li>
<li><p>Incredibly big feature space (2^k-1).</p></li>
<li><p>The Apriori algorithm employs a simple a priori belief as a guideline for reducing the association rule space.</p></li>
<li><p>Support: the fraction of which each item appears within the dataset as a whole. Support(item) = count(item)/N. Higher support is better.</p></li>
<li><p>nfidence: the likelihood that a constructed rule is correct given the items on the left hand side of the transaction. A higher level of confidence implies a higher likelihood that Y appears alongside transactions in which X appears.</p></li>
<li><p>ft: the ratio by which the confidence of a rule exceeds the expected outcome. When lift &gt; 1, the presence of X seems to have increasedthe probability of Y occurring in the transaction. When lift &lt; 1, the presence of X seems to have decreasedthe probability of Y occurring in the transaction. When lift = 1, X and Y are independent.</p></li>
<li><p>t thresholds for support and confidence and then the algorithm goes from all 1-combinations to 2-combinations and up. Those subset below the threshold don’t make it to the higher iterations.</p></li>
</ul>
</div>
<div id="assumptions-18" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Assumptions</h3>
</div>
<div id="characteristics-13" class="section level3">
<h3><span class="header-section-number">8.4.3</span> Characteristics</h3>
</div>
<div id="evaluation-18" class="section level3">
<h3><span class="header-section-number">8.4.4</span> Evaluation</h3>
</div>
<div id="proscons-18" class="section level3">
<h3><span class="header-section-number">8.4.5</span> Pros/Cons</h3>
<p><strong>Pros</strong></p>
<ul>
<li><p>Ideally suited for working with very large amounts of transactional data.</p></li>
<li><p>The results are rules that are generally easy to understand and have a high amount of interpretability.</p></li>
<li><p>The process is useful for data mining and uncovering unexpected knowledge within a dataset.</p></li>
</ul>
<p><strong>Cons</strong></p>
<ul>
<li><p>The outcome is usually not interesting when applied to smaller datasets.</p></li>
<li><p>It is difficult to separate actual insights from common sense notions.</p></li>
<li><p>The analyst might be compelled to draw spurious conclusions–remember that correlation doesn’t imply causation!</p></li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cdm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-model.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
