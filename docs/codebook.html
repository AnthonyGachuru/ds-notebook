<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 9 Codebook | Data Science Cribsheet</title>
  <meta name="description" content="A collection of quick notes on the field.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 9 Codebook | Data Science Cribsheet" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A collection of quick notes on the field." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Codebook | Data Science Cribsheet" />
  
  <meta name="twitter:description" content="A collection of quick notes on the field." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="probabilistic-programming.html">
<link rel="next" href="checklists.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DS Cribsheet</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Workflow</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#preamble"><i class="fa fa-check"></i><b>1.1</b> Preamble</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#resources"><i class="fa fa-check"></i><b>1.2</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pre-modeling.html"><a href="pre-modeling.html"><i class="fa fa-check"></i><b>2</b> Pre-Modeling</a><ul>
<li class="chapter" data-level="2.1" data-path="pre-modeling.html"><a href="pre-modeling.html#import"><i class="fa fa-check"></i><b>2.1</b> Import</a><ul>
<li class="chapter" data-level="2.1.1" data-path="pre-modeling.html"><a href="pre-modeling.html#general"><i class="fa fa-check"></i><b>2.1.1</b> General</a></li>
<li class="chapter" data-level="2.1.2" data-path="pre-modeling.html"><a href="pre-modeling.html#sql"><i class="fa fa-check"></i><b>2.1.2</b> SQL</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pre-modeling.html"><a href="pre-modeling.html#tidy-transform"><i class="fa fa-check"></i><b>2.2</b> Tidy &amp; Transform</a><ul>
<li class="chapter" data-level="2.2.1" data-path="pre-modeling.html"><a href="pre-modeling.html#general-1"><i class="fa fa-check"></i><b>2.2.1</b> General</a></li>
<li class="chapter" data-level="2.2.2" data-path="pre-modeling.html"><a href="pre-modeling.html#missingness-imputation"><i class="fa fa-check"></i><b>2.2.2</b> Missingness &amp; Imputation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pre-modeling.html"><a href="pre-modeling.html#visualize"><i class="fa fa-check"></i><b>2.3</b> Visualize</a></li>
<li class="chapter" data-level="2.4" data-path="pre-modeling.html"><a href="pre-modeling.html#pre-processing"><i class="fa fa-check"></i><b>2.4</b> Pre-processing</a><ul>
<li class="chapter" data-level="2.4.1" data-path="pre-modeling.html"><a href="pre-modeling.html#feature-engineering"><i class="fa fa-check"></i><b>2.4.1</b> Feature Engineering</a></li>
<li class="chapter" data-level="2.4.2" data-path="pre-modeling.html"><a href="pre-modeling.html#feature-selection"><i class="fa fa-check"></i><b>2.4.2</b> Feature Selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="model.html"><a href="model.html"><i class="fa fa-check"></i><b>3</b> Model</a><ul>
<li class="chapter" data-level="3.1" data-path="model.html"><a href="model.html#general-2"><i class="fa fa-check"></i><b>3.1</b> General</a></li>
<li class="chapter" data-level="3.2" data-path="model.html"><a href="model.html#model-selectionevaluation"><i class="fa fa-check"></i><b>3.2</b> Model Selection/Evaluation</a></li>
<li class="chapter" data-level="3.3" data-path="model.html"><a href="model.html#supervised"><i class="fa fa-check"></i><b>3.3</b> Supervised</a><ul>
<li class="chapter" data-level="3.3.1" data-path="model.html"><a href="model.html#glm"><i class="fa fa-check"></i><b>3.3.1</b> GLM</a></li>
<li class="chapter" data-level="3.3.2" data-path="model.html"><a href="model.html#generalized-additive-models"><i class="fa fa-check"></i><b>3.3.2</b> Generalized Additive Models</a></li>
<li class="chapter" data-level="3.3.3" data-path="model.html"><a href="model.html#knn"><i class="fa fa-check"></i><b>3.3.3</b> KNN</a></li>
<li class="chapter" data-level="3.3.4" data-path="model.html"><a href="model.html#svm"><i class="fa fa-check"></i><b>3.3.4</b> SVM</a></li>
<li class="chapter" data-level="3.3.5" data-path="model.html"><a href="model.html#decision-tree"><i class="fa fa-check"></i><b>3.3.5</b> Decision Tree</a></li>
<li class="chapter" data-level="3.3.6" data-path="model.html"><a href="model.html#bagging"><i class="fa fa-check"></i><b>3.3.6</b> Bagging</a></li>
<li class="chapter" data-level="3.3.7" data-path="model.html"><a href="model.html#random-forest"><i class="fa fa-check"></i><b>3.3.7</b> Random Forest</a></li>
<li class="chapter" data-level="3.3.8" data-path="model.html"><a href="model.html#boosting"><i class="fa fa-check"></i><b>3.3.8</b> Boosting</a></li>
<li class="chapter" data-level="3.3.9" data-path="model.html"><a href="model.html#naive-bayes"><i class="fa fa-check"></i><b>3.3.9</b> Naïve Bayes</a></li>
<li class="chapter" data-level="3.3.10" data-path="model.html"><a href="model.html#lda-qda"><i class="fa fa-check"></i><b>3.3.10</b> LDA &amp; QDA</a></li>
<li class="chapter" data-level="3.3.11" data-path="model.html"><a href="model.html#gams"><i class="fa fa-check"></i><b>3.3.11</b> GAMs</a></li>
<li class="chapter" data-level="3.3.12" data-path="model.html"><a href="model.html#hierarchical-models"><i class="fa fa-check"></i><b>3.3.12</b> Hierarchical Models</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="model.html"><a href="model.html#unsupervised"><i class="fa fa-check"></i><b>3.4</b> Unsupervised</a><ul>
<li class="chapter" data-level="3.4.1" data-path="model.html"><a href="model.html#k-means-clustering"><i class="fa fa-check"></i><b>3.4.1</b> K-Means Clustering</a></li>
<li class="chapter" data-level="3.4.2" data-path="model.html"><a href="model.html#hierarchical-clustering"><i class="fa fa-check"></i><b>3.4.2</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="3.4.3" data-path="model.html"><a href="model.html#pca"><i class="fa fa-check"></i><b>3.4.3</b> PCA</a></li>
<li class="chapter" data-level="3.4.4" data-path="model.html"><a href="model.html#multiple-correspondence-analysis"><i class="fa fa-check"></i><b>3.4.4</b> Multiple Correspondence Analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="model.html"><a href="model.html#semi-supervised"><i class="fa fa-check"></i><b>3.5</b> Semi Supervised</a></li>
<li class="chapter" data-level="3.6" data-path="model.html"><a href="model.html#reinforcement-learning"><i class="fa fa-check"></i><b>3.6</b> Reinforcement Learning</a></li>
<li class="chapter" data-level="3.7" data-path="model.html"><a href="model.html#other-ml"><i class="fa fa-check"></i><b>3.7</b> Other ML</a><ul>
<li class="chapter" data-level="3.7.1" data-path="model.html"><a href="model.html#association-rule-mining"><i class="fa fa-check"></i><b>3.7.1</b> Association Rule Mining</a></li>
<li class="chapter" data-level="3.7.2" data-path="model.html"><a href="model.html#nlp"><i class="fa fa-check"></i><b>3.7.2</b> NLP</a></li>
<li class="chapter" data-level="3.7.3" data-path="model.html"><a href="model.html#geospatial"><i class="fa fa-check"></i><b>3.7.3</b> Geospatial</a></li>
<li class="chapter" data-level="3.7.4" data-path="model.html"><a href="model.html#ai"><i class="fa fa-check"></i><b>3.7.4</b> AI</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="model.html"><a href="model.html#online-learning"><i class="fa fa-check"></i><b>3.8</b> Online Learning</a></li>
<li class="chapter" data-level="3.9" data-path="model.html"><a href="model.html#sequences"><i class="fa fa-check"></i><b>3.9</b> Sequences</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="communicate-deploy-maintain.html"><a href="communicate-deploy-maintain.html"><i class="fa fa-check"></i><b>4</b> Communicate, Deploy, Maintain</a><ul>
<li class="chapter" data-level="4.1" data-path="communicate-deploy-maintain.html"><a href="communicate-deploy-maintain.html#communicate"><i class="fa fa-check"></i><b>4.1</b> Communicate</a></li>
<li class="chapter" data-level="4.2" data-path="communicate-deploy-maintain.html"><a href="communicate-deploy-maintain.html#deploymaintain"><i class="fa fa-check"></i><b>4.2</b> Deploy/Maintain</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stats.html"><a href="stats.html"><i class="fa fa-check"></i><b>5</b> Stats</a><ul>
<li class="chapter" data-level="5.1" data-path="stats.html"><a href="stats.html#general-3"><i class="fa fa-check"></i><b>5.1</b> General</a></li>
<li class="chapter" data-level="5.2" data-path="stats.html"><a href="stats.html#sample-size"><i class="fa fa-check"></i><b>5.2</b> Sample Size</a></li>
<li class="chapter" data-level="5.3" data-path="stats.html"><a href="stats.html#hypothesis-testing"><i class="fa fa-check"></i><b>5.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="5.4" data-path="stats.html"><a href="stats.html#ab-testing"><i class="fa fa-check"></i><b>5.4</b> AB Testing</a><ul>
<li class="chapter" data-level="5.4.1" data-path="stats.html"><a href="stats.html#power-analysis"><i class="fa fa-check"></i><b>5.4.1</b> Power Analysis</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="stats.html"><a href="stats.html#experimental-design"><i class="fa fa-check"></i><b>5.5</b> Experimental Design</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="sequences-1.html"><a href="sequences-1.html"><i class="fa fa-check"></i><b>6</b> Sequences</a><ul>
<li class="chapter" data-level="6.1" data-path="sequences-1.html"><a href="sequences-1.html#time-series"><i class="fa fa-check"></i><b>6.1</b> Time Series</a><ul>
<li class="chapter" data-level="6.1.1" data-path="sequences-1.html"><a href="sequences-1.html#notes"><i class="fa fa-check"></i><b>6.1.1</b> Notes</a></li>
<li class="chapter" data-level="6.1.2" data-path="sequences-1.html"><a href="sequences-1.html#workflow-1"><i class="fa fa-check"></i><b>6.1.2</b> Workflow</a></li>
<li class="chapter" data-level="6.1.3" data-path="sequences-1.html"><a href="sequences-1.html#preprocessing"><i class="fa fa-check"></i><b>6.1.3</b> Preprocessing</a></li>
<li class="chapter" data-level="6.1.4" data-path="sequences-1.html"><a href="sequences-1.html#feature-engineering-1"><i class="fa fa-check"></i><b>6.1.4</b> Feature Engineering</a></li>
<li class="chapter" data-level="6.1.5" data-path="sequences-1.html"><a href="sequences-1.html#packages-functions"><i class="fa fa-check"></i><b>6.1.5</b> Packages / Functions</a></li>
<li class="chapter" data-level="6.1.6" data-path="sequences-1.html"><a href="sequences-1.html#models"><i class="fa fa-check"></i><b>6.1.6</b> Models</a></li>
<li class="chapter" data-level="6.1.7" data-path="sequences-1.html"><a href="sequences-1.html#model-selection"><i class="fa fa-check"></i><b>6.1.7</b> Model Selection</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="sequences-1.html"><a href="sequences-1.html#dsp"><i class="fa fa-check"></i><b>6.2</b> DSP</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>7</b> Deep Learning</a><ul>
<li class="chapter" data-level="7.1" data-path="deep-learning.html"><a href="deep-learning.html#general-6"><i class="fa fa-check"></i><b>7.1</b> General</a></li>
<li class="chapter" data-level="7.2" data-path="deep-learning.html"><a href="deep-learning.html#pre-processing-1"><i class="fa fa-check"></i><b>7.2</b> Pre-processing</a></li>
<li class="chapter" data-level="7.3" data-path="deep-learning.html"><a href="deep-learning.html#defaults"><i class="fa fa-check"></i><b>7.3</b> Defaults</a></li>
<li class="chapter" data-level="7.4" data-path="deep-learning.html"><a href="deep-learning.html#rnnlstm"><i class="fa fa-check"></i><b>7.4</b> RNN/LSTM</a></li>
<li class="chapter" data-level="7.5" data-path="deep-learning.html"><a href="deep-learning.html#tuning"><i class="fa fa-check"></i><b>7.5</b> Tuning</a></li>
<li class="chapter" data-level="7.6" data-path="deep-learning.html"><a href="deep-learning.html#debugging"><i class="fa fa-check"></i><b>7.6</b> Debugging</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html"><i class="fa fa-check"></i><b>8</b> Probabilistic Programming</a><ul>
<li class="chapter" data-level="8.1" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#bayes-rule"><i class="fa fa-check"></i><b>8.1</b> Bayes Rule</a></li>
<li class="chapter" data-level="8.2" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#other-1"><i class="fa fa-check"></i><b>8.2</b> Other</a></li>
<li class="chapter" data-level="8.3" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#doing-bayesian-da"><i class="fa fa-check"></i><b>8.3</b> Doing Bayesian DA</a></li>
<li class="chapter" data-level="8.4" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#statistical-rethinking"><i class="fa fa-check"></i><b>8.4</b> Statistical Rethinking</a></li>
<li class="chapter" data-level="8.5" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#causality"><i class="fa fa-check"></i><b>8.5</b> Causality</a></li>
<li class="chapter" data-level="8.6" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#general-7"><i class="fa fa-check"></i><b>8.6</b> General</a></li>
<li class="chapter" data-level="8.7" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#causality-edx"><i class="fa fa-check"></i><b>8.7</b> Causality edX</a><ul>
<li class="chapter" data-level="8.7.1" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#causality-coursera"><i class="fa fa-check"></i><b>8.7.1</b> Causality Coursera</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="codebook.html"><a href="codebook.html"><i class="fa fa-check"></i><b>9</b> Codebook</a><ul>
<li class="chapter" data-level="9.1" data-path="codebook.html"><a href="codebook.html#general-8"><i class="fa fa-check"></i><b>9.1</b> General</a></li>
<li class="chapter" data-level="9.2" data-path="codebook.html"><a href="codebook.html#linear-regression-assumption-checks"><i class="fa fa-check"></i><b>9.2</b> Linear Regression Assumption Checks</a></li>
<li class="chapter" data-level="9.3" data-path="codebook.html"><a href="codebook.html#regression-by-groups"><i class="fa fa-check"></i><b>9.3</b> Regression By Groups</a></li>
<li class="chapter" data-level="9.4" data-path="codebook.html"><a href="codebook.html#cyclical-feature-engineering"><i class="fa fa-check"></i><b>9.4</b> Cyclical Feature Engineering</a></li>
<li class="chapter" data-level="9.5" data-path="codebook.html"><a href="codebook.html#rpy2-ipynb"><i class="fa fa-check"></i><b>9.5</b> Rpy2 Ipynb</a></li>
<li class="chapter" data-level="9.6" data-path="codebook.html"><a href="codebook.html#symbolic-regression"><i class="fa fa-check"></i><b>9.6</b> Symbolic Regression</a></li>
<li class="chapter" data-level="9.7" data-path="codebook.html"><a href="codebook.html#stats-by-simulation"><i class="fa fa-check"></i><b>9.7</b> Stats By Simulation</a></li>
<li class="chapter" data-level="9.8" data-path="codebook.html"><a href="codebook.html#simple-bayes"><i class="fa fa-check"></i><b>9.8</b> Simple Bayes</a></li>
<li class="chapter" data-level="9.9" data-path="codebook.html"><a href="codebook.html#ts-harmonic-regression"><i class="fa fa-check"></i><b>9.9</b> TS Harmonic Regression</a></li>
<li class="chapter" data-level="9.10" data-path="codebook.html"><a href="codebook.html#save-and-load-models"><i class="fa fa-check"></i><b>9.10</b> Save And Load Models</a></li>
<li class="chapter" data-level="9.11" data-path="codebook.html"><a href="codebook.html#lstm"><i class="fa fa-check"></i><b>9.11</b> LSTM</a></li>
<li class="chapter" data-level="9.12" data-path="codebook.html"><a href="codebook.html#logistic-regression-stats-models"><i class="fa fa-check"></i><b>9.12</b> Logistic Regression Stats Models</a></li>
<li class="chapter" data-level="9.13" data-path="codebook.html"><a href="codebook.html#function-negation"><i class="fa fa-check"></i><b>9.13</b> Function Negation</a></li>
<li class="chapter" data-level="9.14" data-path="codebook.html"><a href="codebook.html#attach-date-csv"><i class="fa fa-check"></i><b>9.14</b> Attach Date CSV</a></li>
<li class="chapter" data-level="9.15" data-path="codebook.html"><a href="codebook.html#ebb"><i class="fa fa-check"></i><b>9.15</b> EBB</a></li>
<li class="chapter" data-level="9.16" data-path="codebook.html"><a href="codebook.html#plot-grid"><i class="fa fa-check"></i><b>9.16</b> Plot Grid</a></li>
<li class="chapter" data-level="9.17" data-path="codebook.html"><a href="codebook.html#pairwise-scatterplot"><i class="fa fa-check"></i><b>9.17</b> Pairwise Scatterplot</a></li>
<li class="chapter" data-level="9.18" data-path="codebook.html"><a href="codebook.html#anti-join"><i class="fa fa-check"></i><b>9.18</b> Anti-join</a></li>
<li class="chapter" data-level="9.19" data-path="codebook.html"><a href="codebook.html#df-diff"><i class="fa fa-check"></i><b>9.19</b> DF Diff</a></li>
<li class="chapter" data-level="9.20" data-path="codebook.html"><a href="codebook.html#csv-encoding-check"><i class="fa fa-check"></i><b>9.20</b> CSV Encoding Check</a></li>
<li class="chapter" data-level="9.21" data-path="codebook.html"><a href="codebook.html#pandas-profiling"><i class="fa fa-check"></i><b>9.21</b> Pandas Profiling</a></li>
<li class="chapter" data-level="9.22" data-path="codebook.html"><a href="codebook.html#read-sql"><i class="fa fa-check"></i><b>9.22</b> Read SQL</a></li>
<li class="chapter" data-level="9.23" data-path="codebook.html"><a href="codebook.html#extract-date"><i class="fa fa-check"></i><b>9.23</b> Extract Date</a></li>
<li class="chapter" data-level="9.24" data-path="codebook.html"><a href="codebook.html#ggplot-to-plotly"><i class="fa fa-check"></i><b>9.24</b> GGPLOT To Plotly</a></li>
<li class="chapter" data-level="9.25" data-path="codebook.html"><a href="codebook.html#custom-theme-for-plot"><i class="fa fa-check"></i><b>9.25</b> Custom Theme For Plot</a></li>
<li class="chapter" data-level="9.26" data-path="codebook.html"><a href="codebook.html#heatmap"><i class="fa fa-check"></i><b>9.26</b> Heatmap</a></li>
<li class="chapter" data-level="9.27" data-path="codebook.html"><a href="codebook.html#linear-regression-statsmodels"><i class="fa fa-check"></i><b>9.27</b> Linear Regression Statsmodels</a></li>
<li class="chapter" data-level="9.28" data-path="codebook.html"><a href="codebook.html#linear-regression-by-groups"><i class="fa fa-check"></i><b>9.28</b> Linear Regression By Groups</a></li>
<li class="chapter" data-level="9.29" data-path="codebook.html"><a href="codebook.html#rml-pipeline"><i class="fa fa-check"></i><b>9.29</b> RML Pipeline</a></li>
<li class="chapter" data-level="9.30" data-path="codebook.html"><a href="codebook.html#rowwise"><i class="fa fa-check"></i><b>9.30</b> Rowwise</a></li>
<li class="chapter" data-level="9.31" data-path="codebook.html"><a href="codebook.html#sampling-file"><i class="fa fa-check"></i><b>9.31</b> Sampling File</a></li>
<li class="chapter" data-level="9.32" data-path="codebook.html"><a href="codebook.html#sql-dummy-columns"><i class="fa fa-check"></i><b>9.32</b> SQL Dummy Columns</a></li>
<li class="chapter" data-level="9.33" data-path="codebook.html"><a href="codebook.html#model-calibration"><i class="fa fa-check"></i><b>9.33</b> Model Calibration</a></li>
<li class="chapter" data-level="9.34" data-path="codebook.html"><a href="codebook.html#binning-rule-of-thumb"><i class="fa fa-check"></i><b>9.34</b> Binning Rule Of Thumb</a></li>
<li class="chapter" data-level="9.35" data-path="codebook.html"><a href="codebook.html#featuretools"><i class="fa fa-check"></i><b>9.35</b> Featuretools</a></li>
<li class="chapter" data-level="9.36" data-path="codebook.html"><a href="codebook.html#skimage"><i class="fa fa-check"></i><b>9.36</b> Skimage</a></li>
<li class="chapter" data-level="9.37" data-path="codebook.html"><a href="codebook.html#shap"><i class="fa fa-check"></i><b>9.37</b> SHAP</a></li>
<li class="chapter" data-level="9.38" data-path="codebook.html"><a href="codebook.html#hyperband-cv"><i class="fa fa-check"></i><b>9.38</b> Hyperband CV</a></li>
<li class="chapter" data-level="9.39" data-path="codebook.html"><a href="codebook.html#csv-to-db"><i class="fa fa-check"></i><b>9.39</b> CSV To DB</a></li>
<li class="chapter" data-level="9.40" data-path="codebook.html"><a href="codebook.html#xgboost-light-gbm"><i class="fa fa-check"></i><b>9.40</b> Xgboost &amp; Light GBM</a></li>
<li class="chapter" data-level="9.41" data-path="codebook.html"><a href="codebook.html#bayesian-cv"><i class="fa fa-check"></i><b>9.41</b> Bayesian CV</a></li>
<li class="chapter" data-level="9.42" data-path="codebook.html"><a href="codebook.html#pyspark"><i class="fa fa-check"></i><b>9.42</b> Pyspark</a></li>
<li class="chapter" data-level="9.43" data-path="codebook.html"><a href="codebook.html#sparklyr"><i class="fa fa-check"></i><b>9.43</b> Sparklyr</a></li>
<li class="chapter" data-level="9.44" data-path="codebook.html"><a href="codebook.html#data-table"><i class="fa fa-check"></i><b>9.44</b> Data Table</a></li>
<li class="chapter" data-level="9.45" data-path="codebook.html"><a href="codebook.html#keras"><i class="fa fa-check"></i><b>9.45</b> Keras</a></li>
<li class="chapter" data-level="9.46" data-path="codebook.html"><a href="codebook.html#mnist-example"><i class="fa fa-check"></i><b>9.46</b> MNIST Example</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="checklists.html"><a href="checklists.html"><i class="fa fa-check"></i><b>10</b> Checklists</a><ul>
<li class="chapter" data-level="10.1" data-path="checklists.html"><a href="checklists.html#general-9"><i class="fa fa-check"></i><b>10.1</b> General</a></li>
<li class="chapter" data-level="10.2" data-path="checklists.html"><a href="checklists.html#linear-regression-1"><i class="fa fa-check"></i><b>10.2</b> Linear Regression</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science Cribsheet</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="codebook" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Codebook</h1>
<div id="general-8" class="section level2">
<h2><span class="header-section-number">9.1</span> General</h2>
<p><a href="http://chrisalbon.com/">Chris Albon</a></p>
</div>
<div id="linear-regression-assumption-checks" class="section level2">
<h2><span class="header-section-number">9.2</span> Linear Regression Assumption Checks</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># general check</span>
<span class="kw">plot</span>(mdl)

<span class="co"># linearity check</span>
<span class="kw">avPlots</span>(mdl)

<span class="co"># Outlier Analysis</span>
<span class="co"># influencePlot(mdl)</span>

<span class="co"># multi-colinearity</span>
<span class="kw">vif</span>(mdl) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">VIF =</span> <span class="st">`</span><span class="dt">GVIF..1..2.Df..</span><span class="st">`</span>, <span class="dt">VIF =</span> VIF<span class="op">^</span><span class="dv">2</span>)

<span class="co">#  Autocorrelated Errors</span>
<span class="kw">durbinWatsonTest</span>(rgr_lr_st1)

<span class="co"># Normality</span>
<span class="kw">shapiro.test</span>(data)

<span class="co"># Inspect this same data using the QQ-plots (For normal data, the QQ-plot produces a straight-line relationship. For uniform data, the QQ-plot does NOT produce a straight-line relationship): </span>
<span class="kw">qqnorm</span>(normal.data) <span class="op">+</span><span class="st"> </span><span class="kw">qqline</span>(normal.data)

<span class="co"># heteroskedasticity</span>
<span class="co"># Breusch-Pagan (BP) test lmtest package</span></code></pre>
</div>
<div id="regression-by-groups" class="section level2">
<h2><span class="header-section-number">9.3</span> Regression By Groups</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(purrr)

pga <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(name,year,driveavg,drivepct, score.avg) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">split</span>(.<span class="op">$</span>year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">map</span>(<span class="op">~</span><span class="kw">lm</span>(score.avg <span class="op">~</span><span class="st"> </span>driveavg <span class="op">+</span><span class="st"> </span>drivepct, <span class="dt">data=</span>.)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">map</span>(summary)</code></pre>
</div>
<div id="cyclical-feature-engineering" class="section level2">
<h2><span class="header-section-number">9.4</span> Cyclical Feature Engineering</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Dealing with cyclical features: Hours of the day, days of the week, months in a year, and wind direction are all examples of features that are cyclical. Many new machine learning engineers don’t think to convert these features into a representation that can preserve information such as hour 23 and hour 0 being close to each other and not far. Keeping with the hour example, the best way to handle this is to calculate the sin and cos component so that you represent your cyclical feature as (x,y) coordinates of a circle. In this representation hour, 23 and hour 0 are right next to each other numerically, just as they should be.</span>
<span class="im">import</span> numpy <span class="im">as</span> np
df[<span class="st">&#39;hr_sin&#39;</span>] <span class="op">=</span> np.sin(df.hr<span class="op">*</span>(<span class="fl">2.</span><span class="op">*</span>np.pi<span class="op">/</span><span class="dv">24</span>))
df[<span class="st">&#39;hr_cos&#39;</span>] <span class="op">=</span> np.cos(df.hr<span class="op">*</span>(<span class="fl">2.</span><span class="op">*</span>np.pi<span class="op">/</span><span class="dv">24</span>))
df[<span class="st">&#39;mnth_sin&#39;</span>] <span class="op">=</span> np.sin((df.mnth<span class="dv">-1</span>)<span class="op">*</span>(<span class="fl">2.</span><span class="op">*</span>np.pi<span class="op">/</span><span class="dv">12</span>))
df[<span class="st">&#39;mnth_cos&#39;</span>] <span class="op">=</span> np.cos((df.mnth<span class="dv">-1</span>)<span class="op">*</span>(<span class="fl">2.</span><span class="op">*</span>np.pi<span class="op">/</span><span class="dv">12</span>))</code></pre>
</div>
<div id="rpy2-ipynb" class="section level2">
<h2><span class="header-section-number">9.5</span> Rpy2 Ipynb</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> numpy <span class="im">as</span> np 
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> rpy2.robjects
<span class="im">from</span> rpy2.robjects <span class="im">import</span> r, pandas2ri
<span class="im">from</span> rpy2.robjects.packages <span class="im">import</span> importr
<span class="co"># base = importr(&#39;base&#39;) # not working for some weird issue</span>
<span class="co"># %load_ext rpy2.ipython</span>
stats <span class="op">=</span> importr(<span class="st">&#39;stats&#39;</span>)
pandas2ri.activate()
r[<span class="st">&#39;mtcars&#39;</span>].head()
iris <span class="op">=</span> pd.read_csv(<span class="st">&quot;https://bit.ly/2ow0oJO&quot;</span>)
test <span class="op">=</span> iris.copy()
test.columns  <span class="op">=</span> [<span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Sepal.Width&quot;</span>,  <span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>, <span class="st">&quot;Species&quot;</span>]
rdf <span class="op">=</span> pandas2ri.py2rpy_pandasdataframe(test)
rpy2.robjects.r(<span class="st">&#39;&#39;&#39;</span>
<span class="st">f &lt;- function() {</span>
<span class="st">    model = load(&quot;rgr_iris.rda&quot;)</span>
<span class="st">    #predict(get(model), X)</span>
<span class="st">    return(get(model))</span>
<span class="st">    }</span>
<span class="st">&#39;&#39;&#39;</span>)
r_f <span class="op">=</span> rpy2.robjects.r[<span class="st">&#39;f&#39;</span>]
mdl1 <span class="op">=</span> r_f() 
stats.predict(mdl1, test)
<span class="co">#----------------------------------------------------------</span>
<span class="co"># %%R -i df -o model -w 5 -h 5 --units in -r 200</span>
<span class="co"># import df from global environment</span>
<span class="co"># make default figure size 5 by 5 inches with 200 dpi resolution</span>
<span class="co">#library(ggplot2)</span>
<span class="co">#library(stats)</span>
<span class="co">#ggplot(df, aes(x=cups_of_coffee, y=productivity)) + geom_line()</span>
<span class="co">#model =  lm(&quot;Petal.Length ~ . - Species&quot;, iris)</span>
<span class="co">#----------------------------------------------------------</span>
preds2 <span class="op">=</span> stats.predict(model, test)</code></pre>
</div>
<div id="symbolic-regression" class="section level2">
<h2><span class="header-section-number">9.6</span> Symbolic Regression</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> gplearn <span class="im">import</span> SymbolicRegressor
est_gp <span class="op">=</span> SymbolicRegressor(population_size <span class="op">=</span> <span class="dv">100</span>, generations <span class="op">=</span> <span class="dv">100</span>, stopping_criteria <span class="op">=</span> <span class="fl">0.01</span>, p_crossover <span class="op">=</span> <span class="fl">0.7</span>, p_subtree_mutation <span class="op">=</span> <span class="fl">0.1</span>, metric <span class="op">=</span> <span class="st">&#39;rmse&#39;</span>, p_hoist_mutation <span class="op">=</span> <span class="fl">0.05</span>, p_point_mutation <span class="op">=</span> <span class="fl">0.1</span>, max_samples <span class="op">=</span> <span class="fl">0.9</span>, verbose <span class="op">=</span> <span class="dv">0</span>, parsimony_coefficient <span class="op">=</span> <span class="fl">0.01</span>, random_state <span class="op">=</span> seed)
est_gp.fit(X_train, y_train)
preds <span class="op">=</span> est_gp.predict(X_train)
np.sqrt(mean_squared_error(y_train, preds))
graph <span class="op">=</span> pydotplus.graphviz.graph_from_dot_data(est_gp._program.export_graphviz())
Image(graph.create_png())
eqn <span class="op">=</span> <span class="bu">str</span>(est_gp._program)
mapping_dict <span class="op">=</span> {<span class="st">&#39;X</span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(i): X_train.columns[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X_train.shape[<span class="dv">1</span>])}
<span class="cf">for</span> old_value, new_value <span class="kw">in</span> mapping_dict.items():
  eqn <span class="op">=</span> eqn.replace(old_value, new_value)</code></pre>
</div>
<div id="stats-by-simulation" class="section level2">
<h2><span class="header-section-number">9.7</span> Stats By Simulation</h2>
<p>Notes on the talk by Jake Vanderplas. I left out bootstrap and cross validation below. For all methods look out for selection bias and make sure you have representative samples. More on the bootstrap: These are simulated confidence intervals that work well for n &gt; 20 as a rule of thumb.</p>
<p><strong>Direct Simulation</strong></p>
<p>Works well with an apriori (generative) model of the world, like the probability distribution of a coin toss. Example: Flip a fair coin 30 times. How likely it is to see 22 heads?</p>
<pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>
h_a &lt;-<span class="st"> </span><span class="dv">22</span>
result &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(<span class="kw">seq</span>(<span class="dv">1</span>, n, <span class="dv">1</span>), 
           <span class="op">~</span><span class="st"> </span><span class="kw">sum</span>(base<span class="op">::</span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dv">30</span>, <span class="dt">replace =</span> T)) <span class="op">&gt;=</span><span class="st"> </span>h_a) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>()

result<span class="op">/</span>n</code></pre>
<p><strong>Shuffling</strong></p>
<p>Comparing groups</p>
<pre class="sourceCode r"><code class="sourceCode r">iris_<span class="dv">100</span> &lt;-<span class="st"> </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>)]
(<span class="kw">t.test</span>(iris_<span class="dv">100</span>[<span class="dv">1</span><span class="op">:</span><span class="dv">50</span>, <span class="dv">1</span>], iris_<span class="dv">100</span>[<span class="dv">51</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">1</span>], 
       <span class="dt">alternative =</span> <span class="st">&#39;greater&#39;</span>))<span class="op">$</span>p.value</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">ha_shuffle &lt;-<span class="st"> </span><span class="cf">function</span>(df){
  
  result &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Species =</span> <span class="kw">sample</span>(Species, <span class="kw">n</span>())) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Species) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="dv">1</span>, mean) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mu_diff =</span> Sepal.Width <span class="op">-</span><span class="st"> </span><span class="kw">lag</span>(Sepal.Width)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(mu_diff)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">pull</span>(mu_diff)
  
  <span class="kw">return</span>(result <span class="op">&gt;=</span><span class="st"> </span>observed_diff)
  
}

observed_diff &lt;-<span class="st"> </span>iris_<span class="dv">100</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Species) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="dv">1</span>, mean) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mu_diff =</span> Sepal.Width <span class="op">-</span><span class="st"> </span><span class="kw">lag</span>(Sepal.Width)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(mu_diff)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">pull</span>(mu_diff)

n &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>
result &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(<span class="kw">seq</span>(<span class="dv">1</span>, n, <span class="dv">1</span>), <span class="op">~</span><span class="st"> </span><span class="kw">ha_shuffle</span>(iris_<span class="dv">100</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>()

result<span class="op">/</span>n</code></pre>
</div>
<div id="simple-bayes" class="section level2">
<h2><span class="header-section-number">9.8</span> Simple Bayes</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co">#Posterior prob that CTR_A &gt; CTR_B given data is np.mean(A_samples &gt; B_samples). Prob that lift of A relative to B is &gt;=3%: np.mean(100*(A_samples-B_samples)/B_samples &gt; 3)</span>
<span class="im">from</span> numpy.random <span class="im">import</span> beta <span class="im">as</span> beta_dist
<span class="im">import</span> numpy <span class="im">as</span> np
N_samp <span class="op">=</span> <span class="dv">10000</span> <span class="co">#number of samples to draw</span>
clicks_A <span class="op">=</span> <span class="dv">450</span>
views_A <span class="op">=</span> <span class="dv">56000</span>
clicks_B <span class="op">=</span> <span class="dv">345</span>
views_B <span class="op">=</span> <span class="dv">49000</span>
alpha <span class="op">=</span> <span class="fl">1.1</span>
beta <span class="op">=</span> <span class="fl">14.2</span>
A_samples <span class="op">=</span> beta_dist(clicks_A <span class="op">+</span> alpha, views_A <span class="op">-</span> clicks_A <span class="op">+</span> beta, N_samp)
B_samples <span class="op">=</span> beta_dist(clicks_B <span class="op">+</span> alpha, views_B <span class="op">-</span> clicks_B <span class="op">+</span> beta, N_samp)</code></pre>
</div>
<div id="ts-harmonic-regression" class="section level2">
<h2><span class="header-section-number">9.9</span> TS Harmonic Regression</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set up harmonic regressors of order 13</span>
harmonics &lt;-<span class="st"> </span><span class="kw">fourier</span>(gasoline, <span class="dt">K =</span> <span class="dv">13</span>)
<span class="co"># Fit regression model with ARIMA errors</span>
fit &lt;-<span class="st"> </span><span class="kw">auto.arima</span>(gasoline, <span class="dt">xreg =</span> harmonics, <span class="dt">seasonal =</span> <span class="ot">FALSE</span>)
<span class="co"># Forecasts next 3 years</span>
fc &lt;-<span class="st"> </span><span class="kw">forecast</span>(fit, <span class="dt">xreg =</span> <span class="kw">fourier</span>(gasoline, <span class="dt">K =</span> <span class="dv">13</span>, <span class="dt">h =</span> <span class="dv">156</span>))
<span class="co"># Plot forecasts fc</span>
<span class="kw">autoplot</span>(fc)</code></pre>
</div>
<div id="save-and-load-models" class="section level2">
<h2><span class="header-section-number">9.10</span> Save And Load Models</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> sklearn.externals <span class="im">import</span> joblib
joblib.dump(grid_search, <span class="st">&#39;model.pkl&#39;</span>)
grid_search <span class="op">=</span> joblib.load(<span class="st">&#39;model.pkl&#39;</span>)
model <span class="op">=</span> grid_search.best_estimator_</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">save</span>(m1, <span class="dt">file =</span> <span class="st">&quot;my_model1.rda&quot;</span>)
m1 =<span class="st"> </span><span class="kw">load</span>(<span class="st">&quot;my_model1.rda&quot;</span>)</code></pre>
</div>
<div id="lstm" class="section level2">
<h2><span class="header-section-number">9.11</span> LSTM</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Data Shape</span>
data_x <span class="op">=</span> np.array([
    <span class="co"># Datapoint 1: 3 features for timesteps 1 &amp; 2</span>
    [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]],
    <span class="co"># Datapoint 2</span>
    [[<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>], [<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>]]])</code></pre>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Prediction Example</span>
mdl.predict([[np.array([.<span class="dv">5</span>, <span class="fl">.6</span>, <span class="fl">.6</span>] <span class="op">+</span> [<span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">14</span>)]).reshape((<span class="dv">17</span>, <span class="dv">1</span>))]])[<span class="dv">0</span>]</code></pre>
</div>
<div id="logistic-regression-stats-models" class="section level2">
<h2><span class="header-section-number">9.12</span> Logistic Regression Stats Models</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.api <span class="im">as</span> sm
X <span class="op">=</span> sm.add_constant(X)
clf_lr <span class="op">=</span> sm.Logit(Y, X).fit(disp<span class="op">=</span><span class="va">False</span>)
<span class="bu">print</span>(results.summary())</code></pre>
</div>
<div id="function-negation" class="section level2">
<h2><span class="header-section-number">9.13</span> Function Negation</h2>
<pre class="sourceCode r"><code class="sourceCode r">not_in &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">negate</span>(<span class="op">%in%</span>)
not_between &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">negate</span>(between)</code></pre>
</div>
<div id="attach-date-csv" class="section level2">
<h2><span class="header-section-number">9.14</span> Attach Date CSV</h2>
<pre class="sourceCode python"><code class="sourceCode python">df.to_csv(<span class="st">&#39;</span><span class="sc">{}</span><span class="st">_model.csv&#39;</span>.<span class="bu">format</span>(<span class="bu">str</span>(datetime.datetime.now()).split(<span class="st">&#39; &#39;</span>)[<span class="dv">0</span>]))</code></pre>
</div>
<div id="ebb" class="section level2">
<h2><span class="header-section-number">9.15</span> EBB</h2>
<pre class="sourceCode r"><code class="sourceCode r">df_ebb &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">successes =</span> <span class="kw">sum</span>(success), <span class="dt">sample_size =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_ebb_estimate</span>(num_passed, sample_size)</code></pre>
</div>
<div id="plot-grid" class="section level2">
<h2><span class="header-section-number">9.16</span> Plot Grid</h2>
<pre class="sourceCode r"><code class="sourceCode r">gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(plots[[<span class="dv">1</span>]],plots[[<span class="dv">2</span>]],plots[[<span class="dv">3</span>]], plots[[<span class="dv">4</span>]],plots[[<span class="dv">5</span>]],plots[[<span class="dv">6</span>]], <span class="dt">nrow=</span><span class="dv">3</span>)</code></pre>
</div>
<div id="pairwise-scatterplot" class="section level2">
<h2><span class="header-section-number">9.17</span> Pairwise Scatterplot</h2>
<pre class="sourceCode r"><code class="sourceCode r">GGally<span class="op">::</span><span class="kw">ggpairs</span>(data, <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">colour =</span> category))</code></pre>
</div>
<div id="anti-join" class="section level2">
<h2><span class="header-section-number">9.18</span> Anti-join</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># https://stackoverflow.com/questions/38516664/anti-join-pandas</span>
<span class="co"># Identify what values are in TableB and not in TableA</span>
key_diff <span class="op">=</span> <span class="bu">set</span>(TableB.Key).difference(TableA.Key)
where_diff <span class="op">=</span> TableB.Key.isin(key_diff)
<span class="co"># Slice TableB accordingly and append to TableA</span>
TableA.append(TableB[where_diff], ignore_index<span class="op">=</span><span class="va">True</span>)</code></pre>
</div>
<div id="df-diff" class="section level2">
<h2><span class="header-section-number">9.19</span> DF Diff</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># https://stackoverflow.com/a/36893675/6627726</span>
merged <span class="op">=</span> df1.merge(df2, indicator<span class="op">=</span><span class="va">True</span>, how<span class="op">=</span><span class="st">&#39;outer&#39;</span>)
merged[merged[<span class="st">&#39;_merge&#39;</span>] <span class="op">==</span> <span class="st">&#39;right_only&#39;</span>]</code></pre>
</div>
<div id="csv-encoding-check" class="section level2">
<h2><span class="header-section-number">9.20</span> CSV Encoding Check</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> chardet
<span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;../input/kickstarter-projects/ks-projects-201801.csv&quot;</span>, <span class="st">&#39;rb&#39;</span>) <span class="im">as</span> rawdata:
    result <span class="op">=</span> chardet.detect(rawdata.read(<span class="dv">10000</span>))</code></pre>
</div>
<div id="pandas-profiling" class="section level2">
<h2><span class="header-section-number">9.21</span> Pandas Profiling</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas_profiling
pandas_profiling.ProfileReport(data)</code></pre>
</div>
<div id="read-sql" class="section level2">
<h2><span class="header-section-number">9.22</span> Read SQL</h2>
<pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">dbGetQuery</span>(con, <span class="dt">statement =</span> <span class="kw">read_file</span>(<span class="st">&#39;query.sql&#39;</span>))</code></pre>
</div>
<div id="extract-date" class="section level2">
<h2><span class="header-section-number">9.23</span> Extract Date</h2>
<pre class="sourceCode r"><code class="sourceCode r">StartTime <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.POSIXct</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">strftime</span>(<span class="dt">format=</span><span class="st">&quot;%Y-%m-%d&quot;</span>)
YearMonth =<span class="st"> </span>Day <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">strftime</span>(<span class="dt">format=</span><span class="st">&quot;%Y-%m&quot;</span>)
date =<span class="st"> </span>date <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.POSIXct</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">strptime</span>(<span class="st">&#39;%Y-%m-%d&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">strftime</span>(<span class="dt">format=</span><span class="st">&quot;%Y-%m-%d&quot;</span>)</code></pre>
</div>
<div id="ggplot-to-plotly" class="section level2">
<h2><span class="header-section-number">9.24</span> GGPLOT To Plotly</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplotly</span>(<span class="kw">ggplot</span>(<span class="kw">filter</span>(df_master2, group <span class="op">==</span><span class="st"> </span>x), <span class="kw">aes</span>(x,y, <span class="dt">label =</span> z, <span class="dt">color =</span> w)) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">.2</span>), <span class="dt">tooltip =</span> <span class="kw">c</span>(<span class="st">&#39;y&#39;</span>, <span class="st">&#39;label&#39;</span>))</code></pre>
</div>
<div id="custom-theme-for-plot" class="section level2">
<h2><span class="header-section-number">9.25</span> Custom Theme For Plot</h2>
<pre class="sourceCode r"><code class="sourceCode r">theme_ilo &lt;-<span class="st"> </span><span class="cf">function</span>() {
    <span class="kw">theme_minimal</span>() <span class="op">+</span>
<span class="st">        </span><span class="kw">theme</span>(
            <span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Bookman&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;gray25&quot;</span>),
            <span class="dt">plot.subtitle =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">12</span>),
            <span class="dt">plot.caption =</span> <span class="kw">element_text</span>(<span class="dt">color =</span> <span class="st">&quot;gray30&quot;</span>),
            <span class="dt">plot.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;gray95&quot;</span>),
            <span class="dt">plot.margin =</span> <span class="kw">unit</span>(<span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">10</span>), <span class="dt">units =</span> <span class="st">&quot;mm&quot;</span>)
        )
}</code></pre>
</div>
<div id="heatmap" class="section level2">
<h2><span class="header-section-number">9.26</span> Heatmap</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(corrplot)

df_fltrd <span class="op">%&gt;%</span><span class="st"> </span>
<span class="kw">select_if</span>(is.numeric) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">cor</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="kw">corrplot</span>(<span class="dt">method =</span> <span class="st">&quot;circle&quot;</span>, <span class="dt">is.corr =</span> <span class="ot">FALSE</span>)</code></pre>
</div>
<div id="linear-regression-statsmodels" class="section level2">
<h2><span class="header-section-number">9.27</span> Linear Regression Statsmodels</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.api <span class="im">as</span> sm
X <span class="op">=</span> sm.add_constant(X)
mdl <span class="op">=</span> sm.OLS(Y, X).fit(disp <span class="op">=</span> <span class="va">False</span>)
<span class="bu">print</span>(mdl.summary())</code></pre>
</div>
<div id="linear-regression-by-groups" class="section level2">
<h2><span class="header-section-number">9.28</span> Linear Regression By Groups</h2>
<pre class="sourceCode r"><code class="sourceCode r">librarytidyverse<span class="er">)</span>

mtcars <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(cyl) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">split</span>(.<span class="op">$</span>cyl) <span class="op">%&gt;%</span><span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(<span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> .))
mtcars <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(cyl) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nest</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(data, <span class="cf">function</span>(x) <span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> x) ))</code></pre>
</div>
<div id="rml-pipeline" class="section level2">
<h2><span class="header-section-number">9.29</span> RML Pipeline</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># categorical comparison to target</span>
<span class="kw">chisq.test</span>(<span class="kw">table</span>(<span class="kw">cut</span>(iris<span class="op">$</span>Sepal.Length, <span class="dv">3</span>), iris<span class="op">$</span>Species))

<span class="co"># Variable Importance</span>
varImp</code></pre>
</div>
<div id="rowwise" class="section level2">
<h2><span class="header-section-number">9.30</span> Rowwise</h2>
<pre class="sourceCode python"><code class="sourceCode python">rectangles <span class="op">=</span> [
    { <span class="st">&#39;height&#39;</span>: <span class="dv">40</span>, <span class="st">&#39;width&#39;</span>: <span class="dv">10</span> },
    { <span class="st">&#39;height&#39;</span>: <span class="dv">20</span>, <span class="st">&#39;width&#39;</span>: <span class="dv">9</span> },
    { <span class="st">&#39;height&#39;</span>: <span class="fl">3.4</span>, <span class="st">&#39;width&#39;</span>: <span class="dv">4</span> }
]
rectangles_df <span class="op">=</span> pd.DataFrame(rectangles)
<span class="kw">def</span> calculate_area(row):
    <span class="cf">return</span> row[<span class="st">&#39;height&#39;</span>] <span class="op">*</span> row[<span class="st">&#39;width&#39;</span>]
rectangles_df.<span class="bu">apply</span>(calculate_area, axis<span class="op">=</span><span class="dv">1</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)

mtcars <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mymean =</span> <span class="kw">mean</span>(<span class="kw">c</span>(cyl,mpg))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(cyl, mpg, mymean)

df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mu =</span> <span class="kw">select</span>(., R1<span class="op">:</span>R16) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pmap_dbl</span>(<span class="op">~</span><span class="kw">mean</span>(<span class="kw">c</span>(...))))

calc_row_mean &lt;-<span class="st"> </span><span class="cf">function</span>(li){
  
  df &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(li)
  
  result &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(<span class="kw">contains</span>(<span class="st">&quot;Round&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">mu =</span> <span class="kw">rowMeans</span>(.)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">pull</span>(mu)
  
  <span class="kw">return</span>(result)
  
}</code></pre>
</div>
<div id="sampling-file" class="section level2">
<h2><span class="header-section-number">9.31</span> Sampling File</h2>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">pip</span> install subsample
<span class="ex">subsample</span> -s 8 -n 100000 test.csv -r <span class="op">&gt;</span> test_sample.csv</code></pre>
</div>
<div id="sql-dummy-columns" class="section level2">
<h2><span class="header-section-number">9.32</span> SQL Dummy Columns</h2>
<pre class="sourceCode sql"><code class="sourceCode sql"><span class="kw">SELECT</span> <span class="st">&#39;Dummy Column Text&#39;</span> <span class="kw">as</span> DUMMYCOL <span class="kw">FROM</span> tbl</code></pre>
</div>
<div id="model-calibration" class="section level2">
<h2><span class="header-section-number">9.33</span> Model Calibration</h2>
<p>A quick way of visualizing model calibration without having to manually bin any observations</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(fitted_probability, binary_class_indicator)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>()</code></pre>
</div>
<div id="binning-rule-of-thumb" class="section level2">
<h2><span class="header-section-number">9.34</span> Binning Rule Of Thumb</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># https://stats.stackexchange.com/questions/798/calculating-optimal-number-of-bins-in-a-histogram/862#862</span>
<span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(x), <span class="dt">binwidth =</span> <span class="kw">diff</span>(<span class="kw">range</span>(x)) <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">IQR</span>(x) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x)<span class="op">^</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)))</code></pre>
</div>
<div id="featuretools" class="section level2">
<h2><span class="header-section-number">9.35</span> Featuretools</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co">#https://stackoverflow.com/questions/50145953/how-to-apply-deep-feature-synthesis-to-a-single-table</span>
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> featuretools <span class="im">as</span> ft
df <span class="op">=</span> pd.read_csv(<span class="st">&#39;iris.csv&#39;</span>)
df <span class="op">=</span> df.reset_index()
es <span class="op">=</span> ft.EntitySet(<span class="bu">id</span> <span class="op">=</span> <span class="st">&quot;test&quot;</span>) <span class="co">#.drop(columns = [&#39;species&#39;], axis = 1)</span>
es <span class="op">=</span> es.entity_from_dataframe(entity_id <span class="op">=</span> <span class="st">&#39;d&#39;</span>, dataframe <span class="op">=</span> df, make_index<span class="op">=</span><span class="va">True</span>, index<span class="op">=</span><span class="st">&#39;ind&#39;</span>)
<span class="co"># produces 626 features</span>
fm, features <span class="op">=</span> ft.dfs(
    entityset <span class="op">=</span> es, 
    target_entity <span class="op">=</span> <span class="st">&#39;d&#39;</span>,
    agg_primitives <span class="op">=</span> [<span class="st">&#39;mean&#39;</span>, <span class="st">&#39;max&#39;</span>, <span class="st">&#39;percent_true&#39;</span>, <span class="st">&#39;last&#39;</span>],
    trans_primitives <span class="op">=</span> [<span class="st">&#39;subtract&#39;</span>, <span class="st">&#39;divide&#39;</span>]
)
<span class="co"># produces no new features</span>
_, features2 <span class="op">=</span> ft.dfs(
    entityset <span class="op">=</span> es, 
    target_entity <span class="op">=</span> <span class="st">&#39;d&#39;</span>,
    max_depth <span class="op">=</span> <span class="dv">2</span>
)</code></pre>
</div>
<div id="skimage" class="section level2">
<h2><span class="header-section-number">9.36</span> Skimage</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
<span class="im">from</span> skimage <span class="im">import</span> io
<span class="im">from</span> skimage.transform <span class="im">import</span> resize
image <span class="op">=</span> io.imread(<span class="vs">r&#39;test.jpg&#39;</span>)
image2 <span class="op">=</span> resize(image,(<span class="dv">200</span>, <span class="dv">200</span>),mode<span class="op">=</span><span class="st">&#39;edge&#39;</span>)
plt.imshow(image)
plt.show()</code></pre>
</div>
<div id="shap" class="section level2">
<h2><span class="header-section-number">9.37</span> SHAP</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> shap
mdl.fit(X_train, y_train)
explainer <span class="op">=</span> shap.TreeExplainer(clf)
shap_values <span class="op">=</span> explainer.shap_values(X_train)
<span class="co">#all records explained (both lines of code)</span>
shap.summary_plot(shap_values, X_train)
shap.summary_plot(shap_values, X_train, plot_type <span class="op">=</span> <span class="st">&quot;bar&quot;</span>)
df_shap <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(<span class="bu">zip</span>(np.mean(shap_values, axis <span class="op">=</span> <span class="dv">0</span>), X_train.columns)),
                       columns <span class="op">=</span> [<span class="st">&#39;shap_mean&#39;</span>, <span class="st">&#39;feature&#39;</span>])
df_shap <span class="op">=</span> df_shap[[<span class="st">&#39;feature&#39;</span>, <span class="st">&#39;shap_mean&#39;</span>]]
df_shap[<span class="st">&#39;shap_mean_abs&#39;</span>] <span class="op">=</span> np.absolute(df_shap[<span class="st">&#39;shap_mean&#39;</span>])
df_shap.sort_values([<span class="st">&#39;shap_mean_abs&#39;</span>], ascending <span class="op">=</span> <span class="va">False</span>, inplace <span class="op">=</span> <span class="va">True</span>)
<span class="im">import</span> shap
<span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
attribution_data <span class="op">=</span> np.array(train_data[:<span class="dv">50</span>])
explainer <span class="op">=</span> shap.DeepExplainer(model, attribution_data)</code></pre>
</div>
<div id="hyperband-cv" class="section level2">
<h2><span class="header-section-number">9.38</span> Hyperband CV</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co">#https://github.com/civisanalytics/civisml-extensions/blob/master/civismlext/hyperband.py</span>
<span class="im">from</span> civismlext.hyperband <span class="im">import</span> HyperbandSearchCV</code></pre>
</div>
<div id="csv-to-db" class="section level2">
<h2><span class="header-section-number">9.39</span> CSV To DB</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co">#source: http://bit.ly/294gmmP</span>
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> sqlite3
<span class="co"># pass in column names for each CSV</span>
r_cols <span class="op">=</span> [<span class="st">&#39;user_id&#39;</span>, <span class="st">&#39;movie_id&#39;</span>, <span class="st">&#39;rating&#39;</span>, <span class="st">&#39;unix_timestamp&#39;</span>]
ratings <span class="op">=</span> pd.read_csv(fdata, sep<span class="op">=</span><span class="st">&#39;;&#39;</span>, names<span class="op">=</span>r_cols, compression<span class="op">=</span><span class="st">&#39;gzip&#39;</span>)
m_cols <span class="op">=</span> [<span class="st">&#39;movie_id&#39;</span>, <span class="st">&#39;title&#39;</span>, <span class="st">&#39;genres&#39;</span>]
movies <span class="op">=</span> pd.read_csv(fitem, sep<span class="op">=</span><span class="st">&#39;;&#39;</span>, names<span class="op">=</span>m_cols, dtype<span class="op">=</span>{<span class="st">&#39;title&#39;</span>: <span class="bu">object</span>, <span class="st">&#39;genres&#39;</span>: <span class="bu">object</span>})
sqlite_norm <span class="op">=</span> <span class="st">&quot;movielens-norm.sqlite&quot;</span>
<span class="cf">if</span> os.path.exists(sqlite_norm):
    os.unlink(sqlite_norm)
conn <span class="op">=</span> sqlite3.<span class="ex">connect</span>(sqlite_norm)
conn.text_factory <span class="op">=</span> <span class="bu">str</span>   <span class="co"># Shut up problems with Unicode</span>
ratings.to_sql(<span class="st">&quot;ratings&quot;</span>, conn)
movies.to_sql(<span class="st">&quot;movies&quot;</span>, conn)
conn.close()</code></pre>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">sqlite3</span> db_name.db
<span class="ex">.mode</span> csv db_name
<span class="ex">.import</span> data.csv db_name</code></pre>
</div>
<div id="xgboost-light-gbm" class="section level2">
<h2><span class="header-section-number">9.40</span> Xgboost &amp; Light GBM</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> xgboost <span class="im">as</span> xgb
<span class="im">import</span> lightgbm <span class="im">as</span> lgb
param_grid_lgb <span class="op">=</span> {
    <span class="st">&#39;learning_rate&#39;</span>: [<span class="fl">0.005</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>], <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">250</span>, <span class="dv">500</span>],
    <span class="st">&#39;num_leaves&#39;</span>: [<span class="dv">6</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">250</span>, <span class="dv">500</span>], <span class="st">&#39;boosting_type&#39;</span>: [<span class="st">&#39;gbdt&#39;</span>, <span class="st">&#39;rf&#39;</span>],
    <span class="st">&#39;colsample_bytree&#39;</span> : [<span class="fl">0.65</span>, <span class="dv">1</span>], <span class="st">&#39;subsample&#39;</span>: [<span class="fl">0.7</span>, <span class="fl">0.9</span>],
    <span class="st">&#39;reg_alpha&#39;</span>: [<span class="dv">0</span>, <span class="fl">1.2</span>], <span class="st">&#39;reg_lambda&#39;</span>: [<span class="dv">0</span>, <span class="dv">2</span>],
    }
param_grid_xgb <span class="op">=</span> {<span class="st">&#39;bootstrap&#39;</span>: [<span class="va">True</span>, <span class="va">False</span>],
 <span class="st">&#39;max_depth&#39;</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">70</span>, <span class="dv">80</span>, <span class="dv">90</span>, <span class="dv">100</span>, <span class="va">None</span>],
 <span class="st">&#39;max_features&#39;</span>: [<span class="st">&#39;auto&#39;</span>, <span class="st">&#39;sqrt&#39;</span>],
 <span class="st">&#39;min_samples_leaf&#39;</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>],
 <span class="st">&#39;min_samples_split&#39;</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],
 <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">200</span>, <span class="dv">400</span>, <span class="dv">600</span>, <span class="dv">800</span>, <span class="dv">1000</span>, <span class="dv">1200</span>, <span class="dv">1400</span>, <span class="dv">1600</span>, <span class="dv">1800</span>, <span class="dv">2000</span>]}</code></pre>
</div>
<div id="bayesian-cv" class="section level2">
<h2><span class="header-section-number">9.41</span> Bayesian CV</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> lightgbm <span class="im">as</span> lgb
<span class="im">from</span> scipy.stats <span class="im">import</span> randint <span class="im">as</span> sp_randint
<span class="im">from</span> skopt <span class="im">import</span> BayesSearchCV
<span class="im">from</span> skopt.space <span class="im">import</span> Real, Integer, Categorical
<span class="co">#v1: Light GBM</span>
bayes_cv_tuner <span class="op">=</span> BayesSearchCV(
    estimator <span class="op">=</span> lgb.LGBMClassifier(
        objective<span class="op">=</span><span class="st">&#39;binary&#39;</span>,
        metric<span class="op">=</span><span class="st">&#39;auc&#39;</span>,
        n_jobs<span class="op">=</span><span class="dv">1</span>,
        verbose<span class="op">=</span><span class="dv">0</span>
    ),
    search_spaces <span class="op">=</span> {
        <span class="st">&#39;learning_rate&#39;</span>: (<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="st">&#39;log-uniform&#39;</span>),
        <span class="st">&#39;num_leaves&#39;</span>: (<span class="dv">1</span>, <span class="dv">100</span>),      
        <span class="st">&#39;max_depth&#39;</span>: (<span class="dv">0</span>, <span class="dv">50</span>),
        <span class="st">&#39;min_child_samples&#39;</span>: (<span class="dv">0</span>, <span class="dv">50</span>),
        <span class="st">&#39;max_bin&#39;</span>: (<span class="dv">100</span>, <span class="dv">1000</span>),
        <span class="st">&#39;subsample&#39;</span>: (<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="st">&#39;uniform&#39;</span>),
        <span class="st">&#39;subsample_freq&#39;</span>: (<span class="dv">0</span>, <span class="dv">10</span>),
        <span class="st">&#39;colsample_bytree&#39;</span>: (<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="st">&#39;uniform&#39;</span>),
        <span class="st">&#39;min_child_weight&#39;</span>: (<span class="dv">0</span>, <span class="dv">10</span>),
        <span class="st">&#39;subsample_for_bin&#39;</span>: (<span class="dv">100000</span>, <span class="dv">500000</span>),
        <span class="st">&#39;reg_lambda&#39;</span>: (<span class="fl">1e-9</span>, <span class="dv">1000</span>, <span class="st">&#39;log-uniform&#39;</span>),
        <span class="st">&#39;reg_alpha&#39;</span>: (<span class="fl">1e-9</span>, <span class="fl">1.0</span>, <span class="st">&#39;log-uniform&#39;</span>),
        <span class="st">&#39;scale_pos_weight&#39;</span>: (<span class="fl">1e-6</span>, <span class="dv">500</span>, <span class="st">&#39;log-uniform&#39;</span>),
        <span class="st">&#39;n_estimators&#39;</span>: (<span class="dv">50</span>, <span class="dv">100</span>),
    },    
    scoring <span class="op">=</span> <span class="st">&#39;roc_auc&#39;</span>,
    cv <span class="op">=</span> sk_ms.StratifiedKFold(
        n_splits<span class="op">=</span><span class="dv">3</span>,
        shuffle<span class="op">=</span><span class="va">True</span>,
        random_state <span class="op">=</span> <span class="dv">42</span>
    ),
    n_jobs <span class="op">=</span> <span class="dv">3</span>,
    n_iter <span class="op">=</span> <span class="dv">10</span>,   
    verbose <span class="op">=</span> <span class="dv">0</span>,
    refit <span class="op">=</span> <span class="va">True</span>,
    random_state <span class="op">=</span> <span class="dv">42</span>
)
result <span class="op">=</span> bayes_cv_tuner.fit(X_train.values, y_train.values)
<span class="co">#v2: XGBoost</span>
bayes_cv_tuner <span class="op">=</span> BayesSearchCV(
    estimator <span class="op">=</span> xgb.XGBClassifier(
        n_jobs <span class="op">=</span> <span class="dv">1</span>,
        objective <span class="op">=</span> <span class="st">&#39;binary:logistic&#39;</span>,
        eval_metric <span class="op">=</span> <span class="st">&#39;auc&#39;</span>,
        silent<span class="op">=</span><span class="dv">1</span>,
        tree_method<span class="op">=</span><span class="st">&#39;approx&#39;</span>
    ),
    search_spaces <span class="op">=</span> {
        <span class="st">&#39;learning_rate&#39;</span>: (<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="st">&#39;log-uniform&#39;</span>),
        <span class="st">&#39;min_child_weight&#39;</span>: (<span class="dv">0</span>, <span class="dv">10</span>),
        <span class="st">&#39;max_depth&#39;</span>: (<span class="dv">0</span>, <span class="dv">50</span>),
        <span class="st">&#39;max_delta_step&#39;</span>: (<span class="dv">0</span>, <span class="dv">20</span>),
        <span class="st">&#39;subsample&#39;</span>: (<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="st">&#39;uniform&#39;</span>),
        <span class="st">&#39;colsample_bytree&#39;</span>: (<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="st">&#39;uniform&#39;</span>),
        <span class="st">&#39;colsample_bylevel&#39;</span>: (<span class="fl">0.01</span>, <span class="fl">1.0</span>, <span class="st">&#39;uniform&#39;</span>),
        <span class="st">&#39;reg_lambda&#39;</span>: (<span class="fl">1e-9</span>, <span class="dv">1000</span>, <span class="st">&#39;log-uniform&#39;</span>),
        <span class="st">&#39;reg_alpha&#39;</span>: (<span class="fl">1e-9</span>, <span class="fl">1.0</span>, <span class="st">&#39;log-uniform&#39;</span>),
        <span class="st">&#39;gamma&#39;</span>: (<span class="fl">1e-9</span>, <span class="fl">0.5</span>, <span class="st">&#39;log-uniform&#39;</span>),
        <span class="st">&#39;min_child_weight&#39;</span>: (<span class="dv">0</span>, <span class="dv">5</span>),
        <span class="st">&#39;n_estimators&#39;</span>: (<span class="dv">50</span>, <span class="dv">100</span>),
        <span class="st">&#39;scale_pos_weight&#39;</span>: (<span class="fl">1e-6</span>, <span class="dv">500</span>, <span class="st">&#39;log-uniform&#39;</span>)
    },    
    scoring <span class="op">=</span> <span class="st">&#39;roc_auc&#39;</span>,
    cv <span class="op">=</span> sk_ms.StratifiedKFold(
        n_splits<span class="op">=</span><span class="dv">3</span>,
        shuffle<span class="op">=</span><span class="va">True</span>,
        random_state<span class="op">=</span><span class="dv">42</span>
    ),
    n_jobs <span class="op">=</span> <span class="dv">3</span>,
    n_iter <span class="op">=</span> <span class="dv">10</span>,   
    verbose <span class="op">=</span> <span class="dv">0</span>,
    refit <span class="op">=</span> <span class="va">True</span>,
    random_state <span class="op">=</span> <span class="dv">42</span>
)
<span class="co">#v3</span>
param_grid <span class="op">=</span> {
    <span class="st">&#39;learning_rate&#39;</span>: Real(<span class="fl">0.005</span>, <span class="fl">0.1</span>), <span class="st">&#39;n_estimators&#39;</span>: Integer(<span class="dv">10</span>, <span class="dv">500</span>),
    <span class="st">&#39;num_leaves&#39;</span>: Integer(<span class="dv">6</span>, <span class="dv">50</span>), <span class="st">&#39;boosting_type&#39;</span> : Categorical([<span class="st">&#39;gbdt&#39;</span>, <span class="st">&#39;rf&#39;</span>]),
    <span class="st">&#39;colsample_bytree&#39;</span> : Real(<span class="fl">0.65</span>, <span class="dv">1</span>), <span class="st">&#39;subsample&#39;</span> : Real(<span class="fl">0.7</span>, <span class="fl">0.9</span>),
    <span class="st">&#39;reg_alpha&#39;</span> : Real(<span class="dv">0</span>, <span class="fl">1.2</span>), <span class="st">&#39;reg_lambda&#39;</span> : Real(<span class="dv">0</span>, <span class="dv">2</span>),
    }
clf_tuned <span class="op">=</span> BayesSearchCV(clf, param_grid, cv <span class="op">=</span> <span class="dv">5</span>, random_state <span class="op">=</span> <span class="dv">8</span>, scoring <span class="op">=</span> <span class="st">&#39;f1&#39;</span>, n_jobs <span class="op">=</span> <span class="dv">-1</span>)</code></pre>
</div>
<div id="pyspark" class="section level2">
<h2><span class="header-section-number">9.42</span> Pyspark</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Cheatsheet: https://www.qubole.com/resources/pyspark-cheatsheet/</span>
<span class="co"># Spark only handles numeric data. </span>
<span class="co"># selectExpr() takes SQL expressions as a string.</span>
<span class="co"># Spark&#39;s assumes the target is called &#39;label&#39; in ML. Everything else is a feature.</span>
<span class="co"># Estimator classes are for modeling and all implement a .fit() method. eg. StringIndexerModel for including categorical data saved as strings in your models</span>
<span class="co"># It&#39;s important to split the data after all the transformations because operations like StringIndexer don&#39;t always produce the same index even when given the same list of strings.</span>
<span class="im">import</span> findspark
findspark.init()
<span class="im">import</span> findspark
findspark.init()
<span class="im">import</span> pyspark
<span class="im">import</span> random
<span class="im">import</span> pyspark
<span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession
<span class="im">from</span> pyspark.ml.feature <span class="im">import</span> StringIndexer, OneHotEncoder, VectorAssembler
<span class="im">from</span> pyspark.ml <span class="im">import</span> Pipeline
<span class="im">from</span> pyspark.ml.classification <span class="im">import</span> LogisticRegression
<span class="im">import</span> pyspark.ml.evaluation <span class="im">as</span> evals
<span class="im">import</span> pyspark.ml.tuning <span class="im">as</span> tune
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> pyspark
<span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession
<span class="im">import</span> pyspark.sql.functions <span class="im">as</span> F
<span class="im">from</span> pyspark.ml <span class="im">import</span> Pipeline
<span class="im">from</span> pyspark.ml.classification <span class="im">import</span> LogisticRegression
<span class="im">import</span> pyspark.ml.evaluation <span class="im">as</span> evals
<span class="im">import</span> pyspark.ml.tuning <span class="im">as</span> tune
sc <span class="op">=</span> pyspark.SparkContext()
spark <span class="op">=</span> SparkSession.builder.getOrCreate() <span class="co"># SparkSession.builder.appName(&#39;chosenName&#39;).getOrCreate()</span>
sc <span class="op">=</span> pyspark.SparkContext()
spark <span class="op">=</span> SparkSession.builder.appName(<span class="st">&#39;example&#39;</span>).getOrCreate()
sc <span class="op">=</span> pyspark.SparkContext(appName<span class="op">=</span><span class="st">&quot;Pi&quot;</span>)
num_samples <span class="op">=</span> <span class="dv">100000000</span>
<span class="kw">def</span> inside(p):     
    x, y <span class="op">=</span> random.random(), random.random()
    <span class="cf">return</span> x<span class="op">*</span>x <span class="op">+</span> y<span class="op">*</span>y <span class="op">&lt;</span> <span class="dv">1</span>
count <span class="op">=</span> sc.parallelize(<span class="bu">range</span>(<span class="dv">0</span>, num_samples)).<span class="bu">filter</span>(inside).count()
pi <span class="op">=</span> <span class="dv">4</span> <span class="op">*</span> count <span class="op">/</span> num_samples
<span class="bu">print</span>(pi)
df <span class="op">=</span> spark.read.csv(<span class="st">&#39;data.csv&#39;</span>, header <span class="op">=</span> <span class="va">True</span>)
df.show(<span class="dv">5</span>)
df.columns
<span class="co"># Preprocessing</span>
df <span class="op">=</span> df.withColumn(<span class="st">&quot;label&quot;</span>, df[<span class="st">&quot;target&quot;</span>].cast(<span class="st">&#39;integer&#39;</span>))
scf_indexer <span class="op">=</span> StringIndexer(inputCol <span class="op">=</span> <span class="st">&quot;some_cat_feature&quot;</span>, outputCol <span class="op">=</span> <span class="st">&quot;some_cat_feature_index&quot;</span>)
scf_encoder <span class="op">=</span> OneHotEncoder(inputCol <span class="op">=</span> <span class="st">&quot;some_cat_feature_index&quot;</span>, outputCol <span class="op">=</span> <span class="st">&quot;some_cat_feature_fact&quot;</span>)
feature_cols <span class="op">=</span> [<span class="st">&quot;some list of column names&quot;</span>]
vec_assembler <span class="op">=</span> VectorAssembler(inputCols <span class="op">=</span> feature_cols, 
                                outputCol <span class="op">=</span> <span class="st">&quot;features&quot;</span>)
pipe <span class="op">=</span> Pipeline(stages <span class="op">=</span> [scf_indexer, scf_encoder, vec_assembler])
piped_data <span class="op">=</span> pipe.fit(df).transform(df)
training, test <span class="op">=</span> piped_data.randomSplit([.<span class="dv">8</span>, <span class="fl">.2</span>])
<span class="co"># Model</span>
clf_lr <span class="op">=</span> LogisticRegression()
evaluator <span class="op">=</span> evals.BinaryClassificationEvaluator(metricName <span class="op">=</span> <span class="st">&quot;areaUnderROC&quot;</span>)
grid <span class="op">=</span> tune.ParamGridBuilder()
grid <span class="op">=</span> grid.addGrid(clf_lr.regParam, np.arange(<span class="dv">0</span>, <span class="fl">.1</span>, <span class="fl">.01</span>))
grid <span class="op">=</span> grid.addGrid(clf_lr.elasticNetParam, [<span class="dv">0</span>, <span class="dv">1</span>])
grid <span class="op">=</span> grid.build()
clf_lr_cv <span class="op">=</span> tune.CrossValidator(
    estimator <span class="op">=</span> clf_lr,
    estimatorParamMaps <span class="op">=</span> grid,
    evaluator <span class="op">=</span> evaluator,
    numFolds <span class="op">=</span> <span class="dv">5</span>
               )
best_clf_lr <span class="op">=</span> clf_lr_cv.fit(training).bestModel
results <span class="op">=</span> best_clf_lr.transform(training)
<span class="bu">print</span>(evaluator.evaluate(results))
<span class="co">## List tables</span>
spark.catalog.listTables()
<span class="co">## Access and display data</span>
query <span class="op">=</span> <span class="st">&quot;FROM flights SELECT * LIMIT 10&quot;</span>
flights10 <span class="op">=</span> spark.sql(query)
flights10.show()
<span class="co">## Cast</span>
df[<span class="st">&#39;g&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;g&#39;</span>].astype(<span class="bu">str</span>)
<span class="co">## Read from csv</span>
df<span class="op">=</span> spark.read.csv(file_path, header <span class="op">=</span> <span class="va">True</span>)
df <span class="op">=</span> spark.read.csv(<span class="st">&#39;fileNameWithPath&#39;</span>, mode<span class="op">=</span><span class="st">&quot;DROPMALFORMED&quot;</span>,inferSchema<span class="op">=</span><span class="va">True</span>, header <span class="op">=</span> <span class="va">True</span>)
df <span class="op">=</span> spark.read.<span class="bu">format</span>(<span class="st">&quot;csv&quot;</span>).option(<span class="st">&quot;header&quot;</span>,<span class="st">&quot;true&quot;</span>).option(<span class="st">&quot;inferSchema&quot;</span>,<span class="st">&quot;true&quot;</span>).load(<span class="st">&quot;john_doe.csv&quot;</span>)
<span class="co">## Spark df to pandas and vice versa</span>
toPandas()
spark_temp <span class="op">=</span> spark.createDataFrame(pd_temp)
<span class="co">## Add to the catalog</span>
spark_temp.createOrReplaceTempView(<span class="st">&quot;temp&quot;</span>)
<span class="co">## Mutate</span>
df <span class="op">=</span> df.withColumn(<span class="st">&quot;newCol&quot;</span>, df.oldCol <span class="op">+</span> <span class="dv">1</span>)
model_data <span class="op">=</span> model_data.withColumn(<span class="st">&quot;arr_delay&quot;</span>, model_data.arr_delay.cast(<span class="st">&#39;integer&#39;</span>))
model_data <span class="op">=</span> model_data.withColumn(<span class="st">&quot;plane_age&quot;</span>, model_data.year <span class="op">-</span> model_data.plane_year)
<span class="co">## Create the DataFrame flights</span>
flights <span class="op">=</span> spark.table(<span class="st">&#39;flights&#39;</span>)
<span class="co">## Get column names</span>
spark_df.schema.names
spark_df.printSchema()
<span class="co">## Filter: takes either a Spark Column of boolean (True/False) values or the WHERE clause of a SQL expression as a string</span>
long_flights1 <span class="op">=</span> flights.<span class="bu">filter</span>(<span class="st">&#39;distance &gt; 1000&#39;</span>)
long_flights2 <span class="op">=</span> flights.<span class="bu">filter</span>(flights.distance <span class="op">&gt;</span> <span class="dv">1000</span>)
model_data <span class="op">=</span> model_data.<span class="bu">filter</span>(<span class="st">&quot;arr_delay is not NULL and dep_delay is not NULL and air_time is not NULL and plane_year is not NULL&quot;</span>)
<span class="co">## Groupby examples</span>
flights.<span class="bu">filter</span>(flights.origin <span class="op">==</span> <span class="st">&quot;PDX&quot;</span>).groupBy().<span class="bu">min</span>(<span class="st">&quot;distance&quot;</span>).show()
flights.<span class="bu">filter</span>(flights.carrier<span class="op">==</span><span class="st">&#39;DL&#39;</span>).<span class="bu">filter</span>(flights.origin<span class="op">==</span><span class="st">&#39;SEA&#39;</span>).groupBy().avg(<span class="st">&#39;air_time&#39;</span>).show()
flights.withColumn(<span class="st">&quot;duration_hrs&quot;</span>, flights.air_time<span class="op">/</span><span class="dv">60</span>).groupBy().<span class="bu">sum</span>(<span class="st">&#39;duration_hrs&#39;</span>).show()
<span class="co">## Spark functions</span>
by_month_dest.agg(F.stddev(<span class="st">&#39;dep_delay&#39;</span>)).show()
<span class="co">## Drop column</span>
final_test_data.drop(<span class="st">&#39;State&#39;</span>)
<span class="co">## Dummying</span>
<span class="co">#The first step to encoding your categorical feature is to create a StringIndexer. Members of this class are #Estimators that take a DataFrame with a column of strings and map each unique string to a number. Then, the #Estimator returns a Transformer that takes a DataFrame, attaches the mapping to it as metadata, and returns a #new DataFrame with a numeric column corresponding to the string column.</span>
<span class="co">#The second step is to encode this numeric column as a one-hot vector using a OneHotEncoder. This works exactly #the same way as the StringIndexer by creating an Estimator and then a Transformer</span>
<span class="co">## Create a StringIndexer</span>
carr_indexer <span class="op">=</span> StringIndexer(inputCol<span class="op">=</span><span class="st">&quot;carrier&quot;</span>, outputCol<span class="op">=</span><span class="st">&quot;carrier_index&quot;</span>)
<span class="co">## Create a OneHotEncoder</span>
carr_encoder <span class="op">=</span> OneHotEncoder(inputCol<span class="op">=</span><span class="st">&quot;carrier_index&quot;</span>, outputCol<span class="op">=</span><span class="st">&quot;carrier_fact&quot;</span>)
<span class="co">## Make a VectorAssembler</span>
vec_assembler <span class="op">=</span> VectorAssembler(inputCols<span class="op">=</span>[<span class="st">&quot;month&quot;</span>, <span class="st">&quot;air_time&quot;</span>, <span class="st">&quot;carrier_fact&quot;</span>, <span class="st">&quot;dest_fact&quot;</span>, <span class="st">&quot;plane_age&quot;</span>], outputCol<span class="op">=</span><span class="st">&quot;features&quot;</span>)
<span class="co">## Import &amp; Make Pipeline</span>
flights_pipe <span class="op">=</span> Pipeline(stages<span class="op">=</span>[dest_indexer, dest_encoder, carr_indexer, carr_encoder, vec_assembler])
<span class="co">## Fit and transform the data</span>
piped_data <span class="op">=</span> flights_pipe.fit(model_data).transform(model_data)
<span class="co">## Train-test split</span>
training, test <span class="op">=</span> piped_data.randomSplit([.<span class="dv">6</span>, <span class="fl">.4</span>])
<span class="co">## Tuning &amp; Selection</span>
<span class="co">## Import LogisticRegression</span>
<span class="co">## Create a LogisticRegression Estimator</span>
lr <span class="op">=</span> LogisticRegression()
<span class="co">## Create a BinaryClassificationEvaluator</span>
evaluator <span class="op">=</span> evals.BinaryClassificationEvaluator(metricName<span class="op">=</span><span class="st">&quot;areaUnderROC&quot;</span>)
<span class="co">## Import the tuning submodule</span>
<span class="co">## Create the parameter grid</span>
grid <span class="op">=</span> tune.ParamGridBuilder()
<span class="co">## Add the hyperparameter</span>
grid <span class="op">=</span> grid.addGrid(lr.regParam, np.arange(<span class="dv">0</span>, <span class="fl">.1</span>, <span class="fl">.01</span>))
grid <span class="op">=</span> grid.addGrid(lr.elasticNetParam, [<span class="dv">0</span>, <span class="dv">1</span>])
<span class="co">## Build the grid</span>
grid <span class="op">=</span> grid.build()
<span class="co">## Create the CrossValidator</span>
cv <span class="op">=</span> tune.CrossValidator(
estimator<span class="op">=</span>lr,
estimatorParamMaps<span class="op">=</span>grid,
evaluator<span class="op">=</span>evaluator
               )
<span class="co">## Fit cross validation models</span>
models <span class="op">=</span> cv.fit(training)
<span class="co">## Extract the best model</span>
best_lr <span class="op">=</span> models.bestModel
<span class="co">## Use the model to predict the test set</span>
test_results <span class="op">=</span> best_lr.transform(test)
<span class="co">## Evaluate the predictions</span>
<span class="bu">print</span>(evaluator.evaluate(test_results))
sc.stop()</code></pre>
</div>
<div id="sparklyr" class="section level2">
<h2><span class="header-section-number">9.43</span> Sparklyr</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># feature transforms: ft_, ml functions: ml_, spark df functions: sdf_</span>

<span class="kw">library</span>(sparklyr)

sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master=</span><span class="st">&quot;local&quot;</span>)
config &lt;-<span class="st"> </span><span class="kw">spark_config</span>()
config<span class="op">$</span>spark.executor.cores &lt;-<span class="st"> </span><span class="dv">8</span>
config<span class="op">$</span>spark.executor.memory &lt;-<span class="st"> &quot;25G&quot;</span>

flights &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, flights, <span class="st">&quot;flights&quot;</span>)
<span class="kw">src_tbls</span>(sc)

iris_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spark_apply</span>(
    <span class="cf">function</span>(e) <span class="kw">summary</span>(<span class="kw">lm</span>(Petal_Length <span class="op">~</span><span class="st"> </span>Petal_Width, e))<span class="op">$</span>r.squared,
    <span class="dt">names =</span> <span class="st">&quot;r.squared&quot;</span>,
    <span class="dt">group_by =</span> <span class="st">&quot;Species&quot;</span>)


<span class="co">## Connect to your Spark cluster</span>
spark_conn &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>)

<span class="co">## Print the version of Spark</span>
<span class="kw">spark_version</span>(<span class="dt">sc =</span> spark_conn)

<span class="co">## Disconnect from Spark</span>
<span class="kw">spark_disconnect</span>(<span class="dt">sc =</span> spark_conn)

<span class="co">## See tables</span>
<span class="kw">src_tbls</span>(sc)

<span class="co">## Copy track_metadata to Spark</span>
track_metadata_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(spark_conn, track_metadata)

<span class="co">## Print 5 rows, all columns</span>
<span class="kw">print</span>(track_metadata_tbl, <span class="dt">n =</span> <span class="dv">5</span>, <span class="dt">width =</span> <span class="ot">Inf</span>)

<span class="co">## Write and run SQL query</span>
query &lt;-<span class="st"> &quot;SELECT * FROM track_metadata WHERE year &lt; 1935 AND duration &gt; 300&quot;</span>
(results &lt;-<span class="st"> </span><span class="kw">dbGetQuery</span>(spark_conn, query))

<span class="co">## General transformation structure and example</span>
a_tibble <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_some_transformation</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>, some_other_args)

hotttnesss &lt;-<span class="st"> </span>track_metadata_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Select artist_hotttnesss</span>
<span class="st">  </span><span class="kw">select</span>(artist_hotttnesss) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Binarize to is_hottt_or_nottt</span>
<span class="st">  </span><span class="kw">ft_binarizer</span>(<span class="st">&#39;artist_hotttnesss&#39;</span>, <span class="st">&#39;is_hottt_or_nottt&#39;</span>, <span class="dt">threshold =</span> <span class="fl">.5</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Collect the result</span>
<span class="st">  </span><span class="kw">collect</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Convert is_hottt_or_nottt to logical</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">is_hottt_or_nottt =</span> <span class="kw">as.logical</span>(is_hottt_or_nottt))
  
<span class="co">## Get and transform the schema</span>

(schema &lt;-<span class="st"> </span><span class="kw">sdf_schema</span>(track_metadata_tbl))
schema <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">lapply</span>(<span class="cf">function</span>(x) <span class="kw">do.call</span>(data_frame, x)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_rows</span>()

<span class="co">## Train-test split</span>
partitioned &lt;-<span class="st"> </span>track_metadata_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_partition</span>(<span class="dt">training =</span> <span class="fl">0.7</span>, <span class="dt">testing =</span> <span class="fl">0.3</span>)

<span class="co">## List ml functions</span>
<span class="kw">ls</span>(<span class="st">&quot;package:sparklyr&quot;</span>, <span class="dt">pattern =</span> <span class="st">&quot;^ml&quot;</span>)

<span class="co">## GBT Example</span>

gradient_boosted_trees_model &lt;-<span class="st"> </span>track_data_to_model_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Run the gradient boosted trees model</span>
<span class="st">   </span><span class="kw">ml_gradient_boosted_trees</span>(<span class="st">&#39;year&#39;</span>, feature_colnames)

responses &lt;-<span class="st"> </span>track_data_to_predict_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Select the year column</span>
<span class="st">  </span><span class="kw">select</span>(year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Collect the results</span>
<span class="st">  </span><span class="kw">collect</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Add in the predictions</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">predicted_year =</span> <span class="kw">predict</span>(
      gradient_boosted_trees_model,
      track_data_to_predict_tbl
    )
  )


<span class="kw">spark_disconnect</span>(sc)</code></pre>
</div>
<div id="data-table" class="section level2">
<h2><span class="header-section-number">9.44</span> Data Table</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Operations done by reference</span>

<span class="kw">names</span>(DT) <span class="co"># colnames</span>
<span class="kw">dim</span>(DT) <span class="co"># dimensions</span>

DT[i, j, by]  <span class="co"># subset by i calculate by j grouped using by</span>
DT[.N]  <span class="co"># prints last row</span>
DT[, .(A, B)] <span class="co"># returns two columns</span>
DT[, <span class="kw">c</span>(A, B)] <span class="co"># returns a concatenated vector</span>
DT[, .(<span class="dt">sum_c =</span> <span class="kw">sum</span>(C)] <span class="co"># mutate</span>
DT[, <span class="kw">plot</span>(A, C)] <span class="co"># plot?</span>
DT[, A <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="ot">NULL</span>] <span class="co"># Remove column A</span>
DT[, .(<span class="dt">sumB =</span> <span class="kw">sum</span>(B)), <span class="dt">by =</span> .(<span class="dt">Grp =</span> A<span class="op">%%</span><span class="dv">2</span>)] <span class="co"># group_by &amp; summarize</span>
DT[, .N, <span class="dt">by =</span> Sepal.Width] <span class="co"># .N is the count of each group</span>
DT[, <span class="kw">lapply</span>(.SD, median)] <span class="co"># .SD is a placeholder for all the columns</span>
DT[, <span class="kw">lapply</span>(.SD, mean), <span class="dt">.SDcols =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">3</span>] <span class="co"># Find mean of columns 2 &amp; 3</span>
DT[.(<span class="st">&#39;b&#39;</span>)]
DT[.(<span class="kw">c</span>(<span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>))]
DT[.(<span class="kw">c</span>(<span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>)), <span class="dt">mult=</span><span class="st">&quot;first&quot;</span>]
DT[<span class="kw">c</span>(<span class="st">&quot;b&quot;</span>, <span class="st">&quot;c&quot;</span>), .SD[<span class="kw">c</span>(<span class="dv">1</span>, .N)], <span class="dt">by =</span> .EACHI] <span class="co"># First and last row of the &quot;b&quot; and &quot;c&quot; groups</span>
DT[<span class="kw">c</span>(<span class="st">&quot;b&quot;</span>, <span class="st">&quot;c&quot;</span>), { <span class="kw">print</span>(.SD); .SD[<span class="kw">c</span>(<span class="dv">1</span>, .N)] }, <span class="dt">by =</span> .EACH]

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>) <span class="kw">set</span>(DT, i, 3L, i<span class="op">+</span><span class="dv">1</span>) <span class="co"># update first 5 rows of 3rd column</span>
<span class="kw">setnames</span>(DT, <span class="st">&#39;y&#39;</span>, <span class="st">&#39;z&#39;</span>) <span class="co"># changes colname from y to z</span>
<span class="kw">setkey</span>(DT, A, B)

dt1[dt2, <span class="dt">roll=</span><span class="op">-</span><span class="ot">Inf</span>, <span class="dt">rollends=</span><span class="ot">FALSE</span>] <span class="co"># rolling join</span></code></pre>
</div>
<div id="keras" class="section level2">
<h2><span class="header-section-number">9.45</span> Keras</h2>
<p>The general framework: 1) instantiate, 2) add layers input-hidden-output, 3) compile, 4) fit</p>
<pre class="sourceCode r"><code class="sourceCode r">network &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() 

network <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">512</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">28</span> <span class="op">*</span><span class="st"> </span><span class="dv">28</span>)) <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">&quot;softmax&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">compile</span>(<span class="dt">optimizer =</span> <span class="st">&quot;rmsprop&quot;</span>,  <span class="dt">loss =</span> <span class="st">&quot;categorical_crossentropy&quot;</span>,  <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">&quot;accuracy&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">fit</span>(train_images, train_labels, <span class="dt">epochs =</span> <span class="dv">5</span>, <span class="dt">batch_size =</span> <span class="dv">128</span>)

metrics &lt;-<span class="st"> </span>network <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">evaluate</span>(test_images, test_labels)</code></pre>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co">#import keras</span>
<span class="co">#from keras.layers import Dense</span>
<span class="co">#from keras.models import Sequential</span>
<span class="co"># Regression</span>
<span class="co"># Specify the model</span>
<span class="co">#model = Sequential()</span>
<span class="co">## Input</span>
<span class="co">#model.add(Dense(50, activation=&#39;relu&#39;, input_shape = 3))</span>
<span class="co"># Hidden</span>
<span class="co">#model.add(Dense(32, activation=&#39;relu&#39;))</span>
<span class="co"># Output</span>
<span class="co">#model.add(Dense(1))</span>
<span class="co"># Compile the model</span>
<span class="co">#model.compile(optimizer = &#39;adam&#39;, loss = &#39;mean_squared_error&#39;) </span>
<span class="co"># Fit the model</span>
<span class="co">#model.fit(predictors, target))</span>
<span class="co"># Classification</span>
<span class="co"># Specify the model: Two hidden layers</span>
<span class="co">#model = Sequential()</span>
<span class="co">## Input</span>
<span class="co">#model.add(Dense(50, activation=&#39;relu&#39;, input_shape = 3))</span>
<span class="co"># Hidden</span>
<span class="co">#model.add(Dense(32, activation=&#39;relu&#39;))</span>
<span class="co"># Output</span>
<span class="co">#model.add(Dense(2, activation = &#39;softmax&#39;))</span>
<span class="co"># Compile the model</span>
<span class="co">#model.compile(optimizer = &#39;sgd&#39;, loss = &#39;categorical_crossentropy&#39;, metrics = &#39;accuracy&#39;)</span>
<span class="co"># Fit the model</span>
<span class="co">#model.fit(predictors, target)</span>
<span class="co"># Other</span>
<span class="co"># Dummying</span>
<span class="co">#y = 1</span>
<span class="co">#keras.utils.to_categorical(y, num_classes = 2)</span>
<span class="co">#Look at summary</span>
<span class="co">#model.summary()</span>
<span class="co">#Calculate predictions: predictions</span>
<span class="co">#predictions = model.predict(pred_data)</span>
<span class="co">#Calculate predicted probability of survival</span>
predicted_prob_true <span class="op">=</span> predictions[:, <span class="dv">1</span>]</code></pre>
</div>
<div id="mnist-example" class="section level2">
<h2><span class="header-section-number">9.46</span> MNIST Example</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
<span class="im">from</span> sklearn <span class="im">import</span> datasets
<span class="im">from</span> sklearn <span class="im">import</span> svm
digits <span class="op">=</span> datasets.load_digits()
<span class="co">#print(digits.data)</span>
<span class="co">#print(digits.target)</span>
<span class="bu">print</span>(digits.images[<span class="dv">0</span>])
clf <span class="op">=</span> svm.SVC(gamma<span class="op">=</span>.<span class="dv">001</span>,C<span class="op">=</span><span class="dv">100</span>)
x, y <span class="op">=</span> digits.data[:<span class="op">-</span><span class="dv">10</span>], digits.target[:<span class="op">-</span><span class="dv">10</span>]
clf.fit(x,y)
<span class="bu">print</span>(<span class="st">&quot;Prediction: &quot;</span>, clf.predict(digits.data[<span class="op">-</span><span class="dv">2</span>].reshape(<span class="dv">1</span>, <span class="dv">-1</span>)))
plt.imshow(digits.images[<span class="op">-</span><span class="dv">2</span>], cmap<span class="op">=</span>plt.cm.gray_r, interpolation<span class="op">=</span><span class="st">&quot;nearest&quot;</span>)
plt.show()</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probabilistic-programming.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="checklists.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-cook_book.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
