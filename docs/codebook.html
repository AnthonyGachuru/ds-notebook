<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Codebook | Data Science Cribsheet</title>
  <meta name="description" content="A collection of quick notes on the field." />
  <meta name="generator" content="bookdown 0.10 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Codebook | Data Science Cribsheet" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A collection of quick notes on the field." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Codebook | Data Science Cribsheet" />
  
  <meta name="twitter:description" content="A collection of quick notes on the field." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probabilistic-programming.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DS Cribsheet</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Workflow</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#preamble"><i class="fa fa-check"></i><b>1.1</b> Preamble</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#checklist"><i class="fa fa-check"></i><b>1.2</b> Checklist</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#preparation"><i class="fa fa-check"></i><b>1.2.1</b> Preparation</a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#import-tidy-transform-visualize"><i class="fa fa-check"></i><b>1.2.2</b> Import-Tidy-Transform-Visualize</a></li>
<li class="chapter" data-level="1.2.3" data-path="index.html"><a href="index.html#model"><i class="fa fa-check"></i><b>1.2.3</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#communicate"><i class="fa fa-check"></i><b>1.3</b> Communicate</a><ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#deploy-maintain"><i class="fa fa-check"></i><b>1.3.1</b> Deploy &amp; Maintain</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#resources"><i class="fa fa-check"></i><b>1.4</b> Resources</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#pipelines"><i class="fa fa-check"></i><b>1.5</b> Pipelines</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pre-modeling.html"><a href="pre-modeling.html"><i class="fa fa-check"></i><b>2</b> Pre-Modeling</a><ul>
<li class="chapter" data-level="2.1" data-path="pre-modeling.html"><a href="pre-modeling.html#import"><i class="fa fa-check"></i><b>2.1</b> Import</a><ul>
<li class="chapter" data-level="2.1.1" data-path="pre-modeling.html"><a href="pre-modeling.html#general"><i class="fa fa-check"></i><b>2.1.1</b> General</a></li>
<li class="chapter" data-level="2.1.2" data-path="pre-modeling.html"><a href="pre-modeling.html#sql"><i class="fa fa-check"></i><b>2.1.2</b> SQL</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pre-modeling.html"><a href="pre-modeling.html#tidy-transform"><i class="fa fa-check"></i><b>2.2</b> Tidy &amp; Transform</a><ul>
<li class="chapter" data-level="2.2.1" data-path="pre-modeling.html"><a href="pre-modeling.html#general-1"><i class="fa fa-check"></i><b>2.2.1</b> General</a></li>
<li class="chapter" data-level="2.2.2" data-path="pre-modeling.html"><a href="pre-modeling.html#missingness-imputation"><i class="fa fa-check"></i><b>2.2.2</b> Missingness &amp; Imputation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pre-modeling.html"><a href="pre-modeling.html#visualize"><i class="fa fa-check"></i><b>2.3</b> Visualize</a></li>
<li class="chapter" data-level="2.4" data-path="pre-modeling.html"><a href="pre-modeling.html#pre-processing"><i class="fa fa-check"></i><b>2.4</b> Pre-processing</a><ul>
<li class="chapter" data-level="2.4.1" data-path="pre-modeling.html"><a href="pre-modeling.html#feature-engineering"><i class="fa fa-check"></i><b>2.4.1</b> Feature Engineering</a></li>
<li class="chapter" data-level="2.4.2" data-path="pre-modeling.html"><a href="pre-modeling.html#feature-selection"><i class="fa fa-check"></i><b>2.4.2</b> Feature Selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="model-1.html"><a href="model-1.html"><i class="fa fa-check"></i><b>3</b> Model</a><ul>
<li class="chapter" data-level="3.1" data-path="model-1.html"><a href="model-1.html#general-2"><i class="fa fa-check"></i><b>3.1</b> General</a></li>
<li class="chapter" data-level="3.2" data-path="model-1.html"><a href="model-1.html#model-selectionevaluation"><i class="fa fa-check"></i><b>3.2</b> Model Selection/Evaluation</a></li>
<li class="chapter" data-level="3.3" data-path="model-1.html"><a href="model-1.html#supervised"><i class="fa fa-check"></i><b>3.3</b> Supervised</a><ul>
<li class="chapter" data-level="3.3.1" data-path="model-1.html"><a href="model-1.html#glm"><i class="fa fa-check"></i><b>3.3.1</b> GLM</a></li>
<li class="chapter" data-level="3.3.2" data-path="model-1.html"><a href="model-1.html#generalized-additive-models"><i class="fa fa-check"></i><b>3.3.2</b> Generalized Additive Models</a></li>
<li class="chapter" data-level="3.3.3" data-path="model-1.html"><a href="model-1.html#knn"><i class="fa fa-check"></i><b>3.3.3</b> KNN</a></li>
<li class="chapter" data-level="3.3.4" data-path="model-1.html"><a href="model-1.html#svm"><i class="fa fa-check"></i><b>3.3.4</b> SVM</a></li>
<li class="chapter" data-level="3.3.5" data-path="model-1.html"><a href="model-1.html#decision-tree"><i class="fa fa-check"></i><b>3.3.5</b> Decision Tree</a></li>
<li class="chapter" data-level="3.3.6" data-path="model-1.html"><a href="model-1.html#bagging"><i class="fa fa-check"></i><b>3.3.6</b> Bagging</a></li>
<li class="chapter" data-level="3.3.7" data-path="model-1.html"><a href="model-1.html#random-forest"><i class="fa fa-check"></i><b>3.3.7</b> Random Forest</a></li>
<li class="chapter" data-level="3.3.8" data-path="model-1.html"><a href="model-1.html#boosting"><i class="fa fa-check"></i><b>3.3.8</b> Boosting</a></li>
<li class="chapter" data-level="3.3.9" data-path="model-1.html"><a href="model-1.html#naive-bayes"><i class="fa fa-check"></i><b>3.3.9</b> Na√Øve Bayes</a></li>
<li class="chapter" data-level="3.3.10" data-path="model-1.html"><a href="model-1.html#lda-qda"><i class="fa fa-check"></i><b>3.3.10</b> LDA &amp; QDA</a></li>
<li class="chapter" data-level="3.3.11" data-path="model-1.html"><a href="model-1.html#gams"><i class="fa fa-check"></i><b>3.3.11</b> GAMs</a></li>
<li class="chapter" data-level="3.3.12" data-path="model-1.html"><a href="model-1.html#hierarchical-models"><i class="fa fa-check"></i><b>3.3.12</b> Hierarchical Models</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="model-1.html"><a href="model-1.html#unsupervised"><i class="fa fa-check"></i><b>3.4</b> Unsupervised</a><ul>
<li class="chapter" data-level="3.4.1" data-path="model-1.html"><a href="model-1.html#k-means-clustering"><i class="fa fa-check"></i><b>3.4.1</b> K-Means Clustering</a></li>
<li class="chapter" data-level="3.4.2" data-path="model-1.html"><a href="model-1.html#hierarchical-clustering"><i class="fa fa-check"></i><b>3.4.2</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="3.4.3" data-path="model-1.html"><a href="model-1.html#dimensionality-reduction"><i class="fa fa-check"></i><b>3.4.3</b> Dimensionality Reduction</a></li>
<li class="chapter" data-level="3.4.4" data-path="model-1.html"><a href="model-1.html#multiple-correspondence-analysis"><i class="fa fa-check"></i><b>3.4.4</b> Multiple Correspondence Analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="model-1.html"><a href="model-1.html#semi-supervised"><i class="fa fa-check"></i><b>3.5</b> Semi Supervised</a></li>
<li class="chapter" data-level="3.6" data-path="model-1.html"><a href="model-1.html#reinforcement-learning"><i class="fa fa-check"></i><b>3.6</b> Reinforcement Learning</a></li>
<li class="chapter" data-level="3.7" data-path="model-1.html"><a href="model-1.html#other-ml"><i class="fa fa-check"></i><b>3.7</b> Other ML</a><ul>
<li class="chapter" data-level="3.7.1" data-path="model-1.html"><a href="model-1.html#association-rule-mining"><i class="fa fa-check"></i><b>3.7.1</b> Association Rule Mining</a></li>
<li class="chapter" data-level="3.7.2" data-path="model-1.html"><a href="model-1.html#nlp"><i class="fa fa-check"></i><b>3.7.2</b> NLP</a></li>
<li class="chapter" data-level="3.7.3" data-path="model-1.html"><a href="model-1.html#geospatial"><i class="fa fa-check"></i><b>3.7.3</b> Geospatial</a></li>
<li class="chapter" data-level="3.7.4" data-path="model-1.html"><a href="model-1.html#ai"><i class="fa fa-check"></i><b>3.7.4</b> AI</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="model-1.html"><a href="model-1.html#online-learning"><i class="fa fa-check"></i><b>3.8</b> Online Learning</a></li>
<li class="chapter" data-level="3.9" data-path="model-1.html"><a href="model-1.html#sequences"><i class="fa fa-check"></i><b>3.9</b> Sequences</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="communicate-deploy-maintain.html"><a href="communicate-deploy-maintain.html"><i class="fa fa-check"></i><b>4</b> Communicate, Deploy, Maintain</a><ul>
<li class="chapter" data-level="4.1" data-path="communicate-deploy-maintain.html"><a href="communicate-deploy-maintain.html#communicate-1"><i class="fa fa-check"></i><b>4.1</b> Communicate</a></li>
<li class="chapter" data-level="4.2" data-path="communicate-deploy-maintain.html"><a href="communicate-deploy-maintain.html#deploymaintain"><i class="fa fa-check"></i><b>4.2</b> Deploy/Maintain</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stats.html"><a href="stats.html"><i class="fa fa-check"></i><b>5</b> Stats</a><ul>
<li class="chapter" data-level="5.1" data-path="stats.html"><a href="stats.html#general-3"><i class="fa fa-check"></i><b>5.1</b> General</a></li>
<li class="chapter" data-level="5.2" data-path="stats.html"><a href="stats.html#sample-size"><i class="fa fa-check"></i><b>5.2</b> Sample Size</a></li>
<li class="chapter" data-level="5.3" data-path="stats.html"><a href="stats.html#hypothesis-testing"><i class="fa fa-check"></i><b>5.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="5.4" data-path="stats.html"><a href="stats.html#ab-testing"><i class="fa fa-check"></i><b>5.4</b> AB Testing</a><ul>
<li class="chapter" data-level="5.4.1" data-path="stats.html"><a href="stats.html#power-analysis"><i class="fa fa-check"></i><b>5.4.1</b> Power Analysis</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="stats.html"><a href="stats.html#experimental-design"><i class="fa fa-check"></i><b>5.5</b> Experimental Design</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="sequences-1.html"><a href="sequences-1.html"><i class="fa fa-check"></i><b>6</b> Sequences</a><ul>
<li class="chapter" data-level="6.1" data-path="sequences-1.html"><a href="sequences-1.html#time-series"><i class="fa fa-check"></i><b>6.1</b> Time Series</a><ul>
<li class="chapter" data-level="6.1.1" data-path="sequences-1.html"><a href="sequences-1.html#notes"><i class="fa fa-check"></i><b>6.1.1</b> Notes</a></li>
<li class="chapter" data-level="6.1.2" data-path="sequences-1.html"><a href="sequences-1.html#workflow-1"><i class="fa fa-check"></i><b>6.1.2</b> Workflow</a></li>
<li class="chapter" data-level="6.1.3" data-path="sequences-1.html"><a href="sequences-1.html#preprocessing"><i class="fa fa-check"></i><b>6.1.3</b> Preprocessing</a></li>
<li class="chapter" data-level="6.1.4" data-path="sequences-1.html"><a href="sequences-1.html#feature-engineering-1"><i class="fa fa-check"></i><b>6.1.4</b> Feature Engineering</a></li>
<li class="chapter" data-level="6.1.5" data-path="sequences-1.html"><a href="sequences-1.html#packages-functions"><i class="fa fa-check"></i><b>6.1.5</b> Packages / Functions</a></li>
<li class="chapter" data-level="6.1.6" data-path="sequences-1.html"><a href="sequences-1.html#models"><i class="fa fa-check"></i><b>6.1.6</b> Models</a></li>
<li class="chapter" data-level="6.1.7" data-path="sequences-1.html"><a href="sequences-1.html#model-selection"><i class="fa fa-check"></i><b>6.1.7</b> Model Selection</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="sequences-1.html"><a href="sequences-1.html#dsp"><i class="fa fa-check"></i><b>6.2</b> DSP</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>7</b> Deep Learning</a><ul>
<li class="chapter" data-level="7.1" data-path="deep-learning.html"><a href="deep-learning.html#general-6"><i class="fa fa-check"></i><b>7.1</b> General</a></li>
<li class="chapter" data-level="7.2" data-path="deep-learning.html"><a href="deep-learning.html#pre-processing-1"><i class="fa fa-check"></i><b>7.2</b> Pre-processing</a></li>
<li class="chapter" data-level="7.3" data-path="deep-learning.html"><a href="deep-learning.html#defaults"><i class="fa fa-check"></i><b>7.3</b> Defaults</a></li>
<li class="chapter" data-level="7.4" data-path="deep-learning.html"><a href="deep-learning.html#rnnlstm"><i class="fa fa-check"></i><b>7.4</b> RNN/LSTM</a></li>
<li class="chapter" data-level="7.5" data-path="deep-learning.html"><a href="deep-learning.html#tuning"><i class="fa fa-check"></i><b>7.5</b> Tuning</a></li>
<li class="chapter" data-level="7.6" data-path="deep-learning.html"><a href="deep-learning.html#debugging"><i class="fa fa-check"></i><b>7.6</b> Debugging</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html"><i class="fa fa-check"></i><b>8</b> Probabilistic Programming</a><ul>
<li class="chapter" data-level="8.1" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#bayes-rule"><i class="fa fa-check"></i><b>8.1</b> Bayes Rule</a></li>
<li class="chapter" data-level="8.2" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#simple-bayes"><i class="fa fa-check"></i><b>8.2</b> Simple Bayes</a></li>
<li class="chapter" data-level="8.3" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#other-1"><i class="fa fa-check"></i><b>8.3</b> Other</a></li>
<li class="chapter" data-level="8.4" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#doing-bayesian-da"><i class="fa fa-check"></i><b>8.4</b> Doing Bayesian DA</a></li>
<li class="chapter" data-level="8.5" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#statistical-rethinking"><i class="fa fa-check"></i><b>8.5</b> Statistical Rethinking</a></li>
<li class="chapter" data-level="8.6" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#causality"><i class="fa fa-check"></i><b>8.6</b> Causality</a><ul>
<li class="chapter" data-level="8.6.1" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#general-7"><i class="fa fa-check"></i><b>8.6.1</b> General</a></li>
<li class="chapter" data-level="8.6.2" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#causality-edx"><i class="fa fa-check"></i><b>8.6.2</b> Causality edX</a></li>
<li class="chapter" data-level="8.6.3" data-path="probabilistic-programming.html"><a href="probabilistic-programming.html#causality-coursera"><i class="fa fa-check"></i><b>8.6.3</b> Causality Coursera</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="codebook.html"><a href="codebook.html"><i class="fa fa-check"></i><b>9</b> Codebook</a><ul>
<li class="chapter" data-level="9.1" data-path="codebook.html"><a href="codebook.html#mixed-effect-regression"><i class="fa fa-check"></i><b>9.1</b> Mixed Effect Regression</a></li>
<li class="chapter" data-level="9.2" data-path="codebook.html"><a href="codebook.html#regression-by-groups"><i class="fa fa-check"></i><b>9.2</b> Regression By Groups</a></li>
<li class="chapter" data-level="9.3" data-path="codebook.html"><a href="codebook.html#symbolic-regression"><i class="fa fa-check"></i><b>9.3</b> Symbolic Regression</a></li>
<li class="chapter" data-level="9.4" data-path="codebook.html"><a href="codebook.html#stats-by-simulation"><i class="fa fa-check"></i><b>9.4</b> Stats By Simulation</a></li>
<li class="chapter" data-level="9.5" data-path="codebook.html"><a href="codebook.html#ts-harmonic-regression"><i class="fa fa-check"></i><b>9.5</b> TS Harmonic Regression</a></li>
<li class="chapter" data-level="9.6" data-path="codebook.html"><a href="codebook.html#save-and-load-models"><i class="fa fa-check"></i><b>9.6</b> Save And Load Models</a></li>
<li class="chapter" data-level="9.7" data-path="codebook.html"><a href="codebook.html#lstm"><i class="fa fa-check"></i><b>9.7</b> LSTM</a></li>
<li class="chapter" data-level="9.8" data-path="codebook.html"><a href="codebook.html#pairwise-scatterplot"><i class="fa fa-check"></i><b>9.8</b> Pairwise Scatterplot</a></li>
<li class="chapter" data-level="9.9" data-path="codebook.html"><a href="codebook.html#anti-join"><i class="fa fa-check"></i><b>9.9</b> Anti-join</a></li>
<li class="chapter" data-level="9.10" data-path="codebook.html"><a href="codebook.html#df-diff"><i class="fa fa-check"></i><b>9.10</b> Df Diff</a></li>
<li class="chapter" data-level="9.11" data-path="codebook.html"><a href="codebook.html#read-sql"><i class="fa fa-check"></i><b>9.11</b> Read SQL</a></li>
<li class="chapter" data-level="9.12" data-path="codebook.html"><a href="codebook.html#extract-date"><i class="fa fa-check"></i><b>9.12</b> Extract Date</a></li>
<li class="chapter" data-level="9.13" data-path="codebook.html"><a href="codebook.html#ggplot-to-plotly"><i class="fa fa-check"></i><b>9.13</b> GGplot To Plotly</a></li>
<li class="chapter" data-level="9.14" data-path="codebook.html"><a href="codebook.html#custom-plotting-theme"><i class="fa fa-check"></i><b>9.14</b> Custom Plotting Theme</a></li>
<li class="chapter" data-level="9.15" data-path="codebook.html"><a href="codebook.html#rowwise"><i class="fa fa-check"></i><b>9.15</b> Rowwise</a></li>
<li class="chapter" data-level="9.16" data-path="codebook.html"><a href="codebook.html#sampling-file"><i class="fa fa-check"></i><b>9.16</b> Sampling File</a></li>
<li class="chapter" data-level="9.17" data-path="codebook.html"><a href="codebook.html#featuretools"><i class="fa fa-check"></i><b>9.17</b> Featuretools</a></li>
<li class="chapter" data-level="9.18" data-path="codebook.html"><a href="codebook.html#shap"><i class="fa fa-check"></i><b>9.18</b> SHAP</a></li>
<li class="chapter" data-level="9.19" data-path="codebook.html"><a href="codebook.html#csv-to-db"><i class="fa fa-check"></i><b>9.19</b> CSV To DB</a></li>
<li class="chapter" data-level="9.20" data-path="codebook.html"><a href="codebook.html#bayesian-cv"><i class="fa fa-check"></i><b>9.20</b> Bayesian CV</a></li>
<li class="chapter" data-level="9.21" data-path="codebook.html"><a href="codebook.html#pyspark"><i class="fa fa-check"></i><b>9.21</b> Pyspark</a></li>
<li class="chapter" data-level="9.22" data-path="codebook.html"><a href="codebook.html#sparklyr"><i class="fa fa-check"></i><b>9.22</b> Sparklyr</a></li>
<li class="chapter" data-level="9.23" data-path="codebook.html"><a href="codebook.html#data-table"><i class="fa fa-check"></i><b>9.23</b> Data Table</a></li>
<li class="chapter" data-level="9.24" data-path="codebook.html"><a href="codebook.html#keras"><i class="fa fa-check"></i><b>9.24</b> Keras</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science Cribsheet</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="codebook" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Codebook</h1>
<div id="mixed-effect-regression" class="section level2">
<h2><span class="header-section-number">9.1</span> Mixed Effect Regression</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.api <span class="im">as</span> sm
<span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf

mdl <span class="op">=</span> smf.mixedlm(<span class="st">&quot;y ~ x&quot;</span>. df, groups <span class="op">=</span> train[<span class="st">&#39;group&#39;</span>])
mdl_fit <span class="op">=</span> mdl.fit()</code></pre>
</div>
<div id="regression-by-groups" class="section level2">
<h2><span class="header-section-number">9.2</span> Regression By Groups</h2>
<pre class="sourceCode r"><code class="sourceCode r">pga <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">split</span>(.<span class="op">$</span>year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">map</span>(<span class="op">~</span><span class="kw">lm</span>(score.avg <span class="op">~</span><span class="st"> </span>driveavg <span class="op">+</span><span class="st"> </span>drivepct, <span class="dt">data=</span>.)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">map</span>(summary)

mtcars <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(cyl) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">split</span>(.<span class="op">$</span>cyl) <span class="op">%&gt;%</span><span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(<span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> .))
mtcars <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(cyl) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nest</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(data, <span class="cf">function</span>(x) <span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> x) ))</code></pre>
</div>
<div id="symbolic-regression" class="section level2">
<h2><span class="header-section-number">9.3</span> Symbolic Regression</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> gplearn <span class="im">import</span> SymbolicRegressor

est_gp <span class="op">=</span> SymbolicRegressor(population_size <span class="op">=</span> <span class="dv">100</span>, generations <span class="op">=</span> <span class="dv">100</span>, stopping_criteria <span class="op">=</span> <span class="fl">0.01</span>, p_crossover <span class="op">=</span> <span class="fl">0.7</span>, p_subtree_mutation <span class="op">=</span> <span class="fl">0.1</span>, metric <span class="op">=</span> <span class="st">&#39;rmse&#39;</span>, p_hoist_mutation <span class="op">=</span> <span class="fl">0.05</span>, p_point_mutation <span class="op">=</span> <span class="fl">0.1</span>, max_samples <span class="op">=</span> <span class="fl">0.9</span>, verbose <span class="op">=</span> <span class="dv">0</span>, parsimony_coefficient <span class="op">=</span> <span class="fl">0.01</span>, random_state <span class="op">=</span> seed)

est_gp.fit(X_train, y_train)
preds <span class="op">=</span> est_gp.predict(X_train)
np.sqrt(mean_squared_error(y_train, preds))

graph <span class="op">=</span> pydotplus.graphviz.graph_from_dot_data(est_gp._program.export_graphviz())
Image(graph.create_png())
eqn <span class="op">=</span> <span class="bu">str</span>(est_gp._program)
mapping_dict <span class="op">=</span> {<span class="st">&#39;X</span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(i): X_train.columns[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X_train.shape[<span class="dv">1</span>])}

<span class="cf">for</span> old_value, new_value <span class="kw">in</span> mapping_dict.items():
  eqn <span class="op">=</span> eqn.replace(old_value, new_value)</code></pre>
</div>
<div id="stats-by-simulation" class="section level2">
<h2><span class="header-section-number">9.4</span> Stats By Simulation</h2>
<p>Notes on the talk by Jake Vanderplas. I left out bootstrap and cross validation below. For all methods look out for selection bias and make sure you have representative samples. More on the bootstrap: These are simulated confidence intervals that work well for n &gt; 20 as a rule of thumb.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Direct Simulation: Works well with an apriori (generative) model of the world, like the probability distribution of a coin toss. Example: Flip a fair coin 30 times. How likely it is to see 22 heads?</span>

n &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>
h_a &lt;-<span class="st"> </span><span class="dv">22</span>
result &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(<span class="kw">seq</span>(<span class="dv">1</span>, n, <span class="dv">1</span>), 
           <span class="op">~</span><span class="st"> </span><span class="kw">sum</span>(base<span class="op">::</span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dv">30</span>, <span class="dt">replace =</span> T)) <span class="op">&gt;=</span><span class="st"> </span>h_a) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>()

result<span class="op">/</span>n

<span class="co"># Shuffling: Comparing groups</span>

iris_<span class="dv">100</span> &lt;-<span class="st"> </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>)]
(<span class="kw">t.test</span>(iris_<span class="dv">100</span>[<span class="dv">1</span><span class="op">:</span><span class="dv">50</span>, <span class="dv">1</span>], iris_<span class="dv">100</span>[<span class="dv">51</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">1</span>], 
       <span class="dt">alternative =</span> <span class="st">&#39;greater&#39;</span>))<span class="op">$</span>p.value

ha_shuffle &lt;-<span class="st"> </span><span class="cf">function</span>(df){
  
  result &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Species =</span> <span class="kw">sample</span>(Species, <span class="kw">n</span>())) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Species) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="dv">1</span>, mean) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mu_diff =</span> Sepal.Width <span class="op">-</span><span class="st"> </span><span class="kw">lag</span>(Sepal.Width)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(mu_diff)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">pull</span>(mu_diff)
  
  <span class="kw">return</span>(result <span class="op">&gt;=</span><span class="st"> </span>observed_diff)
  
}

observed_diff &lt;-<span class="st"> </span>iris_<span class="dv">100</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Species) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="dv">1</span>, mean) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mu_diff =</span> Sepal.Width <span class="op">-</span><span class="st"> </span><span class="kw">lag</span>(Sepal.Width)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(mu_diff)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">pull</span>(mu_diff)

n &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>
result &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(<span class="kw">seq</span>(<span class="dv">1</span>, n, <span class="dv">1</span>), <span class="op">~</span><span class="st"> </span><span class="kw">ha_shuffle</span>(iris_<span class="dv">100</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sum</span>()

result<span class="op">/</span>n

<span class="co"># He discussed cross validation as a third method</span></code></pre>
</div>
<div id="ts-harmonic-regression" class="section level2">
<h2><span class="header-section-number">9.5</span> TS Harmonic Regression</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set up harmonic regressors of order 13</span>
harmonics &lt;-<span class="st"> </span><span class="kw">fourier</span>(gasoline, <span class="dt">K =</span> <span class="dv">13</span>)
<span class="co"># Fit regression model with ARIMA errors</span>
fit &lt;-<span class="st"> </span><span class="kw">auto.arima</span>(gasoline, <span class="dt">xreg =</span> harmonics, <span class="dt">seasonal =</span> <span class="ot">FALSE</span>)
<span class="co"># Forecasts next 3 years</span>
fc &lt;-<span class="st"> </span><span class="kw">forecast</span>(fit, <span class="dt">xreg =</span> <span class="kw">fourier</span>(gasoline, <span class="dt">K =</span> <span class="dv">13</span>, <span class="dt">h =</span> <span class="dv">156</span>))
<span class="co"># Plot forecasts fc</span>
<span class="kw">autoplot</span>(fc)</code></pre>
</div>
<div id="save-and-load-models" class="section level2">
<h2><span class="header-section-number">9.6</span> Save And Load Models</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> sklearn.externals <span class="im">import</span> joblib

joblib.dump(grid_search, <span class="st">&#39;model.pkl&#39;</span>)
grid_search <span class="op">=</span> joblib.load(<span class="st">&#39;model.pkl&#39;</span>)

model <span class="op">=</span> grid_search.best_estimator_</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">save</span>(m1, <span class="dt">file =</span> <span class="st">&quot;my_model1.rda&quot;</span>)
m1 =<span class="st"> </span><span class="kw">load</span>(<span class="st">&quot;my_model1.rda&quot;</span>)</code></pre>
</div>
<div id="lstm" class="section level2">
<h2><span class="header-section-number">9.7</span> LSTM</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Data Shape</span>
data_x <span class="op">=</span> np.array([
    <span class="co"># Datapoint 1: 3 features for timesteps 1 &amp; 2</span>
    [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]],
    <span class="co"># Datapoint 2</span>
    [[<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>], [<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>]]])
    
<span class="co"># Prediction Example</span>
mdl.predict([[np.array([.<span class="dv">5</span>, <span class="fl">.6</span>, <span class="fl">.6</span>] <span class="op">+</span> [<span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">14</span>)]).reshape((<span class="dv">17</span>, <span class="dv">1</span>))]])[<span class="dv">0</span>]</code></pre>
</div>
<div id="pairwise-scatterplot" class="section level2">
<h2><span class="header-section-number">9.8</span> Pairwise Scatterplot</h2>
<pre class="sourceCode r"><code class="sourceCode r">GGally<span class="op">::</span><span class="kw">ggpairs</span>(data, <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">colour =</span> category))</code></pre>
</div>
<div id="anti-join" class="section level2">
<h2><span class="header-section-number">9.9</span> Anti-join</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># https://stackoverflow.com/questions/38516664/anti-join-pandas</span>

<span class="co"># Identify what values are in TableB and not in TableA</span>
key_diff <span class="op">=</span> <span class="bu">set</span>(TableB.Key).difference(TableA.Key)
where_diff <span class="op">=</span> TableB.Key.isin(key_diff)

<span class="co"># Slice TableB accordingly and append to TableA</span>
TableA.append(TableB[where_diff], ignore_index<span class="op">=</span><span class="va">True</span>)</code></pre>
</div>
<div id="df-diff" class="section level2">
<h2><span class="header-section-number">9.10</span> Df Diff</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># https://stackoverflow.com/a/36893675/6627726</span>

merged <span class="op">=</span> df1.merge(df2, indicator<span class="op">=</span><span class="va">True</span>, how<span class="op">=</span><span class="st">&#39;outer&#39;</span>)
merged[merged[<span class="st">&#39;_merge&#39;</span>] <span class="op">==</span> <span class="st">&#39;right_only&#39;</span>]</code></pre>
</div>
<div id="read-sql" class="section level2">
<h2><span class="header-section-number">9.11</span> Read SQL</h2>
<pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">dbGetQuery</span>(con, <span class="dt">statement =</span> <span class="kw">read_file</span>(<span class="st">&#39;query.sql&#39;</span>))</code></pre>
</div>
<div id="extract-date" class="section level2">
<h2><span class="header-section-number">9.12</span> Extract Date</h2>
<pre class="sourceCode r"><code class="sourceCode r">StartTime <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.POSIXct</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">strftime</span>(<span class="dt">format=</span><span class="st">&quot;%Y-%m-%d&quot;</span>)
YearMonth =<span class="st"> </span>Day <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">strftime</span>(<span class="dt">format=</span><span class="st">&quot;%Y-%m&quot;</span>)
date =<span class="st"> </span>date <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.POSIXct</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">strptime</span>(<span class="st">&#39;%Y-%m-%d&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">strftime</span>(<span class="dt">format=</span><span class="st">&quot;%Y-%m-%d&quot;</span>)</code></pre>
</div>
<div id="ggplot-to-plotly" class="section level2">
<h2><span class="header-section-number">9.13</span> GGplot To Plotly</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplotly</span>(<span class="kw">ggplot</span>(df), <span class="kw">aes</span>(x, y, <span class="dt">label =</span> z, <span class="dt">color =</span> w)) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">.2</span>), tooltip =<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;y&#39;</span>, <span class="st">&#39;label&#39;</span>)<span class="er">)</span></code></pre>
</div>
<div id="custom-plotting-theme" class="section level2">
<h2><span class="header-section-number">9.14</span> Custom Plotting Theme</h2>
<pre class="sourceCode r"><code class="sourceCode r">theme_ilo &lt;-<span class="st"> </span><span class="cf">function</span>() {
    <span class="kw">theme_minimal</span>() <span class="op">+</span>
<span class="st">        </span><span class="kw">theme</span>(
            <span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Bookman&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;gray25&quot;</span>),
            <span class="dt">plot.subtitle =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">12</span>),
            <span class="dt">plot.caption =</span> <span class="kw">element_text</span>(<span class="dt">color =</span> <span class="st">&quot;gray30&quot;</span>),
            <span class="dt">plot.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;gray95&quot;</span>),
            <span class="dt">plot.margin =</span> <span class="kw">unit</span>(<span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">10</span>), <span class="dt">units =</span> <span class="st">&quot;mm&quot;</span>)
        )
}</code></pre>
</div>
<div id="rowwise" class="section level2">
<h2><span class="header-section-number">9.15</span> Rowwise</h2>
<pre class="sourceCode python"><code class="sourceCode python">rectangles <span class="op">=</span> [
    { <span class="st">&#39;height&#39;</span>: <span class="dv">40</span>, <span class="st">&#39;width&#39;</span>: <span class="dv">10</span> },
    { <span class="st">&#39;height&#39;</span>: <span class="dv">20</span>, <span class="st">&#39;width&#39;</span>: <span class="dv">9</span> },
    { <span class="st">&#39;height&#39;</span>: <span class="fl">3.4</span>, <span class="st">&#39;width&#39;</span>: <span class="dv">4</span> }
]
rectangles_df <span class="op">=</span> pd.DataFrame(rectangles)
<span class="kw">def</span> calculate_area(row):
    <span class="cf">return</span> row[<span class="st">&#39;height&#39;</span>] <span class="op">*</span> row[<span class="st">&#39;width&#39;</span>]
rectangles_df.<span class="bu">apply</span>(calculate_area, axis<span class="op">=</span><span class="dv">1</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)

mtcars <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mymean =</span> <span class="kw">mean</span>(<span class="kw">c</span>(cyl,mpg))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(cyl, mpg, mymean)

df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mu =</span> <span class="kw">select</span>(., R1<span class="op">:</span>R16) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pmap_dbl</span>(<span class="op">~</span><span class="kw">mean</span>(<span class="kw">c</span>(...))))

calc_row_mean &lt;-<span class="st"> </span><span class="cf">function</span>(li){
  
  df &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(li)
  
  result &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(<span class="kw">contains</span>(<span class="st">&quot;Round&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">mu =</span> <span class="kw">rowMeans</span>(.)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">pull</span>(mu)
  
  <span class="kw">return</span>(result)
  
}</code></pre>
</div>
<div id="sampling-file" class="section level2">
<h2><span class="header-section-number">9.16</span> Sampling File</h2>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">pip</span> install subsample
<span class="ex">subsample</span> -s 8 -n 100000 test.csv -r <span class="op">&gt;</span> test_sample.csv</code></pre>
</div>
<div id="featuretools" class="section level2">
<h2><span class="header-section-number">9.17</span> Featuretools</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># https://stackoverflow.com/questions/50145953/how-to-apply-deep-feature-synthesis-to-a-single-table</span>

<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> featuretools <span class="im">as</span> ft

df <span class="op">=</span> pd.read_csv(<span class="st">&#39;iris.csv&#39;</span>)
df <span class="op">=</span> df.reset_index()

es <span class="op">=</span> ft.EntitySet(<span class="bu">id</span> <span class="op">=</span> <span class="st">&quot;test&quot;</span>) <span class="co">#.drop(columns = [&#39;species&#39;], axis = 1)</span>
es <span class="op">=</span> es.entity_from_dataframe(entity_id <span class="op">=</span> <span class="st">&#39;d&#39;</span>, dataframe <span class="op">=</span> df, make_index<span class="op">=</span><span class="va">True</span>, index<span class="op">=</span><span class="st">&#39;ind&#39;</span>)

<span class="co"># produces 626 features</span>
fm, features <span class="op">=</span> ft.dfs(
    entityset <span class="op">=</span> es, 
    target_entity <span class="op">=</span> <span class="st">&#39;d&#39;</span>,
    agg_primitives <span class="op">=</span> [<span class="st">&#39;mean&#39;</span>, <span class="st">&#39;max&#39;</span>, <span class="st">&#39;percent_true&#39;</span>, <span class="st">&#39;last&#39;</span>],
    trans_primitives <span class="op">=</span> [<span class="st">&#39;subtract&#39;</span>, <span class="st">&#39;divide&#39;</span>]
)

<span class="co"># produces no new features</span>
_, features2 <span class="op">=</span> ft.dfs(
    entityset <span class="op">=</span> es, 
    target_entity <span class="op">=</span> <span class="st">&#39;d&#39;</span>,
    max_depth <span class="op">=</span> <span class="dv">2</span>
)</code></pre>
</div>
<div id="shap" class="section level2">
<h2><span class="header-section-number">9.18</span> SHAP</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> shap
<span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt

mdl.fit(X_train, y_train)
explainer <span class="op">=</span> shap.TreeExplainer(clf)
shap_values <span class="op">=</span> explainer.shap_values(X_train)

<span class="co">#all records explained (both lines of code)</span>
shap.summary_plot(shap_values, X_train)
shap.summary_plot(shap_values, X_train, plot_type <span class="op">=</span> <span class="st">&quot;bar&quot;</span>)

df_shap <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(<span class="bu">zip</span>(np.mean(shap_values, axis <span class="op">=</span> <span class="dv">0</span>), X_train.columns)),
                       columns <span class="op">=</span> [<span class="st">&#39;shap_mean&#39;</span>, <span class="st">&#39;feature&#39;</span>])
df_shap <span class="op">=</span> df_shap[[<span class="st">&#39;feature&#39;</span>, <span class="st">&#39;shap_mean&#39;</span>]]

df_shap[<span class="st">&#39;shap_mean_abs&#39;</span>] <span class="op">=</span> np.absolute(df_shap[<span class="st">&#39;shap_mean&#39;</span>])
df_shap.sort_values([<span class="st">&#39;shap_mean_abs&#39;</span>], ascending <span class="op">=</span> <span class="va">False</span>, inplace <span class="op">=</span> <span class="va">True</span>)

attribution_data <span class="op">=</span> np.array(train_data[:<span class="dv">50</span>])
explainer <span class="op">=</span> shap.DeepExplainer(model, attribution_data)</code></pre>
</div>
<div id="csv-to-db" class="section level2">
<h2><span class="header-section-number">9.19</span> CSV To DB</h2>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># alternative: http://bit.ly/294gmmP</span>
<span class="ex">sqlite3</span> db_name.db
<span class="ex">.mode</span> csv db_name
<span class="ex">.import</span> data.csv db_name</code></pre>
</div>
<div id="bayesian-cv" class="section level2">
<h2><span class="header-section-number">9.20</span> Bayesian CV</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy.stats <span class="im">import</span> randint <span class="im">as</span> sp_randint
<span class="im">from</span> skopt <span class="im">import</span> BayesSearchCV
<span class="im">from</span> skopt.space <span class="im">import</span> Real, Integer, Categorical

mdl_tuner <span class="op">=</span> BayesSearchCV(estimator <span class="op">=</span> mdl, search_spaces <span class="op">=</span> grid, scoring <span class="op">=</span> <span class="st">&#39;roc_auc&#39;</span>,
                          cv <span class="op">=</span> folds, random_state <span class="op">=</span> <span class="dv">8</span>)
                          
result <span class="op">=</span> mdl_tuner.fit(X_train.values, y_train.values)</code></pre>
</div>
<div id="pyspark" class="section level2">
<h2><span class="header-section-number">9.21</span> Pyspark</h2>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Cheatsheet: https://www.qubole.com/resources/pyspark-cheatsheet/</span>

<span class="co"># Spark only handles numeric data. </span>

<span class="co"># selectExpr() takes SQL expressions as a string.</span>

<span class="co"># Spark&#39;s assumes the target is called &#39;label&#39; in ML. Everything else is a feature.</span>

<span class="co"># Estimator classes are for modeling and all implement a .fit() method. eg. StringIndexerModel for including categorical data saved as strings in your models</span>

<span class="co"># It&#39;s important to split the data after all the transformations because operations like StringIndexer don&#39;t always produce the same index even when given the same list of strings.</span>

<span class="co"># Import</span>

<span class="im">import</span> findspark
findspark.init()

<span class="im">import</span> pyspark
<span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession
<span class="im">from</span> pyspark.ml.feature <span class="im">import</span> StringIndexer, OneHotEncoder, VectorAssembler
<span class="im">from</span> pyspark.ml <span class="im">import</span> Pipeline
<span class="im">from</span> pyspark.ml.classification <span class="im">import</span> LogisticRegression
<span class="im">import</span> pyspark.ml.evaluation <span class="im">as</span> evals
<span class="im">import</span> pyspark.ml.tuning <span class="im">as</span> tune
<span class="im">import</span> pyspark.sql.functions <span class="im">as</span> F

sc <span class="op">=</span> pyspark.SparkContext()
spark <span class="op">=</span> SparkSession.builder.getOrCreate() <span class="co"># SparkSession.builder.appName(&#39;chosenName&#39;).getOrCreate()</span>

<span class="co"># Approximate Pi</span>

<span class="kw">def</span> inside(p):     
    x, y <span class="op">=</span> random.random(), random.random()
    <span class="cf">return</span> x<span class="op">*</span>x <span class="op">+</span> y<span class="op">*</span>y <span class="op">&lt;</span> <span class="dv">1</span>
    
num_samples <span class="op">=</span> <span class="dv">100000000</span>
count <span class="op">=</span> sc.parallelize(<span class="bu">range</span>(<span class="dv">0</span>, num_samples)).<span class="bu">filter</span>(inside).count()
pi <span class="op">=</span> <span class="dv">4</span> <span class="op">*</span> count <span class="op">/</span> num_samples

<span class="bu">print</span>(pi)

df <span class="op">=</span> spark.read.csv(<span class="st">&#39;data.csv&#39;</span>, header <span class="op">=</span> <span class="va">True</span>)
<span class="co">#df = spark.read.format(&quot;csv&quot;).option(&quot;header&quot;,&quot;true&quot;).option(&quot;inferSchema&quot;,&quot;true&quot;).load(&quot;john_doe.csv&quot;)</span>

df.show(<span class="dv">5</span>)
df.columns

<span class="co"># Transform</span>

<span class="co">## List tables</span>
spark.catalog.listTables()

<span class="co"># Access and display data</span>
flights10 <span class="op">=</span> spark.sql(<span class="st">&quot;FROM flights SELECT * LIMIT 10&quot;</span>)
flights10.show()

<span class="co"># Cast</span>
df[<span class="st">&#39;g&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;g&#39;</span>].astype(<span class="bu">str</span>)

<span class="co"># Spark df to pandas and vice versa</span>
spark_temp <span class="op">=</span> spark.createDataFrame(pd_temp) <span class="co"># toPandas()</span>

<span class="co"># Add to the catalog</span>
spark_temp.createOrReplaceTempView(<span class="st">&quot;temp&quot;</span>)

<span class="co"># Create the DataFrame flights</span>
flights <span class="op">=</span> spark.table(<span class="st">&#39;flights&#39;</span>)

<span class="co"># Get column names</span>
spark_df.schema.names
spark_df.printSchema()

<span class="co"># Filter</span>
<span class="co"># takes either a Spark Column of boolean (True/False) values or the WHERE clause of a SQL expression as a string</span>
long_flights1 <span class="op">=</span> flights.<span class="bu">filter</span>(<span class="st">&#39;distance &gt; 1000&#39;</span>)
long_flights2 <span class="op">=</span> flights.<span class="bu">filter</span>(flights.distance <span class="op">&gt;</span> <span class="dv">1000</span>)
model_data <span class="op">=</span> model_data.<span class="bu">filter</span>(<span class="st">&quot;arr_delay is not NULL and dep_delay is not NULL and air_time is not NULL&quot;</span>)

<span class="co"># Groupby</span>
flights.<span class="bu">filter</span>(flights.origin <span class="op">==</span> <span class="st">&quot;PDX&quot;</span>).groupBy().<span class="bu">min</span>(<span class="st">&quot;distance&quot;</span>).show()
flights.<span class="bu">filter</span>(flights.carrier<span class="op">==</span><span class="st">&#39;DL&#39;</span>).<span class="bu">filter</span>(flights.origin<span class="op">==</span><span class="st">&#39;SEA&#39;</span>).groupBy().avg(<span class="st">&#39;air_time&#39;</span>).show()
flights.withColumn(<span class="st">&quot;duration_hrs&quot;</span>, flights.air_time<span class="op">/</span><span class="dv">60</span>).groupBy().<span class="bu">sum</span>(<span class="st">&#39;duration_hrs&#39;</span>).show()

<span class="co"># Spark functions</span>
by_month_dest.agg(F.stddev(<span class="st">&#39;dep_delay&#39;</span>)).show()

<span class="co"># Drop column</span>
final_test_data.drop(<span class="st">&#39;State&#39;</span>)

<span class="co"># Dummying</span>

<span class="co"># The first step to encoding your categorical feature is to create a StringIndexer. Members of this class are Estimators that take a DataFrame with a column of strings and map each unique string to a number. Then, the Estimator returns a Transformer that takes a DataFrame, attaches the mapping to it as metadata, and returns a new DataFrame with a numeric column corresponding to the string column. The second step is to encode this numeric column as a one-hot vector using a OneHotEncoder. This works exactly #the same way as the StringIndexer by creating an Estimator and then a Transformer</span>

<span class="co"># Create a StringIndexer</span>
carr_indexer <span class="op">=</span> StringIndexer(inputCol<span class="op">=</span><span class="st">&quot;carrier&quot;</span>, outputCol<span class="op">=</span><span class="st">&quot;carrier_index&quot;</span>)

<span class="co"># Create a OneHotEncoder</span>
carr_encoder <span class="op">=</span> OneHotEncoder(inputCol<span class="op">=</span><span class="st">&quot;carrier_index&quot;</span>, outputCol<span class="op">=</span><span class="st">&quot;carrier_fact&quot;</span>)

<span class="co"># Make a VectorAssembler</span>
vec_assembler <span class="op">=</span> VectorAssembler(inputCols <span class="op">=</span> [<span class="st">&quot;carrier_fact&quot;</span>, <span class="st">&quot;dest_fact&quot;</span>, <span class="st">&quot;plane_age&quot;</span>], outputCol <span class="op">=</span> <span class="st">&quot;features&quot;</span>)

<span class="co">## Import &amp; Make Pipeline</span>
flights_pipe <span class="op">=</span> Pipeline(stages<span class="op">=</span>[dest_indexer, dest_encoder, carr_indexer, carr_encoder, vec_assembler])

<span class="co">## Fit and transform the data</span>
piped_data <span class="op">=</span> flights_pipe.fit(model_data).transform(model_data)

<span class="co"># Preprocessing</span>

<span class="co"># Mutate</span>
df <span class="op">=</span> df.withColumn(<span class="st">&quot;label&quot;</span>, df[<span class="st">&quot;target&quot;</span>].cast(<span class="st">&#39;integer&#39;</span>))
<span class="co">#df = df.withColumn(&quot;newCol&quot;, df.oldCol + 1)</span>
<span class="co">#model_data = model_data.withColumn(&quot;plane_age&quot;, model_data.year - model_data.plane_year)</span>

feature_cols <span class="op">=</span> [<span class="st">&quot;some list of column names&quot;</span>]

scf_indexer <span class="op">=</span> StringIndexer(inputCol <span class="op">=</span> <span class="st">&quot;some_cat_feature&quot;</span>, outputCol <span class="op">=</span> <span class="st">&quot;some_cat_feature_index&quot;</span>)
scf_encoder <span class="op">=</span> OneHotEncoder(inputCol <span class="op">=</span> <span class="st">&quot;some_cat_feature_index&quot;</span>, outputCol <span class="op">=</span> <span class="st">&quot;some_cat_feature_fact&quot;</span>)
vec_assembler <span class="op">=</span> VectorAssembler(inputCols <span class="op">=</span> feature_cols, outputCol <span class="op">=</span> <span class="st">&quot;features&quot;</span>)

pipe <span class="op">=</span> Pipeline(stages <span class="op">=</span> [scf_indexer, scf_encoder, vec_assembler])

piped_data <span class="op">=</span> pipe.fit(df).transform(df)
training, test <span class="op">=</span> piped_data.randomSplit([.<span class="dv">8</span>, <span class="fl">.2</span>])

<span class="co"># Model</span>

mdl <span class="op">=</span> LogisticRegression()
evaluator <span class="op">=</span> evals.BinaryClassificationEvaluator(metricName <span class="op">=</span> <span class="st">&quot;areaUnderROC&quot;</span>)

grid <span class="op">=</span> tune.ParamGridBuilder()
grid <span class="op">=</span> grid.addGrid(mdl.regParam, np.arange(<span class="dv">0</span>, <span class="fl">.1</span>, <span class="fl">.01</span>))
grid <span class="op">=</span> grid.addGrid(mdl.elasticNetParam, [<span class="dv">0</span>, <span class="dv">1</span>])
grid <span class="op">=</span> grid.build()

cv_results <span class="op">=</span> tune.CrossValidator(estimator <span class="op">=</span> mdl, estimatorParamMaps <span class="op">=</span> grid,
                                 evaluator <span class="op">=</span> evaluator, numFolds <span class="op">=</span> <span class="dv">5</span>)

mdl_best <span class="op">=</span> cv_results.fit(training).bestModel
results <span class="op">=</span> mdl_best.transform(training)

<span class="bu">print</span>(evaluator.evaluate(results))

sc.stop()</code></pre>
</div>
<div id="sparklyr" class="section level2">
<h2><span class="header-section-number">9.22</span> Sparklyr</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)

<span class="co"># feature transforms: ft_, ml functions: ml_, spark df functions: sdf_</span>
<span class="co"># spark: src, ft, ml, sdf, new_ml, spark, stream, compute &amp; collect spark</span>

sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master=</span><span class="st">&quot;local&quot;</span>)
config &lt;-<span class="st"> </span><span class="kw">spark_config</span>()
config<span class="op">$</span>spark.executor.cores &lt;-<span class="st"> </span><span class="dv">8</span>
config<span class="op">$</span>spark.executor.memory &lt;-<span class="st"> &quot;25G&quot;</span>

flights &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, flights, <span class="st">&quot;flights&quot;</span>)
<span class="kw">src_tbls</span>(sc)

<span class="kw">spark_apply</span>(iris_tbl, 
            <span class="cf">function</span>(e) <span class="kw">summary</span>(<span class="kw">lm</span>(Petal_Length <span class="op">~</span><span class="st"> </span>Petal_Width, e))<span class="op">$</span>r.squared, 
            <span class="dt">names =</span> <span class="st">&quot;r.squared&quot;</span>,
            <span class="dt">group_by =</span> <span class="st">&quot;Species&quot;</span>)

final &lt;-<span class="st"> </span>names <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spark_dataframe</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sqlfunction</span>(sc, <span class="st">&quot;SELECT * FROM test&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_register</span>(<span class="st">&quot;name5&quot;</span>)

<span class="co">## Print 5 rows, all columns</span>
<span class="kw">print</span>(track_metadata_tbl, <span class="dt">n =</span> <span class="dv">5</span>, <span class="dt">width =</span> <span class="ot">Inf</span>)

<span class="co">## Write and run SQL query</span>
query &lt;-<span class="st"> &quot;SELECT * FROM track_metadata WHERE year &lt; 1935 AND duration &gt; 300&quot;</span>
results &lt;-<span class="st"> </span><span class="kw">dbGetQuery</span>(sc, query)

<span class="co">## General transformation structure and example</span>
df &lt;-<span class="st"> </span><span class="kw">ft_some_transformation</span>(df, <span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>, some_other_args)

hotttnesss &lt;-<span class="st"> </span>track_metadata_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Select artist_hotttnesss</span>
<span class="st">  </span><span class="kw">select</span>(artist_hotttnesss) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Binarize to is_hottt_or_nottt</span>
<span class="st">  </span><span class="kw">ft_binarizer</span>(<span class="st">&#39;artist_hotttnesss&#39;</span>, <span class="st">&#39;is_hottt_or_nottt&#39;</span>, <span class="dt">threshold =</span> <span class="fl">.5</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Collect the result</span>
<span class="st">  </span><span class="kw">collect</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Convert is_hottt_or_nottt to logical</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">is_hottt_or_nottt =</span> <span class="kw">as.logical</span>(is_hottt_or_nottt))
  
<span class="co">## Get and transform the schema</span>

(schema &lt;-<span class="st"> </span><span class="kw">sdf_schema</span>(track_metadata_tbl))
schema <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lapply</span>(<span class="cf">function</span>(x) <span class="kw">do.call</span>(data_frame, x)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_rows</span>()

<span class="co">## Train-test split</span>
partitioned &lt;-<span class="st"> </span><span class="kw">sdf_partition</span>(df, <span class="dt">training =</span> <span class="fl">0.7</span>, <span class="dt">testing =</span> <span class="fl">0.3</span>)

<span class="co">## gradient boosted trees model Example</span>

gradient_boosted_trees_model &lt;-<span class="st"> </span><span class="kw">ml_gradient_boosted_trees</span>(df, <span class="st">&#39;year&#39;</span>, feature_colnames)

responses &lt;-<span class="st"> </span>track_data_to_predict_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Select the year column</span>
<span class="st">  </span><span class="kw">select</span>(year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Collect the results</span>
<span class="st">  </span><span class="kw">collect</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Add in the predictions</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predicted_year =</span> <span class="kw">predict</span>(gradient_boosted_trees_model, track_data_to_predict_tbl))

<span class="kw">spark_disconnect</span>(sc)</code></pre>
</div>
<div id="data-table" class="section level2">
<h2><span class="header-section-number">9.23</span> Data Table</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Operations done by reference</span>

<span class="kw">names</span>(DT) <span class="co"># colnames</span>
<span class="kw">dim</span>(DT) <span class="co"># dimensions</span>

DT[i, j, by]  <span class="co"># subset by i calculate by j grouped using by</span>
DT[.N]  <span class="co"># prints last row</span>
DT[, .(A, B)] <span class="co"># returns two columns</span>
DT[, <span class="kw">c</span>(A, B)] <span class="co"># returns a concatenated vector</span>
DT[, .(<span class="dt">sum_c =</span> <span class="kw">sum</span>(C)] <span class="co"># mutate</span>
DT[, <span class="kw">plot</span>(A, C)] <span class="co"># plot?</span>
DT[, A <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="ot">NULL</span>] <span class="co"># Remove column A</span>
DT[, .(<span class="dt">sumB =</span> <span class="kw">sum</span>(B)), <span class="dt">by =</span> .(<span class="dt">Grp =</span> A<span class="op">%%</span><span class="dv">2</span>)] <span class="co"># group_by &amp; summarize</span>
DT[, .N, <span class="dt">by =</span> Sepal.Width] <span class="co"># .N is the count of each group</span>
DT[, <span class="kw">lapply</span>(.SD, median)] <span class="co"># .SD is a placeholder for all the columns</span>
DT[, <span class="kw">lapply</span>(.SD, mean), <span class="dt">.SDcols =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">3</span>] <span class="co"># Find mean of columns 2 &amp; 3</span>
DT[.(<span class="st">&#39;b&#39;</span>)]
DT[.(<span class="kw">c</span>(<span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>))]
DT[.(<span class="kw">c</span>(<span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>)), <span class="dt">mult=</span><span class="st">&quot;first&quot;</span>]
DT[<span class="kw">c</span>(<span class="st">&quot;b&quot;</span>, <span class="st">&quot;c&quot;</span>), .SD[<span class="kw">c</span>(<span class="dv">1</span>, .N)], <span class="dt">by =</span> .EACHI] <span class="co"># First and last row of the &quot;b&quot; and &quot;c&quot; groups</span>
DT[<span class="kw">c</span>(<span class="st">&quot;b&quot;</span>, <span class="st">&quot;c&quot;</span>), { <span class="kw">print</span>(.SD); .SD[<span class="kw">c</span>(<span class="dv">1</span>, .N)] }, <span class="dt">by =</span> .EACH]

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>) <span class="kw">set</span>(DT, i, 3L, i<span class="op">+</span><span class="dv">1</span>) <span class="co"># update first 5 rows of 3rd column</span>
<span class="kw">setnames</span>(DT, <span class="st">&#39;y&#39;</span>, <span class="st">&#39;z&#39;</span>) <span class="co"># changes colname from y to z</span>
<span class="kw">setkey</span>(DT, A, B)

dt1[dt2, <span class="dt">roll=</span><span class="op">-</span><span class="ot">Inf</span>, <span class="dt">rollends=</span><span class="ot">FALSE</span>] <span class="co"># rolling join</span></code></pre>
</div>
<div id="keras" class="section level2">
<h2><span class="header-section-number">9.24</span> Keras</h2>
<p>The general framework: 1) instantiate, 2) add layers input-hidden-output, 3) compile, 4) fit</p>
<pre class="sourceCode r"><code class="sourceCode r">network &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() 

network <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">512</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">28</span> <span class="op">*</span><span class="st"> </span><span class="dv">28</span>)) <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">&quot;softmax&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">compile</span>(<span class="dt">optimizer =</span> <span class="st">&quot;rmsprop&quot;</span>,  <span class="dt">loss =</span> <span class="st">&quot;categorical_crossentropy&quot;</span>,  <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">&quot;accuracy&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">fit</span>(train_images, train_labels, <span class="dt">epochs =</span> <span class="dv">5</span>, <span class="dt">batch_size =</span> <span class="dv">128</span>)

metrics &lt;-<span class="st"> </span>network <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">evaluate</span>(test_images, test_labels)

<span class="co">#import keras</span>
<span class="co">#from keras.layers import Dense</span>
<span class="co">#from keras.models import Sequential</span>

<span class="co"># Regression</span>

<span class="co"># Specify the model</span>
<span class="co">#model = Sequential()</span>
<span class="co">## Input</span>
<span class="co">#model.add(Dense(50, activation=&#39;relu&#39;, input_shape = 3))</span>
<span class="co"># Hidden</span>
<span class="co">#model.add(Dense(32, activation=&#39;relu&#39;))</span>
<span class="co"># Output</span>
<span class="co">#model.add(Dense(1))</span>
<span class="co"># Compile the model</span>
<span class="co">#model.compile(optimizer = &#39;adam&#39;, loss = &#39;mean_squared_error&#39;) </span>
<span class="co"># Fit the model</span>
<span class="co">#model.fit(predictors, target))</span>

<span class="co"># Classification</span>

<span class="co"># Specify the model: Two hidden layers</span>
<span class="co">#model = Sequential()</span>
<span class="co">## Input</span>
<span class="co">#model.add(Dense(50, activation=&#39;relu&#39;, input_shape = 3))</span>
<span class="co"># Hidden</span>
<span class="co">#model.add(Dense(32, activation=&#39;relu&#39;))</span>
<span class="co"># Output</span>
<span class="co">#model.add(Dense(2, activation = &#39;softmax&#39;))</span>
<span class="co"># Compile the model</span>
<span class="co">#model.compile(optimizer = &#39;sgd&#39;, loss = &#39;categorical_crossentropy&#39;, metrics = &#39;accuracy&#39;)</span>
<span class="co"># Fit the model</span>
<span class="co">#model.fit(predictors, target)</span>

<span class="co"># Other</span>

<span class="co"># Dummying</span>
<span class="co">#y = 1</span>
<span class="co">#keras.utils.to_categorical(y, num_classes = 2)</span>

<span class="co">#Look at summary</span>
<span class="co">#model.summary()</span>

<span class="co">#Calculate predictions: predictions</span>
<span class="co">#predictions = model.predict(pred_data)</span>

<span class="co">#Calculate predicted probability of survival</span>
<span class="co">#predicted_prob_true = predictions[:, 1]</span></code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probabilistic-programming.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-cook_book.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
