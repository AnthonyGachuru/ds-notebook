# Codebook 

```{python, eval = F}
def objective(trial):    
    
    #joblib.dump(study, 'study.pkl')
    
    lr = trial.suggest_uniform('learning_rate', 0.01, 1.0)
    nl = trial.suggest_int('num_leaves', 1, 100) 
    md = trial.suggest_int('max_depth', 0, 50) 
    mcs = trial.suggest_int('min_child_samples', 0, 50) 
    mb = trial.suggest_int('max_bin', 100, 1000) 
    ss = trial.suggest_uniform('subsample', 0.01, 1.0)
    ssf = trial.suggest_int('subsample_freq', 0, 10) 
    csbt = trial.suggest_uniform('subsample', 0.01, 1.0)
    mcw = trial.suggest_int('min_child_weight', 0, 10) 
    ssfb = trial.suggest_int('subsample_for_bin', 100000, 500000) 
    rl = trial.suggest_loguniform('reg_lambda', 1e-9, 1000)
    ra = trial.suggest_loguniform('reg_alpha', 1e-9, 1.0)
    spw = trial.suggest_loguniform('scale_pos_weight', 1e-6, 500)
    ne = trial.suggest_int('n_estimators', 50, 100)
    
    grid = {'learning_rate': lr,
            'num_leaves': nl, 
            'max_depth': md, 
            'min_child_samples': mcs,
            'max_bin': mb, 
            'subsample': ss,
            'subsample_freq': ssf, 
            'colsample_bytree': csbt,
            'min_child_weight': mcw,
            'subsample_for_bin': ssfb,
            'reg_lambda': rl,
            'reg_alpha': ra ,
            'scale_pos_weight': spw,
            'n_estimators': ne}
    
    mdl.set_params(**grid)

    return(np.mean(sk_ms.cross_val_score(mdl, X_train, y_train, cv = 5)))

study = optuna.create_study()
study.optimize(objective, timeout = 10)
```


## Mixed Effect Regression

```{python, eval = F}
import statsmodels.api as sm
import statsmodels.formula.api as smf

mdl = smf.mixedlm("y ~ x". df, groups = train['group'])
mdl_fit = mdl.fit()
```

## Regression By Groups

```{r, eval = FALSE}
pga %>% 
  split(.$year) %>%
  map(~lm(score.avg ~ driveavg + drivepct, data=.)) %>%
  map(summary)

mtcars %>% group_by(cyl) %>% split(.$cyl) %>% purrr::map(~ lm(mpg ~ ., data = .))
mtcars %>% group_by(cyl) %>% nest() %>% 
mutate(model = map(data, function(x) lm(mpg ~ ., data = x) ))
```

## Symbolic Regression

```{python, eval = F}
from gplearn import SymbolicRegressor

est_gp = SymbolicRegressor(population_size = 100, generations = 100, stopping_criteria = 0.01, p_crossover = 0.7, p_subtree_mutation = 0.1, metric = 'rmse', p_hoist_mutation = 0.05, p_point_mutation = 0.1, max_samples = 0.9, verbose = 0, parsimony_coefficient = 0.01, random_state = seed)

est_gp.fit(X_train, y_train)
preds = est_gp.predict(X_train)
np.sqrt(mean_squared_error(y_train, preds))

graph = pydotplus.graphviz.graph_from_dot_data(est_gp._program.export_graphviz())
Image(graph.create_png())
eqn = str(est_gp._program)
mapping_dict = {'X{}'.format(i): X_train.columns[i] for i in range(X_train.shape[1])}

for old_value, new_value in mapping_dict.items():
  eqn = eqn.replace(old_value, new_value)
```

## Stats By Simulation

Notes on the talk by Jake Vanderplas. I left out bootstrap and cross validation below. For all methods look out for selection bias and make sure you have representative samples. More on the bootstrap: These are simulated confidence intervals that work well for n > 20 as a rule of thumb.

```{r, eval = F}
# Direct Simulation: Works well with an apriori (generative) model of the world, like the probability distribution of a coin toss. Example: Flip a fair coin 30 times. How likely it is to see 22 heads?

n <- 10^6
h_a <- 22
result <- purrr::map(seq(1, n, 1), 
           ~ sum(base::sample(c(0,1), 30, replace = T)) >= h_a) %>%
  unlist() %>% sum()

result/n

# Shuffling: Comparing groups

iris_100 <- iris[1:100, c(2,5)]
(t.test(iris_100[1:50, 1], iris_100[51:100, 1], 
       alternative = 'greater'))$p.value

ha_shuffle <- function(df){
  
  result <- df %>% 
  mutate(Species = sample(Species, n())) %>% 
  group_by(Species) %>% 
  summarise_at(1, mean) %>% 
  mutate(mu_diff = Sepal.Width - lag(Sepal.Width)) %>% 
  filter(!is.na(mu_diff)) %>% 
  pull(mu_diff)
  
  return(result >= observed_diff)
  
}

observed_diff <- iris_100 %>% 
  group_by(Species) %>% 
  summarise_at(1, mean) %>% 
  mutate(mu_diff = Sepal.Width - lag(Sepal.Width)) %>% 
  filter(!is.na(mu_diff)) %>% 
  pull(mu_diff)

n <- 10^6
result <- purrr::map(seq(1, n, 1), ~ ha_shuffle(iris_100)) %>%
  unlist() %>% sum()

result/n

# He discussed cross validation as a third method
```

## TS Harmonic Regression

```{r, eval = F}
# Set up harmonic regressors of order 13
harmonics <- fourier(gasoline, K = 13)
# Fit regression model with ARIMA errors
fit <- auto.arima(gasoline, xreg = harmonics, seasonal = FALSE)
# Forecasts next 3 years
fc <- forecast(fit, xreg = fourier(gasoline, K = 13, h = 156))
# Plot forecasts fc
autoplot(fc)
```

## Save And Load Models

```{python, eval = F}
from sklearn.externals import joblib

joblib.dump(grid_search, 'model.joblib')
grid_search = joblib.load('model.joblib')

model = grid_search.best_estimator_
```

```{r, eval = F}
save(m1, file = "my_model1.rda")
m1 = load("my_model1.rda")
```

## LSTM 

```{python, eval = F}
# Data Shape
data_x = np.array([
    # Datapoint 1: 3 features for timesteps 1 & 2
    [[1, 2, 3], [4, 5, 6]],
    # Datapoint 2
    [[7, 8, 9], [10, 11, 12]]])
    
# Prediction Example
mdl.predict([[np.array([.5, .6, .6] + [0 for i in range(14)]).reshape((17, 1))]])[0]
```

## Pairwise Scatterplot

```{r, eval = F}
GGally::ggpairs(data, mapping = aes(colour = category))
```

## Anti-join

```{python, eval = F}
# https://stackoverflow.com/questions/38516664/anti-join-pandas

# Identify what values are in TableB and not in TableA
key_diff = set(TableB.Key).difference(TableA.Key)
where_diff = TableB.Key.isin(key_diff)

# Slice TableB accordingly and append to TableA
TableA.append(TableB[where_diff], ignore_index=True)
```

## Df Diff

```{python, eval = F}
# https://stackoverflow.com/a/36893675/6627726

merged = df1.merge(df2, indicator=True, how='outer')
merged[merged['_merge'] == 'right_only']
```

## Read SQL 

```{r, eval = F}
df <- dbGetQuery(con, statement = read_file('query.sql'))
```

## Extract Date

```{r, eval = F}
StartTime %>% as.POSIXct() %>% strftime(format="%Y-%m-%d")
YearMonth = Day %>% strftime(format="%Y-%m")
date = date %>% as.POSIXct() %>% strptime('%Y-%m-%d') %>% strftime(format="%Y-%m-%d")
```

## GGplot To Plotly

```{r, eval = F}
ggplotly(ggplot(df), aes(x, y, label = z, color = w)) +
        geom_jitter(width = .2), tooltip = c('y', 'label'))
```

## Custom Plotting Theme

```{r, eval = F}
theme_ilo <- function() {
    theme_minimal() +
        theme(
            text = element_text(family = "Bookman", color = "gray25"),
            plot.subtitle = element_text(size = 12),
            plot.caption = element_text(color = "gray30"),
            plot.background = element_rect(fill = "gray95"),
            plot.margin = unit(c(5, 10, 5, 10), units = "mm")
        )
}
```

## Rowwise

```{python, eval = F}
rectangles = [
    { 'height': 40, 'width': 10 },
    { 'height': 20, 'width': 9 },
    { 'height': 3.4, 'width': 4 }
]
rectangles_df = pd.DataFrame(rectangles)
def calculate_area(row):
    return row['height'] * row['width']
rectangles_df.apply(calculate_area, axis=1)
```

```{r, eval = F}
library(dplyr)

mtcars %>% 
  rowwise() %>% 
  mutate(mymean = mean(c(cyl,mpg))) %>% 
  select(cyl, mpg, mymean)

df %>% 
  mutate(mu = select(., R1:R16) %>% pmap_dbl(~mean(c(...))))

calc_row_mean <- function(li){
  
  df <- as.data.frame(li)
  
  result <- df %>% 
    select(contains("Round")) %>%
    mutate(mu = rowMeans(.)) %>% 
    pull(mu)
  
  return(result)
  
}
```

## Sampling File

```{bash, eval = F}
pip install subsample
subsample -s 8 -n 100000 test.csv -r > test_sample.csv
```

## Featuretools

```{python, eval = F}
# https://stackoverflow.com/questions/50145953/how-to-apply-deep-feature-synthesis-to-a-single-table

import numpy as np
import pandas as pd
import featuretools as ft

df = pd.read_csv('iris.csv')
df = df.reset_index()

es = ft.EntitySet(id = "test") #.drop(columns = ['species'], axis = 1)
es = es.entity_from_dataframe(entity_id = 'd', dataframe = df, make_index=True, index='ind')

# produces 626 features
fm, features = ft.dfs(
    entityset = es, 
    target_entity = 'd',
    agg_primitives = ['mean', 'max', 'percent_true', 'last'],
    trans_primitives = ['subtract', 'divide']
)

# produces no new features
_, features2 = ft.dfs(
    entityset = es, 
    target_entity = 'd',
    max_depth = 2
)
```

## SHAP

```{python, eval = F}
import shap
import matplotlib.pyplot as plt

mdl.fit(X_train, y_train)
explainer = shap.TreeExplainer(clf)
shap_values = explainer.shap_values(X_train)

#all records explained (both lines of code)
shap.summary_plot(shap_values, X_train)
shap.summary_plot(shap_values, X_train, plot_type = "bar")

df_shap = pd.DataFrame(list(zip(np.mean(shap_values, axis = 0), X_train.columns)),
                       columns = ['shap_mean', 'feature'])
df_shap = df_shap[['feature', 'shap_mean']]

df_shap['shap_mean_abs'] = np.absolute(df_shap['shap_mean'])
df_shap.sort_values(['shap_mean_abs'], ascending = False, inplace = True)

attribution_data = np.array(train_data[:50])
explainer = shap.DeepExplainer(model, attribution_data)
```

## CSV To DB

```{bash, eval = F}
# alternative: http://bit.ly/294gmmP
sqlite3 db_name.db
.mode csv db_name
.import data.csv db_name
```

## Bayesian CV

```{python, eval = F}
from scipy.stats import randint as sp_randint
from skopt import BayesSearchCV
from skopt.space import Real, Integer, Categorical

mdl_tuner = BayesSearchCV(estimator = mdl, search_spaces = grid, scoring = 'roc_auc',
                          cv = folds, random_state = 8)
                          
result = mdl_tuner.fit(X_train.values, y_train.values)
```

## Pyspark

```{python, eval = FALSE}
# Cheatsheet: https://www.qubole.com/resources/pyspark-cheatsheet/

# Spark only handles numeric data. 

# selectExpr() takes SQL expressions as a string.

# Spark's assumes the target is called 'label' in ML. Everything else is a feature.

# Estimator classes are for modeling and all implement a .fit() method. eg. StringIndexerModel for including categorical data saved as strings in your models

# It's important to split the data after all the transformations because operations like StringIndexer don't always produce the same index even when given the same list of strings.

# Import

import findspark
findspark.init()

import pyspark
from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml import Pipeline
from pyspark.ml.classification import LogisticRegression
import pyspark.ml.evaluation as evals
import pyspark.ml.tuning as tune
import pyspark.sql.functions as F

sc = pyspark.SparkContext()
spark = SparkSession.builder.getOrCreate() # SparkSession.builder.appName('chosenName').getOrCreate()

# Approximate Pi

def inside(p):     
    x, y = random.random(), random.random()
    return x*x + y*y < 1
    
num_samples = 100000000
count = sc.parallelize(range(0, num_samples)).filter(inside).count()
pi = 4 * count / num_samples

print(pi)

df = spark.read.csv('data.csv', header = True)
#df = spark.read.format("csv").option("header","true").option("inferSchema","true").load("john_doe.csv")

df.show(5)
df.columns

# Transform

## List tables
spark.catalog.listTables()

# Access and display data
flights10 = spark.sql("FROM flights SELECT * LIMIT 10")
flights10.show()

# Cast
df['g'] = df['g'].astype(str)

# Spark df to pandas and vice versa
spark_temp = spark.createDataFrame(pd_temp) # toPandas()

# Add to the catalog
spark_temp.createOrReplaceTempView("temp")

# Create the DataFrame flights
flights = spark.table('flights')

# Get column names
spark_df.schema.names
spark_df.printSchema()

# Filter
# takes either a Spark Column of boolean (True/False) values or the WHERE clause of a SQL expression as a string
long_flights1 = flights.filter('distance > 1000')
long_flights2 = flights.filter(flights.distance > 1000)
model_data = model_data.filter("arr_delay is not NULL and dep_delay is not NULL and air_time is not NULL")

# Groupby
flights.filter(flights.origin == "PDX").groupBy().min("distance").show()
flights.filter(flights.carrier=='DL').filter(flights.origin=='SEA').groupBy().avg('air_time').show()
flights.withColumn("duration_hrs", flights.air_time/60).groupBy().sum('duration_hrs').show()

# Spark functions
by_month_dest.agg(F.stddev('dep_delay')).show()

# Drop column
final_test_data.drop('State')

# Dummying

# The first step to encoding your categorical feature is to create a StringIndexer. Members of this class are Estimators that take a DataFrame with a column of strings and map each unique string to a number. Then, the Estimator returns a Transformer that takes a DataFrame, attaches the mapping to it as metadata, and returns a new DataFrame with a numeric column corresponding to the string column. The second step is to encode this numeric column as a one-hot vector using a OneHotEncoder. This works exactly #the same way as the StringIndexer by creating an Estimator and then a Transformer

# Create a StringIndexer
carr_indexer = StringIndexer(inputCol="carrier", outputCol="carrier_index")

# Create a OneHotEncoder
carr_encoder = OneHotEncoder(inputCol="carrier_index", outputCol="carrier_fact")

# Make a VectorAssembler
vec_assembler = VectorAssembler(inputCols = ["carrier_fact", "dest_fact", "plane_age"], outputCol = "features")

## Import & Make Pipeline
flights_pipe = Pipeline(stages=[dest_indexer, dest_encoder, carr_indexer, carr_encoder, vec_assembler])

## Fit and transform the data
piped_data = flights_pipe.fit(model_data).transform(model_data)

# Preprocessing

# Mutate
df = df.withColumn("label", df["target"].cast('integer'))
#df = df.withColumn("newCol", df.oldCol + 1)
#model_data = model_data.withColumn("plane_age", model_data.year - model_data.plane_year)

feature_cols = ["some list of column names"]

scf_indexer = StringIndexer(inputCol = "some_cat_feature", outputCol = "some_cat_feature_index")
scf_encoder = OneHotEncoder(inputCol = "some_cat_feature_index", outputCol = "some_cat_feature_fact")
vec_assembler = VectorAssembler(inputCols = feature_cols, outputCol = "features")

pipe = Pipeline(stages = [scf_indexer, scf_encoder, vec_assembler])

piped_data = pipe.fit(df).transform(df)
training, test = piped_data.randomSplit([.8, .2])

# Model

mdl = LogisticRegression()
evaluator = evals.BinaryClassificationEvaluator(metricName = "areaUnderROC")

grid = tune.ParamGridBuilder()
grid = grid.addGrid(mdl.regParam, np.arange(0, .1, .01))
grid = grid.addGrid(mdl.elasticNetParam, [0, 1])
grid = grid.build()

cv_results = tune.CrossValidator(estimator = mdl, estimatorParamMaps = grid,
                                 evaluator = evaluator, numFolds = 5)

mdl_best = cv_results.fit(training).bestModel
results = mdl_best.transform(training)

print(evaluator.evaluate(results))

sc.stop()
```

## Sparklyr

```{r, eval = FALSE}
library(sparklyr)

# feature transforms: ft_, ml functions: ml_, spark df functions: sdf_
# spark: src, ft, ml, sdf, new_ml, spark, stream, compute & collect spark

sc <- spark_connect(master="local")
config <- spark_config()
config$spark.executor.cores <- 8
config$spark.executor.memory <- "25G"

flights <- copy_to(sc, flights, "flights")
src_tbls(sc)

spark_apply(iris_tbl, 
            function(e) summary(lm(Petal_Length ~ Petal_Width, e))$r.squared, 
            names = "r.squared",
            group_by = "Species")

final <- names %>%
  spark_dataframe() %>%
  sqlfunction(sc, "SELECT * FROM test") %>%
  sdf_register("name5")

## Print 5 rows, all columns
print(track_metadata_tbl, n = 5, width = Inf)

## Write and run SQL query
query <- "SELECT * FROM track_metadata WHERE year < 1935 AND duration > 300"
results <- dbGetQuery(sc, query)

## General transformation structure and example
df <- ft_some_transformation(df, "x", "y", some_other_args)

hotttnesss <- track_metadata_tbl %>%
  # Select artist_hotttnesss
  select(artist_hotttnesss) %>%
  # Binarize to is_hottt_or_nottt
  ft_binarizer('artist_hotttnesss', 'is_hottt_or_nottt', threshold = .5) %>%
  # Collect the result
  collect() %>%
  # Convert is_hottt_or_nottt to logical
  mutate(is_hottt_or_nottt = as.logical(is_hottt_or_nottt))
  
## Get and transform the schema

(schema <- sdf_schema(track_metadata_tbl))
schema %>% lapply(function(x) do.call(data_frame, x)) %>% bind_rows()

## Train-test split
partitioned <- sdf_partition(df, training = 0.7, testing = 0.3)

## gradient boosted trees model Example

gradient_boosted_trees_model <- ml_gradient_boosted_trees(df, 'year', feature_colnames)

responses <- track_data_to_predict_tbl %>%
  # Select the year column
  select(year) %>%
  # Collect the results
  collect() %>%
  # Add in the predictions
  mutate(predicted_year = predict(gradient_boosted_trees_model, track_data_to_predict_tbl))

spark_disconnect(sc)
```

## Data Table

```{r, eval = FALSE}
# Operations done by reference

names(DT) # colnames
dim(DT) # dimensions

DT[i, j, by]  # subset by i calculate by j grouped using by
DT[.N]  # prints last row
DT[, .(A, B)] # returns two columns
DT[, c(A, B)] # returns a concatenated vector
DT[, .(sum_c = sum(C)] # mutate
DT[, plot(A, C)] # plot?
DT[, A := NULL] # Remove column A
DT[, .(sumB = sum(B)), by = .(Grp = A%%2)] # group_by & summarize
DT[, .N, by = Sepal.Width] # .N is the count of each group
DT[, lapply(.SD, median)] # .SD is a placeholder for all the columns
DT[, lapply(.SD, mean), .SDcols = 2:3] # Find mean of columns 2 & 3
DT[.('b')]
DT[.(c('b', 'c'))]
DT[.(c('b', 'c')), mult="first"]
DT[c("b", "c"), .SD[c(1, .N)], by = .EACHI] # First and last row of the "b" and "c" groups
DT[c("b", "c"), { print(.SD); .SD[c(1, .N)] }, by = .EACH]

for (i in 1:5) set(DT, i, 3L, i+1) # update first 5 rows of 3rd column
setnames(DT, 'y', 'z') # changes colname from y to z
setkey(DT, A, B)

dt1[dt2, roll=-Inf, rollends=FALSE] # rolling join
```

## Keras 

The general framework: 1) instantiate, 2) add layers input-hidden-output, 3) compile, 4) fit

```{r, eval = F}
network <- keras_model_sequential() 

network %>%  
  layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>%  
  layer_dense(units = 10, activation = "softmax") %>% 
  compile(optimizer = "rmsprop",  loss = "categorical_crossentropy",  metrics = c("accuracy")) %>% 
  fit(train_images, train_labels, epochs = 5, batch_size = 128)

metrics <- network %>% evaluate(test_images, test_labels)

#import keras
#from keras.layers import Dense
#from keras.models import Sequential

# Regression

# Specify the model
#model = Sequential()
## Input
#model.add(Dense(50, activation='relu', input_shape = 3))
# Hidden
#model.add(Dense(32, activation='relu'))
# Output
#model.add(Dense(1))
# Compile the model
#model.compile(optimizer = 'adam', loss = 'mean_squared_error') 
# Fit the model
#model.fit(predictors, target))

# Classification

# Specify the model: Two hidden layers
#model = Sequential()
## Input
#model.add(Dense(50, activation='relu', input_shape = 3))
# Hidden
#model.add(Dense(32, activation='relu'))
# Output
#model.add(Dense(2, activation = 'softmax'))
# Compile the model
#model.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = 'accuracy')
# Fit the model
#model.fit(predictors, target)

# Other

# Dummying
#y = 1
#keras.utils.to_categorical(y, num_classes = 2)

#Look at summary
#model.summary()

#Calculate predictions: predictions
#predictions = model.predict(pred_data)

#Calculate predicted probability of survival
#predicted_prob_true = predictions[:, 1]
```

## Parsnip

```{r, eval = F}
# parsnip

predict_cv <- function(split, rec, model) {
  
  test <- bake(rec, assessment(split))
  
  result <- tibble(actual = test$map_growth_fw,
                   predicted = predict(model, test))
  
  
  return(result)
  
}

split <- initial_split(df_fw, prop = 3/4)
train <- training(split)
test <- testing(split)

rcp <- recipe(map_growth_fw ~ ., train) %>% 
pp <- prep(rcp, training = train, retain = TRUE)
train_pp <- juice(pp)
#test_pp <- bake(pp, newdata = test)

mdl <- set_engine(rand_forest(mode = "regression", trees = 200),
                  "randomForest")

# regular
mdl_fit <- fit(object = mdl,
               formula = formula(pp),
               data = train_pp)

results <- train_pp %>%
  mutate(actual = target,
         preds = pull(predict(mdl_fit, train_pp), .pred)) %>%
  select(actual, preds)

metrics(results, truth = actual, estimate = preds)

#cv

folds <- vfold_cv(train, v = 10)

cv <- folds %>% 
  mutate(train = map(splits, prepper, recipe = rcp), 
         val = map(splits, analysis),
         mdl_fits = map2(train, 
                         val, 
                         ~ fit(mdl, 
                               formula(.x), 
                               data = bake(object = .x, new_data = .y))))

preds <- mutate(cv, 
                pred = pmap(list(splits, train, mdl_fits), predict_cv))

evaluation <- preds %>% 
  mutate(metrics = map(pred, ~ metrics(.x, truth = actual, estimate = predicted))) %>% 
  select(metrics) %>% 
  unnest(metrics) %>% 
  summarise_at(vars(accuracy), funs(mean, sd))


```

